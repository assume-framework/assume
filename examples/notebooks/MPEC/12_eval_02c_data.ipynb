{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtaining data for MA-DPG evaluation form example 02b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module imports\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# assume module imports\n",
    "import examples.examples as examples\n",
    "import examples.notebooks.MPEC.utils as utils\n",
    "from assume import World\n",
    "from assume.scenario.loader_csv import load_file, load_scenario_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting scenario parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if current_dir := os.path.basename(os.getcwd()) == \"MPEC\":\n",
    "    %cd ../../..\n",
    "\n",
    "example = \"small_learning_2\"\n",
    "# actual equilibrium prices\n",
    "# because one can just see it actually\n",
    "\n",
    "# all learning units only needed when the demand exceeds 7000 MW and hence only then market power is necessary\n",
    "equi = [\n",
    "    36.156,\n",
    "    36.156,\n",
    "    36.156,\n",
    "    55.708,\n",
    "    55.708,\n",
    "    55.708,\n",
    "    55.708,\n",
    "    55.708,\n",
    "    85.708,\n",
    "    85.708,\n",
    "    85.708,\n",
    "    85.708,\n",
    "    85.708,\n",
    "    55.708,\n",
    "    55.708,\n",
    "    55.708,\n",
    "    55.708,\n",
    "    55.708,\n",
    "    55.708,\n",
    "    55.708,\n",
    "    55.708,\n",
    "    55.708,\n",
    "    55.708,\n",
    "]\n",
    "# equi = [36.156, 36.156, 36.156] + [55.708] * 20\n",
    "db_uri = \"postgresql://assume:assume@localhost:5432/assume\"\n",
    "inputs_dir = \"examples/inputs\"\n",
    "\n",
    "scenario = examples.available_examples[example][\"scenario\"]\n",
    "study_case = examples.available_examples[example][\"study_case\"]\n",
    "\n",
    "# Set up the database connection\n",
    "db = create_engine(db_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Retrieving the data from the best run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Getting the demand dataframe and power plant units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_case_config = utils.load_config(inputs_dir, scenario, study_case)\n",
    "start = pd.Timestamp(study_case_config[\"start_date\"])\n",
    "end = pd.Timestamp(study_case_config[\"end_date\"])\n",
    "\n",
    "index = pd.date_range(\n",
    "    start=start,\n",
    "    end=end,\n",
    "    freq=study_case_config[\"time_step\"],\n",
    ")\n",
    "\n",
    "demand_df = load_file(\n",
    "    os.path.join(inputs_dir, scenario), study_case_config, \"demand_df\", index\n",
    ")\n",
    "demand_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_units = pd.read_csv(\n",
    "    os.path.join(inputs_dir, scenario, \"powerplant_units.csv\"), index_col=0\n",
    ")\n",
    "pp_units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE: Delete base dispatch if you retrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = utils.load_config(inputs_dir, scenario)\n",
    "if f\"{study_case}_dispatch\" in config:\n",
    "    del config[f\"{study_case}_dispatch\"]\n",
    "# Copy the base and new base_dispatch configuration\n",
    "base_config = config[study_case].copy()\n",
    "base_dispatch = config[study_case].copy()\n",
    "base_dispatch[\"learning_config\"] = base_config[\"learning_config\"].copy()\n",
    "\n",
    "# Modify learning config parameters for base_dispatch\n",
    "base_dispatch[\"learning_config\"].update(\n",
    "    {\n",
    "        \"continue_learning\": False,\n",
    "        \"trained_policies_save_path\": \"learned_strategies/base_dispatch/last_policies\",\n",
    "        \"trained_policies_load_path\": \"learned_strategies/base_dispatch/avg_reward_eval_policies\",\n",
    "        \"training_episodes\": 0,\n",
    "        \"episodes_collecting_initial_experience\": 0,\n",
    "    }\n",
    ")\n",
    "\n",
    "base_dispatch.update(\n",
    "    {\n",
    "        \"learning_mode\": False,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Update the config with both sections\n",
    "config[study_case] = base_config\n",
    "config[f\"{study_case}_dispatch\"] = base_dispatch\n",
    "\n",
    "# Write the updated config back to file\n",
    "utils.store_config(config, inputs_dir, scenario)\n",
    "\n",
    "# Define paths\n",
    "base_dir = Path(\n",
    "    os.path.join(inputs_dir, scenario, f\"learned_strategies/{scenario}_{study_case}\")\n",
    ")\n",
    "dispatch_dir = Path(\n",
    "    os.path.join(inputs_dir, scenario, f\"learned_strategies/{study_case}_dispatch\")\n",
    ")\n",
    "\n",
    "# Check if source directory exists\n",
    "if not base_dir.exists():\n",
    "    print(f\"Source directory {base_dir} does not exist!\")\n",
    "elif dispatch_dir.exists():\n",
    "    print(f\"Target directory {dispatch_dir} already exists!\")\n",
    "else:\n",
    "    # Create target directory if it doesn't exist\n",
    "    dispatch_dir.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Copy directory\n",
    "    shutil.copytree(base_dir, dispatch_dir)\n",
    "    print(f\"Successfully copied {base_dir} to {dispatch_dir}\")\n",
    "\n",
    "world = World(database_uri=db_uri)\n",
    "\n",
    "load_scenario_folder(world, inputs_dir, scenario, f\"{study_case}_dispatch\")\n",
    "\n",
    "world.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get mc\n",
    "\n",
    "Since we want to avoid logging the mc in assume itself, because this is slowing the simualtion down I will get them afterwards. Curretnly the script only runs with time-invariant mc. Hence I test here if that si still the case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = world.unit_operators[\"Operator 1\"].units\n",
    "for name, unit in units.items():\n",
    "    mc = np.array(unit.marginal_cost)\n",
    "    # Check all values are the same\n",
    "    assert np.all(mc == mc[0]), f\"Marginal costs for {name} are not constant: {mc}\"\n",
    "    # Check none are zero\n",
    "    assert np.all(mc != 0), f\"Marginal costs for {name} contain zero: {mc}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose unit.marginal_cost is a list/array of values for each unit\n",
    "# Collect all marginal_cost series in a dict\n",
    "costs_dict = {\n",
    "    name: unit.marginal_cost\n",
    "    for name, unit in world.unit_operators[\"Operator 1\"].units.items()\n",
    "}\n",
    "\n",
    "# Find the length of the series (assuming all are the same length)\n",
    "n = len(next(iter(costs_dict.values())))\n",
    "\n",
    "# Optionally, create a time index (e.g., hourly from start_date)\n",
    "start = pd.Timestamp(study_case_config[\"start_date\"])\n",
    "time_index = pd.date_range(start=start, periods=n, freq=\"h\")  # adjust freq as needed\n",
    "\n",
    "# Create the DataFrame\n",
    "marginal_costs_df = pd.DataFrame(costs_dict, index=time_index)\n",
    "marginal_costs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = (\n",
    "    f\"SELECT * FROM market_orders where simulation = '{scenario}_{study_case}_dispatch'\"\n",
    ")\n",
    "market_orders_df = pd.read_sql(query, db)\n",
    "market_orders_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Establish Sampling of days to be analysed\n",
    "\n",
    "Here we sample from the entire training data a subset of days, for which we test if the profit of all drl agents is similar to their MPEC formulation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = utils.sample_seasonal_weeks(demand_df.index)\n",
    "# TODO: LÖSCHEN NUR FÜR FASTER SOLAVBIILTY AS 1 Week runs into run time limit\n",
    "sampled_indices = sampled_indices[:1]\n",
    "\n",
    "sampled_indices = [demand_df.index.date[0]]\n",
    "sampled_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Get sample subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_df[\"date\"] = demand_df.index.date\n",
    "sample_demand_df = demand_df.loc[demand_df[\"date\"].isin(sampled_indices)]\n",
    "rest_demand_df = demand_df.loc[~demand_df[\"date\"].isin(sampled_indices)]\n",
    "sample_demand_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = (\n",
    "    f\"SELECT * FROM unit_dispatch where simulation = '{scenario}_{study_case}_dispatch'\"\n",
    ")\n",
    "dispatch_df = pd.read_sql(query, db)\n",
    "# dispatch_df = dispatch_df.drop_duplicates(subset=[\"time\", \"unit\"], keep=\"first\")\n",
    "\n",
    "dispatch_df = dispatch_df.sort_values(\"time\")\n",
    "\n",
    "\n",
    "dispatch_df.index = dispatch_df[\"time\"]\n",
    "dispatch_df.drop(columns=[\"time\"], inplace=True)\n",
    "dispatch_df[\"date\"] = dispatch_df.index.date\n",
    "\n",
    "# merge marginal_costs based on unit and time\n",
    "# Reset index to get time as a column\n",
    "mc_long = marginal_costs_df.reset_index().melt(\n",
    "    id_vars=\"index\", var_name=\"unit\", value_name=\"marginal_cost\"\n",
    ")\n",
    "mc_long = mc_long.rename(columns={\"index\": \"time\"})  # Rename index to time if needed\n",
    "\n",
    "# Now merge with dispatch_df on 'time' and 'unit'\n",
    "dispatch_df = dispatch_df.merge(mc_long, on=[\"time\", \"unit\"], how=\"left\")\n",
    "\n",
    "sample_dispatch_df = dispatch_df.loc[dispatch_df[\"date\"].isin(sampled_indices)]\n",
    "rest_dispatch_df = dispatch_df.loc[~dispatch_df[\"date\"].isin(sampled_indices)]\n",
    "sample_dispatch_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample market orders as well\n",
    "market_orders_df.index = pd.to_datetime(market_orders_df[\"start_time\"])\n",
    "market_orders_df = market_orders_df.drop(columns=[\"start_time\"])\n",
    "market_orders_df[\"date\"] = market_orders_df.index.date\n",
    "\n",
    "sample_market_orders_df = market_orders_df.loc[\n",
    "    market_orders_df[\"date\"].isin(sampled_indices)\n",
    "]\n",
    "rest_market_orders_df = market_orders_df.loc[\n",
    "    ~market_orders_df[\"date\"].isin(sampled_indices)\n",
    "]\n",
    "sample_market_orders_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Analyse sample distribution in comparison to entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_sample_distribution(sample_demand_df, rest_demand_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Bi-Level Optimisation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defintion for case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_w = 100000  # weight for duality gap objective\n",
    "k_max = 2  # maximum multiplier for strategic bidding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input data transformation for Optimisation Problem "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gens\n",
    "gens_df = utils.create_gens_df(pp_units, dispatch_df)\n",
    "gens_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Sortiere nach marginalen Kosten (mc)\n",
    "gens_sorted = gens_df.sort_values(\"mc\").reset_index(drop=True)\n",
    "\n",
    "# Farben und Muster für die Balken\n",
    "color_map = {\n",
    "    \"uranium\": \"#99cccc\",\n",
    "    \"lignite\": \"#7fb3d5\",\n",
    "    \"hard coal\": \"#d5dbdb\",\n",
    "    \"natural gas\": \"#ffe680\",\n",
    "    \"learning unit\": \"#ffe680\",  # gleiche Farbe wie gas, aber mit Muster\n",
    "}\n",
    "hatch_map = {\n",
    "    \"learning unit\": \"//\",\n",
    "}\n",
    "\n",
    "# Linke Kante für jeden Balken\n",
    "left_edges = np.concatenate([[0], gens_sorted[\"g_max\"].cumsum()[:-1]])\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "bars = []\n",
    "labels = []\n",
    "for i, row in gens_sorted.iterrows():\n",
    "    # Fuel-Type bestimmen\n",
    "    if \"bidding_EOM\" in row and row[\"bidding_EOM\"] == \"pp_learning_single_bid\":\n",
    "        fuel = \"learning unit\"\n",
    "    else:\n",
    "        fuel = row[\"fuel_type\"]\n",
    "    color = color_map.get(fuel, \"#cccccc\")\n",
    "    hatch = hatch_map.get(fuel, None)\n",
    "    bar = plt.bar(\n",
    "        left_edges[i],\n",
    "        row[\"mc\"],\n",
    "        width=row[\"g_max\"],\n",
    "        align=\"edge\",\n",
    "        color=color,\n",
    "        edgecolor=\"black\",\n",
    "        hatch=hatch,\n",
    "        label=fuel if fuel not in labels else \"\",\n",
    "    )\n",
    "    bars.append(bar)\n",
    "    labels.append(fuel)\n",
    "\n",
    "# Legende manuell erstellen, damit jede Kategorie nur einmal erscheint\n",
    "handles = []\n",
    "legend_labels = []\n",
    "for fuel, color in color_map.items():\n",
    "    hatch = hatch_map.get(fuel, None)\n",
    "    handle = plt.Rectangle(\n",
    "        (0, 0), 1, 1, facecolor=color, edgecolor=\"black\", hatch=hatch\n",
    "    )\n",
    "    handles.append(handle)\n",
    "    legend_labels.append(fuel)\n",
    "\n",
    "plt.legend(handles, legend_labels, title=\"Fuel Type\", loc=\"upper right\")\n",
    "plt.xlabel(\"Power [MW]\")\n",
    "plt.ylabel(\"Marginal Costs [€/MWh]\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "plt.xlim(0, 15000)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translate actions of RL model into k_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge on both 'unit_id' and 'time' columns\n",
    "merged_df = sample_market_orders_df.merge(\n",
    "    sample_dispatch_df[[\"unit\", \"time\", \"marginal_cost\"]].reset_index(),\n",
    "    left_on=[\"unit_id\", \"start_time\"],\n",
    "    right_on=[\"unit\", \"time\"],\n",
    "    how=\"left\",\n",
    ")\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"bid_id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_df = merged_df[[\"unit_id\", \"time\", \"price\"]].copy()[\n",
    "    merged_df[\"unit_id\"] != \"demand_EOM\"\n",
    "]\n",
    "\n",
    "k_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values_df = utils.obtain_k_values(k_df, gens_df)\n",
    "k_values_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join demand and price bid\n",
    "\n",
    "Since assume has the problem that the market always starts at 1 instead of zero we need to equal the modelling times here to avoid problems. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop demand_df rows where start_time is not in sample_market_orders time column\n",
    "sample_demand_df = sample_demand_df[\n",
    "    sample_demand_df.index.isin(sample_market_orders_df.index)\n",
    "]\n",
    "\n",
    "demand_df = utils.join_demand_market_orders(sample_demand_df, sample_market_orders_df)\n",
    "demand_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run MPEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = pd.to_datetime(\"2019-03-01 01:00\")\n",
    "end = pd.to_datetime(\"2019-03-01 23:00\")\n",
    "index = pd.date_range(start, end, freq=\"h\")\n",
    "\n",
    "opt_name = \"pp_6\"\n",
    "# get index of opt_name from gens_df\n",
    "opt_gen = gens_df[gens_df[\"name\"] == opt_name].index[0]\n",
    "\n",
    "\n",
    "demand_df_short = demand_df.copy().loc[index]\n",
    "demand_df_short.drop(columns=[\"date\"], inplace=True)\n",
    "\n",
    "k_values_df_short = k_values_df.copy().loc[index]\n",
    "k_values_df_short.drop(columns=[\"date\"], inplace=True)\n",
    "\n",
    "profits_1, profits_2, results_2_1, results_2_2 = utils.run_MPEC(\n",
    "    opt_gen, gens_df, demand_df_short, k_values_df_short, k_max, big_w, demand_bids=3\n",
    ")\n",
    "\n",
    "print(\"\")\n",
    "print(\"Optimisation results:\")\n",
    "print(f\"Estimated Profits: {profits_1[opt_gen].sum():.2f}\")\n",
    "print(f\"True profits: {profits_2[opt_gen].sum():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution with find_optimal_dispatch_linearized\n",
    "\n",
    "Estimated Profits: 35736.88\n",
    "True profits: 27418.56\n",
    "\n",
    "-> verifiziert das nciht zu weit weg \n",
    "\n",
    "Dann habe ich jetzt auch noch viele demand bids eingeführt sorgt für wietere Abweichung:\n",
    "- Jede Demand-Stufe (Bid) bringt **2 zusätzliche Binärvariablen** in die Big-M-Linearisation:\n",
    "  - eine für die obere Schranke (\\(\\bar{\\mu}_k\\)),\n",
    "  - eine für die untere Schranke (\\(\\mu_k\\)).\n",
    "\n",
    "- Mehr Binaries ⇒ schwächere Relaxierung (LP)\n",
    "  → Das LP liegt „weiter weg“ vom echten MILP, weil mehr Freiheitsgrade existieren, die im Relax zwischen 0 und 1 „schweben“ dürfen.\n",
    "\n",
    "- Folge: die relaxierten Preise \\(\\hat{\\lambda}\\) können deutlich stärker abweichen,  \n",
    "  verglichen mit dem Fall mit nur wenigen Binaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get learning results\n",
    "sample_dispatch_df = sample_dispatch_df.set_index(\"time\")\n",
    "\n",
    "cashflow = sample_dispatch_df[\n",
    "    sample_dispatch_df[\"unit\"] == gens_df.loc[opt_gen][\"name\"]\n",
    "].loc[start:end][\"energy_cashflow\"]\n",
    "costs = sample_dispatch_df[\n",
    "    sample_dispatch_df[\"unit\"] == gens_df.loc[opt_gen][\"name\"]\n",
    "].loc[start:end][\"total_costs\"]\n",
    "\n",
    "profit = (cashflow - costs).sum()\n",
    "\n",
    "print(\"\")\n",
    "print(f\"Learning results {opt_name}:\")\n",
    "print(f\"Profits: {profit:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_name = gens_df.loc[opt_gen][\"name\"]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(results_2_1[f\"gen_{opt_gen}\"], label=\"MPEC Dispatch\")\n",
    "plt.plot(\n",
    "    sample_dispatch_df[sample_dispatch_df[\"unit\"] == unit_name][\"power\"]\n",
    "    .loc[start:end]\n",
    "    .values,\n",
    "    label=\"Learning Dispatch\",\n",
    ")\n",
    "plt.title(f\"Vergleich der Erzeugung für Einheit: {unit_name}\")\n",
    "plt.xlabel(\"Zeitindex\")\n",
    "plt.ylabel(\"Leistung [MW]\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_name = gens_df.loc[opt_gen][\"name\"]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(results_2_1[\"mcp\"], label=\"Diagonlised MPEC\")\n",
    "plt.plot(\n",
    "    sample_market_orders_df[sample_market_orders_df[\"unit_id\"] == unit_name][\n",
    "        \"accepted_price\"\n",
    "    ]\n",
    "    .loc[start:end]\n",
    "    .values,\n",
    "    label=\"Learning\",\n",
    ")\n",
    "plt.plot(equi, label=\"Equilibrium Price\", linestyle=\"--\", color=\"red\")\n",
    "\n",
    "# shade area between 3.5 and 4.5 on x axis with a vetrical box\n",
    "plt.axvspan(2.5, 7.5, color=\"red\", alpha=0.2, label=\"Problem Area\")\n",
    "plt.axvspan(12.5, 22, color=\"red\", alpha=0.2, label=\"Problem Area\")\n",
    "\n",
    "plt.title(f\"Market Prices for diaganolised unit: {unit_name}\")\n",
    "plt.xlabel(\"Zeitindex\")\n",
    "plt.ylabel(\"Preis [€/MWh]\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning in general does not manage to identify the hours in which all learning units would have market power. This is as expected shown by the the one peak in the price for example. \n",
    "\n",
    "This shit is super hard to interpret, actually in hour 4 pp_6 and the resulting market price is close for the diagonlisation and the learning outcome. Yet this is only the case because pp_7 is not acting \"optimal\". Shows quite good how any variation from the best-response actually does not let us judge wether we are in an equilibirum. \n",
    "\n",
    "If we want to compare them I'd say we need to show the market price variation across all unit diagonalisations. For pp_7 we would see the jump in timestep 4 upwards of the blue line as well. High variations of the price would therefore indicate that we are especially unsure if we find an equilibirum in these hours. As soon as we get the time coupling of storages though any deviation in hour also makes us question all other hours. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop over different units and weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: delete just here because it takes soooo long otherwise\n",
    "start = pd.to_datetime(\"2019-03-01 01:00\")\n",
    "end = pd.to_datetime(\"2019-03-01 23:00\")\n",
    "index = pd.date_range(start, end, freq=\"h\")\n",
    "\n",
    "rl_units = gens_df[gens_df[\"bidding_EOM\"] == \"pp_learning_single_bid\"][\"name\"].values\n",
    "opt_gens = sorted([int(unit.split(\"_\")[-1]) for unit in rl_units], key=int)\n",
    "\n",
    "# Get unique year-month combinations to filter for different weeks\n",
    "unique_year_months = set((date.year, date.month) for date in sampled_indices)\n",
    "\n",
    "df_estimated = pd.DataFrame(columns=[f\"Unit_{opt_gen}\" for opt_gen in opt_gens])\n",
    "df_true = pd.DataFrame(columns=[f\"Unit_{opt_gen}\" for opt_gen in opt_gens])\n",
    "df_mcp = pd.DataFrame(columns=[f\"Unit_{opt_gen}\" for opt_gen in opt_gens])\n",
    "\n",
    "for i, (year, month) in enumerate(unique_year_months):\n",
    "    filtered_indices = [\n",
    "        date for date in sampled_indices if date.year == year and date.month == month\n",
    "    ]\n",
    "    demand_df_filtered = (\n",
    "        demand_df.copy().loc[demand_df[\"date\"].isin(filtered_indices)].loc[index]\n",
    "    )  # TODO: DELETE second loc\n",
    "    demand_df_filtered.drop(columns=[\"date\"], inplace=True)\n",
    "\n",
    "    k_values_df_filtered = (\n",
    "        k_values_df.copy().loc[k_values_df[\"date\"].isin(filtered_indices)].loc[index]\n",
    "    )  # TODO: DELETE second loc\n",
    "    k_values_df_filtered.drop(columns=[\"date\"], inplace=True)\n",
    "    df_estimated_tmp = pd.DataFrame(columns=[f\"Unit_{opt_gen}\" for opt_gen in opt_gens])\n",
    "    df_true_tmp = pd.DataFrame(columns=[f\"Unit_{opt_gen}\" for opt_gen in opt_gens])\n",
    "    df_mcp_tmp = pd.DataFrame(columns=[f\"Unit_{opt_gen}\" for opt_gen in opt_gens])\n",
    "    for opt_gen in opt_gens:\n",
    "        print(\"We now optimize the decison for unit_\", opt_gen)\n",
    "        profits_1, profits_2, results_2_1, results_2_2 = utils.run_MPEC(\n",
    "            opt_gen - 1, gens_df, demand_df_filtered, k_values_df_filtered, k_max, big_w\n",
    "        )\n",
    "        df_estimated_tmp[f\"Unit_{opt_gen}\"] = profits_1[opt_gen - 1]\n",
    "        df_true_tmp[f\"Unit_{opt_gen}\"] = profits_2[opt_gen - 1]\n",
    "        df_mcp_tmp[f\"Unit_{opt_gen}\"] = results_2_1[\"mcp\"]\n",
    "    df_estimated = pd.concat([df_estimated, df_estimated_tmp])\n",
    "    df_true = pd.concat([df_true, df_true_tmp])\n",
    "    df_mcp = pd.concat([df_mcp, df_mcp_tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame zur Speicherung der Profite pro Unit\n",
    "df_rl = pd.DataFrame()\n",
    "\n",
    "# Über alle Units iterieren\n",
    "for opt_gen in gens_df.index:\n",
    "    unit_name = gens_df.loc[opt_gen][\"name\"]\n",
    "\n",
    "    # Cashflow und Kosten für die spezifische Unit und Zeitraum extrahieren\n",
    "    unit_data = sample_dispatch_df[sample_dispatch_df[\"unit\"] == unit_name]\n",
    "    cashflow = unit_data[\"energy_cashflow\"]\n",
    "    costs = unit_data[\"total_costs\"]\n",
    "\n",
    "    # Profit als Differenz\n",
    "    profit_series = cashflow - costs\n",
    "\n",
    "    # Ergebnisse in den DataFrame einfügen\n",
    "    df_rl[unit_name] = profit_series.reset_index(drop=True)\n",
    "\n",
    "    # rename pp_x columns zu unit_x columns\n",
    "    df_rl = df_rl.rename(\n",
    "        columns={col: col.replace(\"pp_\", \"Unit_\") for col in df_rl.columns}\n",
    "    )\n",
    "\n",
    "# drop all unit columns that are not in df_real columns\n",
    "df_rl = df_rl[df_true.columns]\n",
    "\n",
    "df_rl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only use hours 1 to 23 (assuming your data is ordered accordingly)\n",
    "hours = np.arange(1, 24)\n",
    "market_price_learning = sample_market_orders_df[\n",
    "    [\"accepted_price\", \"end_time\"]\n",
    "].drop_duplicates()[\"accepted_price\"]\n",
    "\n",
    "# MPEC market price: mean, min, max\n",
    "mcp_mean = df_mcp.mean(axis=1)\n",
    "mcp_min = df_mcp.min(axis=1)\n",
    "mcp_max = df_mcp.max(axis=1)\n",
    "\n",
    "\n",
    "# --- Highlight background regions ---\n",
    "plt.axvspan(1, 3.5, color=\"#e6ffe6\", alpha=0.5)\n",
    "plt.axvspan(3.5, 8.5, color=\"#fff5e6\", alpha=0.5)\n",
    "plt.axvspan(8.5, 13.5, color=\"#ffe6e6\", alpha=0.5)\n",
    "plt.axvspan(13.5, 23, color=\"#fff5e6\", alpha=0.5)\n",
    "\n",
    "# --- Plot lines ---\n",
    "plt.plot(hours, market_price_learning, label=\"Learning Market Price\", color=\"tab:blue\")\n",
    "plt.plot(hours, mcp_mean, label=\"MPEC Mean Market Price\", color=\"tab:orange\")\n",
    "plt.fill_between(\n",
    "    hours, mcp_min, mcp_max, color=\"tab:orange\", alpha=0.2, label=\"MPEC Min-Max Range\"\n",
    ")\n",
    "plt.plot(hours, equi, label=\"Equilibrium Price\", linestyle=\"--\", color=\"red\")\n",
    "\n",
    "plt.xlabel(\"Hour of Day\")\n",
    "plt.ylabel(\"Market Price [€/MWh]\")\n",
    "plt.xlim(1, 23)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "plt.grid(linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "# Add numbers to the colored regions INSIDE the plot area\n",
    "ymin, ymax = plt.ylim()\n",
    "plt.text(\n",
    "    2,\n",
    "    ymin + 0.92 * (ymax - ymin),\n",
    "    \"1\",\n",
    "    fontsize=18,\n",
    "    color=\"#74ff33\",\n",
    "    ha=\"center\",\n",
    "    va=\"top\",\n",
    "    alpha=0.7,\n",
    ")\n",
    "plt.text(\n",
    "    6,\n",
    "    ymin + 0.92 * (ymax - ymin),\n",
    "    \"2\",\n",
    "    fontsize=18,\n",
    "    color=\"#ff9900\",\n",
    "    ha=\"center\",\n",
    "    va=\"top\",\n",
    "    alpha=0.7,\n",
    ")\n",
    "plt.text(\n",
    "    11,\n",
    "    ymin + 0.92 * (ymax - ymin),\n",
    "    \"3\",\n",
    "    fontsize=18,\n",
    "    color=\"#cc3333\",\n",
    "    ha=\"center\",\n",
    "    va=\"top\",\n",
    "    alpha=0.7,\n",
    ")\n",
    "plt.text(\n",
    "    18,\n",
    "    ymin + 0.92 * (ymax - ymin),\n",
    "    \"2\",\n",
    "    fontsize=18,\n",
    "    color=\"#ff9900\",\n",
    "    ha=\"center\",\n",
    "    va=\"top\",\n",
    "    alpha=0.7,\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare sum per unit betwenn df_rl and df_true\n",
    "df_rl.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and show the plot\n",
    "# TODO: Use daily mean for plot\n",
    "fig = utils.plot_profit_comparison(df_rl, df_true)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assume-framework",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
