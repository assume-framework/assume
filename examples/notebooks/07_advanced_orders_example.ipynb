{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4JeBorbE6FYr"
   },
   "source": [
    "# 7. Using advanced orders: Effects of regular block orders and linked orders\n",
    "\n",
    "This tutorial describes a showcase [from the scientific paper \"Do Block Orders Matter? Impact of Regular Block and Linked Orders on Electricity Market Simulation Outcomes\"](link).\n",
    "\n",
    "In this publication the advanced strategies using regular block orders and linked orders are presented and their impact on the market outcome both on system and unit level discussed compared to strategies using only single hourly orders.\n",
    "\n",
    "With the integration of block orders, minimum acceptance ratios are added to the orders as additional field. To account for those in the clearing, a new market clearing algorithm becomes necessary.\n",
    "\n",
    "In this tutorial, we will show, how to create and integrate this advanced market clearing and adjust bidding strategies to allow the use of regular block orders and linked orders.\n",
    "Finally, we will create a small comparison study of the results using matplotlib.\n",
    "\n",
    "**As a whole, this tutorial covers the following**\n",
    "\n",
    "1. Explain the basic rules of block and linked orders.\n",
    "\n",
    "2. Run a small example with single hourly orders.\n",
    "\n",
    "3. Create the new market clearing algorithm.\n",
    "\n",
    "4. Adjust a given strategy to integrate block orders.\n",
    "\n",
    "5. Adjust a given strategy to integrate linked orders.\n",
    "\n",
    "6. Extract graphs from the simulation run and interpret results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OMvIl2xLVi1l"
   },
   "source": [
    "# 1. Basics\n",
    "\n",
    "In general, most simulation studies only focus on single hourly orders.\n",
    "Yet, the reality includes a lot more than that, especially different types of block orders.\n",
    "The question is, how much do the advanced order types deviate the market outcome.\n",
    "\n",
    "To showcase that ASSUME can handle different order types an advanced market clearing algorithm is created and tested with three different strategies.\n",
    "The testing scenarios are defined as 12 units (one for each technology) and an unflexible demand, cleared on a day-ahead market.\n",
    "\n",
    "**What are single hourly orders?**\n",
    "\n",
    "These are the simplest order structures implemented, also called simple orders. \n",
    "They can take the form of linear piece-wise curves containing interpolated orders only, step-wise curves containing step orders only, or a hybrid form of both. \n",
    "The general clearing of these orders strictly follows the merit order principle:\n",
    "any order with a bidding price below the MCP must be fully accepted, any order with a price above the MCP must be rejected, and orders where the price equals the MCP can be either accepted (fully/partially) or rejected.\n",
    "\n",
    "**What are block orders?**\n",
    "\n",
    "The characteristic of block orders is a time horizon that spans multiple minimum time units (MTUs). \n",
    "They are defined by a price, a number of time periods, some volumes that can be different for each period, and a constant minimum acceptance ratio (MAR). \n",
    "The MAR defines a restriction on how much a bid can be curtailed before it must be rejected. \n",
    "They can be divided into four subcategories:\n",
    "\n",
    "* **Independent block orders (BOs)**: \n",
    "The elemental form is the regular block order, with constant volume and a MAR equal to 1, also referred to as “fill-or-kill”-condition.\n",
    "This determines that the volume must be entirely accepted or rejected. \n",
    "This BO-type is used most frequently and applied in all European power exchanges [17] (source). \n",
    "Slight deviations are given with the curtailable BO, where the MAR can be below 1, and the profile BO, which includes volume changes over the block order periods.\n",
    "\n",
    "* **Linked groups or linked orders (LOs)**: \n",
    "These groups of orders include parent and dependent child orders with the additional condition that the acceptance ratio\n",
    "of a parent order must be greater or equal to those of all child orders. \n",
    "During market clearing, children are considered, if they increase the profit. \n",
    "Hence, they can “save” the parent order, but not vice versa. \n",
    "There can be several levels of LOs in one group, but the number of children and levels is constrained by the power exchanges.\n",
    "\n",
    "* **Exclusive groups**: \n",
    "For this order type, the sum of acceptance ratios of a set of block orders must be below 1. \n",
    "If the MAR is set to 1, this results in an exclusive-or-relation of all orders in that group.\n",
    "\n",
    "* **Flexible orders**: \n",
    "These order structures are created through the formation of an exclusive group where the MAR is set to 1 and each order is shifted by one hour, introducing flexibility through the dispatch time determined by the\n",
    "algorithm, not predefined by the participant.\n",
    "\n",
    "In this tutorial, we will compare the simple hourly orders with regular block orders and linked orders.\n",
    "\n",
    "**Bid formulation in this example**\n",
    "\n",
    "According to flexABLE, the inflexible and flexible power of a unit is bid seperately [compare the paper (link)].\n",
    "\n",
    "The inflexible power $P^{\\mathrm{inflex}}_{t}$ at time $t$ is the minimum volume that can by dispatched. \n",
    "It is defined by the current operation status of the unit, ramp-down limitations and the must-run time.\n",
    "The inflexible bid price depends on the marginal cost $C^{\\mathrm{marginal}}_t$ at time $t$ and the power dispatch of the previous time step $P^{\\mathrm{dispatch}}_{t-1}$ and adds a markup, if the unit has to be started newly and a reduction, to prevent a shut-down, including the start-up costs $C^{\\mathrm{su}}_t$.\n",
    "Here, the average time of continuous operation is given by $T^{\\mathrm{op, avg}}$ and the average time of continuous shut down is given by $T^{\\mathrm{down, avg}}$:\n",
    "\n",
    "$C^{\\mathrm{inflex}}_t=C^{\\mathrm{marginal}}_t + \\frac{C^{\\mathrm{su}}_t}{P^{\\mathrm{inflex}}_{t} T^{\\mathrm{op/down}}} \\: \\mathrm{with} T^{\\mathrm{op/down}} = \\begin{cases} -T^{\\mathrm{down, avg}}, & \\mathrm{if} \\: P^{\\mathrm{dispatch}}_{t-1} > 0 \\\\ T^{\\mathrm{op, avg}}, & \\mathrm{otherwise} \\end{cases} $.\n",
    "\n",
    "The flexible power $P^{\\mathrm{flex}}_{t}$ at time $t$ is then the difference between maximum dispatchable volume and the inflexible power. \n",
    "It is defined by current operation status of the unit, ramp-up limitations and the must-operation time.\n",
    "The flexible bidding price is given by the marginal costs only:\n",
    "\n",
    "$C^{\\mathrm{flex}}_t=C^{\\mathrm{marginal}}_t$.\n",
    "\n",
    "When transforming those bids into block orders, the volumes of the inflexible bids build the profile of one block bid over 24 hours.\n",
    "Because block orders are cleared according to the average market clearing price over the order period $\\mathcal{T}$, the price of the block order is given by the weighted average of the inflexible bid price:\n",
    "\n",
    "$C^{\\mathrm{block}} = \\frac{\\sum_{t \\in \\mathcal{T}} C^{\\mathrm{inflex}}_t \\: P^{\\mathrm{inflex}}_t}{\\sum_{t \\in \\mathcal{T}} P^{\\mathrm{inflex}}_t}$.\n",
    "\n",
    "The linked order are built by the flexible power for each hour and linked as children to the one block bid.\n",
    "They then use directly the flexible bid price $C^{\\mathrm{flex}}_t$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OeeZDtIFmmhn"
   },
   "source": [
    "## 2. Get ASSUME running\n",
    "Here we just install the ASSUME core package via pip - just as we did in the other tutorials. In general the instructions for an installation can be found here: https://assume.readthedocs.io/en/latest/installation.html. All the required steps are executed here and since we are working in colab the generation of a venv is not necessary.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m0DaRwFA7VgW",
    "outputId": "5655adad-5b7a-4fe3-9067-6b502a06136b",
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: assume-framework in c:\\users\\johanna\\appdata\\roaming\\python\\python311\\site-packages (0.2.1)\n",
      "Collecting windpowerlib@ git+https://github.com/maurerle/windpowerlib@maurerle (from assume-framework)\n",
      "  Cloning https://github.com/maurerle/windpowerlib (to revision maurerle) to c:\\users\\johanna\\appdata\\local\\temp\\pip-install-zmbwksuc\\windpowerlib_e3bbaffa2cb44dc1859aa240a7927309\n",
      "  Resolved https://github.com/maurerle/windpowerlib to commit d93c6656847d2e4e2c0c24e5b2b96184f2b8dc35\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: argcomplete<4.0.0,>=3.1.4 in c:\\users\\johanna\\appdata\\roaming\\python\\python311\\site-packages (from assume-framework) (3.2.1)\n",
      "Requirement already satisfied: demandlib<0.2.0,>=0.1.9 in c:\\users\\johanna\\appdata\\roaming\\python\\python311\\site-packages (from assume-framework) (0.1.9)\n",
      "Requirement already satisfied: holidays<0.38,>=0.37 in c:\\users\\johanna\\appdata\\roaming\\python\\python311\\site-packages (from assume-framework) (0.37)\n",
      "Requirement already satisfied: mango-agents-assume<2.0.0,>=1.1.1-8 in c:\\users\\johanna\\appdata\\roaming\\python\\python311\\site-packages (from assume-framework) (1.1.1.post8)\n",
      "Requirement already satisfied: mypy<2.0.0,>=1.1.1 in c:\\users\\johanna\\appdata\\roaming\\python\\python311\\site-packages (from assume-framework) (1.4.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.6 in c:\\users\\johanna\\appdata\\roaming\\python\\python311\\site-packages (from assume-framework) (1.5.6)\n",
      "Requirement already satisfied: paho-mqtt<2.0.0,>=1.5.1 in c:\\programdata\\anaconda3\\envs\\assume-framework\\lib\\site-packages (from assume-framework) (1.5.1)\n",
      "Requirement already satisfied: pandas<3.0.0,>=2.0.0 in c:\\users\\johanna\\appdata\\roaming\\python\\python311\\site-packages (from assume-framework) (2.0.3)\n",
      "Requirement already satisfied: psycopg2-binary<3.0.0,>=2.9.5 in c:\\programdata\\anaconda3\\envs\\assume-framework\\lib\\site-packages (from assume-framework) (2.9.6)\n",
      "Requirement already satisfied: pvlib<0.11.0,>=0.10.2 in c:\\users\\johanna\\appdata\\roaming\\python\\python311\\site-packages (from assume-framework) (0.10.3)\n",
      "Requirement already satisfied: pyomo<7.0.0,>=6.6.1 in c:\\users\\johanna\\appdata\\roaming\\python\\python311\\site-packages (from assume-framework) (6.6.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in c:\\users\\johanna\\appdata\\roaming\\python\\python311\\site-packages (from assume-framework) (2.8.2)\n",
      "Requirement already satisfied: pyyaml<7.0,>=6.0 in c:\\users\\johanna\\appdata\\roaming\\python\\python311\\site-packages (from assume-framework) (6.0)\n",
      "Requirement already satisfied: pyyaml-include<2.0.0,>=1.3.1 in c:\\users\\johanna\\appdata\\roaming\\python\\python311\\site-packages (from assume-framework) (1.3.2)\n",
      "Requirement already satisfied: sqlalchemy<3.0.0,>=2.0.9 in c:\\programdata\\anaconda3\\envs\\assume-framework\\lib\\site-packages (from assume-framework) (2.0.12)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.64.1 in c:\\programdata\\anaconda3\\envs\\assume-framework\\lib\\site-packages (from assume-framework) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\programdata\\anaconda3\\envs\\assume-framework\\lib\\site-packages (from demandlib<0.2.0,>=0.1.9->assume-framework) (1.24.3)\n",
      "Requirement already satisfied: dill>=0.3.6 in c:\\users\\johanna\\appdata\\roaming\\python\\python311\\site-packages (from mango-agents-assume<2.0.0,>=1.1.1-8->assume-framework) (0.3.6)\n",
      "Requirement already satisfied: msgspec>=0.14.2 in c:\\users\\johanna\\appdata\\roaming\\python\\python311\\site-packages (from mango-agents-assume<2.0.0,>=1.1.1-8->assume-framework) (0.18.2)\n",
      "Requirement already satisfied: protobuf<4.0.0,>=3.20.3 in c:\\users\\johanna\\appdata\\roaming\\python\\python311\\site-packages (from mango-agents-assume<2.0.0,>=1.1.1-8->assume-framework) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\programdata\\anaconda3\\envs\\assume-framework\\lib\\site-packages (from mypy<2.0.0,>=1.1.1->assume-framework) (4.5.0)\n",
      "Requirement already satisfied: mypy-extensions>=1.0.0 in c:\\users\\johanna\\appdata\\roaming\\python\\python311\\site-packages (from mypy<2.0.0,>=1.1.1->assume-framework) (1.0.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\envs\\assume-framework\\lib\\site-packages (from pandas<3.0.0,>=2.0.0->assume-framework) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\programdata\\anaconda3\\envs\\assume-framework\\lib\\site-packages (from pandas<3.0.0,>=2.0.0->assume-framework) (2023.3)\n",
      "Requirement already satisfied: requests in c:\\users\\johanna\\appdata\\roaming\\python\\python311\\site-packages (from pvlib<0.11.0,>=0.10.2->assume-framework) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\johanna\\appdata\\roaming\\python\\python311\\site-packages (from pvlib<0.11.0,>=0.10.2->assume-framework) (1.11.3)\n",
      "Requirement already satisfied: h5py in c:\\users\\johanna\\appdata\\roaming\\python\\python311\\site-packages (from pvlib<0.11.0,>=0.10.2->assume-framework) (3.10.0)\n",
      "Requirement already satisfied: ply in c:\\programdata\\anaconda3\\envs\\assume-framework\\lib\\site-packages (from pyomo<7.0.0,>=6.6.1->assume-framework) (3.11)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\johanna\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil<3.0.0,>=2.8.2->assume-framework) (1.16.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\programdata\\anaconda3\\envs\\assume-framework\\lib\\site-packages (from sqlalchemy<3.0.0,>=2.0.9->assume-framework) (2.0.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\johanna\\appdata\\roaming\\python\\python311\\site-packages (from tqdm<5.0.0,>=4.64.1->assume-framework) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\johanna\\appdata\\roaming\\python\\python311\\site-packages (from requests->pvlib<0.11.0,>=0.10.2->assume-framework) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\johanna\\appdata\\roaming\\python\\python311\\site-packages (from requests->pvlib<0.11.0,>=0.10.2->assume-framework) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\johanna\\appdata\\roaming\\python\\python311\\site-packages (from requests->pvlib<0.11.0,>=0.10.2->assume-framework) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\envs\\assume-framework\\lib\\site-packages (from requests->pvlib<0.11.0,>=0.10.2->assume-framework) (2023.7.22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/maurerle/windpowerlib 'C:\\Users\\Johanna\\AppData\\Local\\Temp\\pip-install-zmbwksuc\\windpowerlib_e3bbaffa2cb44dc1859aa240a7927309'\n",
      "  Running command git checkout -b maurerle --track origin/maurerle\n",
      "  branch 'maurerle' set up to track 'origin/maurerle'.\n",
      "  Switched to a new branch 'maurerle'\n"
     ]
    }
   ],
   "source": [
    "!pip install assume-framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we run in Google Colab, we need to first clone the ASSUME repository there to access the tutorial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/assume-framework/assume.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IIw_QIE3pY34"
   },
   "source": [
    "And easy like this we have ASSUME installed. Now we can let it run. Please note though that we cannot use the functionalities tied to docker and, hence, cannot access the predefined dashboards in colab. For this please install docker and ASSUME on your personal machine.\n",
    "\n",
    "To run the examples, we still need some packages imports and configure a database server URI - you can adjust this if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3eVM60Qx8SC0",
    "outputId": "20434515-6e65-4d34-d44d-8c4529a46ece"
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import yaml\n",
    "\n",
    "from assume import World\n",
    "from assume.scenario.loader_csv import load_scenario_folder\n",
    "\n",
    "# make sure that you have a database server up and running - preferabely in docker\n",
    "# DB_URI = \"postgresql://assume:assume@localhost:5432/assume\"\n",
    "# but you can use a file-based sqlite database too:\n",
    "DB_URI = \"sqlite:///./examples/local_db/assume_db_example_07.db\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let the magic happen.** Now you can run your first ever simulation in ASSUME. The following code navigates to the respective assume folder and starts the simulation example example_01b using the local database here in colab.\n",
    "\n",
    "When running locally, you can also just run `assume -s example_01b -db \"sqlite:///./examples/local_db/assume_db_example_01b.db\"` in a shell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!cd assume && assume -s example_01b -db \"sqlite:///./examples/local_db/assume_db_example_01b.db\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install jdc for some in line magic, that allows us defining functions of classes across different cells.\n",
    "We further need pyomo to create an optimization model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!pip install jdc\n",
    "!pip install pyomo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Market clearing algorithm\n",
    "\n",
    "To integrate block and linked orders, the market clearing becomes a mixed-integer linear problem (MILP).\n",
    "In addition to the volumes and prices, we now need to knwo the bid type, minimum acceptance ratio for all orders and the parent bid id in case it is a linke bid.\n",
    "\n",
    "Those additional fields then have to be added in the market clearing:\n",
    "* \"bid_type\" defines the order structure and can be \"SB\" for single hourly orders (Simple Bid), \"BB\" for block orders (Block Bid) or \"LB\" for linked orders (Linked Bid).\n",
    "* \"min_acceptance_ratio\" defines how much a bid can be curtailed before it is rejected. If it is set to 1, the bid is either accepted or rejected  with it's full volume.\n",
    "* \"parent_bid_id\" is needed to include linked bids. Here the id of the parent order is defined, where the child order is linked to.\n",
    "The market clearing algorithm then ensures, that the minimum acceptance ratio of the child order is less or equal to the one of its parent order.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First a few imports to use existing functions we do not change:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import jdc\n",
    "from datetime import timedelta\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "import pyomo.environ as pyo\n",
    "from pyomo.opt import SolverFactory, TerminationCondition, check_available_solvers\n",
    "\n",
    "\n",
    "from assume.common.market_objects import MarketConfig, MarketProduct, Orderbook\n",
    "from assume.markets.base_market import MarketRole\n",
    "from assume.markets.clearing_algorithms.complex_clearing import (\n",
    "    extract_results,\n",
    "    calculate_order_surplus,\n",
    "    validate_orderbook,\n",
    ")\n",
    "\n",
    "log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we specify the optimization problem as an MILP.\n",
    "\n",
    "Read the comments in the following function and understand what is happening in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOLVERS = [\"gurobi\", \"glpk\"]\n",
    "EPS = 1e-4\n",
    "\n",
    "def market_clearing_opt(orders, market_products, mode, with_linked_bids):\n",
    "    \"\"\"\n",
    "    Sets up and solves the market clearing optimization problem.\n",
    "\n",
    "    Args:\n",
    "        orders (Orderbook): The list of the orders.\n",
    "        market_products (list[MarketProduct]): The products to be traded.\n",
    "        mode (str): The mode of the market clearing determining whether the minimum acceptance ratio is considered.\n",
    "        with_linked_bids (bool): Whether the market clearing should include linked bids.\n",
    "\n",
    "    Returns:\n",
    "        tuple[pyomo.ConcreteModel, pyomo.opt.results.SolverResults]: The solved pyomo model and the solver results.\n",
    "    \"\"\"\n",
    "    # initiate the pyomo model\n",
    "    model = pyo.ConcreteModel()\n",
    "    # add dual suffix to the model (we need this to extract the market clearing prices later)\n",
    "    model.dual = pyo.Suffix(direction=pyo.Suffix.IMPORT_EXPORT)\n",
    "\n",
    "    # add sets for the orders, timesteps, and bids, to specify the indexes for the decision variables\n",
    "    model.T = pyo.Set(\n",
    "        initialize=[market_product[0] for market_product in market_products],\n",
    "        doc=\"timesteps\",\n",
    "    )\n",
    "    model.sBids = pyo.Set(\n",
    "        initialize=[order[\"bid_id\"] for order in orders if order[\"bid_type\"] == \"SB\"],\n",
    "        doc=\"simple_bids\",\n",
    "    )\n",
    "    model.bBids = pyo.Set(\n",
    "        initialize=[\n",
    "            order[\"bid_id\"] for order in orders if order[\"bid_type\"] in [\"BB\", \"LB\"]\n",
    "        ],\n",
    "        doc=\"block_bids\",\n",
    "    )\n",
    "\n",
    "    # decision variables: the acceptance ratio of simple bids\n",
    "    model.xs = pyo.Var(\n",
    "        model.sBids,\n",
    "        domain=pyo.NonNegativeReals,\n",
    "        bounds=(0, 1),\n",
    "        doc=\"simple_bid_acceptance\",\n",
    "    )\n",
    "    # decision variables: the acceptance ratio of block bids (including linked bids)\n",
    "    model.xb = pyo.Var(\n",
    "        model.bBids,\n",
    "        domain=pyo.NonNegativeReals,\n",
    "        bounds=(0, 1),\n",
    "        doc=\"block_bid_acceptance\",\n",
    "    )\n",
    "\n",
    "    # if the mode is 'with_min_acceptance_ratio', add the binary decision variables for the acceptance\n",
    "    # and the minimum acceptance ratio constraints\n",
    "    if mode == \"with_min_acceptance_ratio\":\n",
    "        # add set for all bids, since the minimum acceptance ratio constraints are defined for all bids\n",
    "        model.Bids = pyo.Set(\n",
    "            initialize=[order[\"bid_id\"] for order in orders], doc=\"all_bids\"\n",
    "        )\n",
    "        # decision variables for the acceptance as binary variable\n",
    "        model.x = pyo.Var(\n",
    "            model.Bids,\n",
    "            domain=pyo.Binary,\n",
    "            doc=\"bid_accepted\",\n",
    "        )\n",
    "\n",
    "        # add minimum acceptance ratio constraints\n",
    "        \"\"\"\n",
    "        Minimum acceptance constraints are defined as:\n",
    "        acceptance ratio (decision variable) >= min_acceptance_ratio * acceptance (binary decision variable)\n",
    "        acceptance ratio (decision variable) <= acceptance (binary decision variable)\n",
    "        \"\"\"\n",
    "        model.mar_constr = pyo.ConstraintList()\n",
    "        for order in orders:\n",
    "            if order[\"min_acceptance_ratio\"] is None:\n",
    "                continue\n",
    "            \n",
    "            elif order[\"bid_type\"] == \"SB\":\n",
    "                model.mar_constr.add(\n",
    "                    model.xs[order[\"bid_id\"]]\n",
    "                    >= order[\"min_acceptance_ratio\"] * model.x[order[\"bid_id\"]]\n",
    "                )\n",
    "                model.mar_constr.add(\n",
    "                    model.xs[order[\"bid_id\"]] <= model.x[order[\"bid_id\"]]\n",
    "                )\n",
    "\n",
    "            elif order[\"bid_type\"] in [\"BB\", \"LB\"]:\n",
    "                model.mar_constr.add(\n",
    "                    model.xb[order[\"bid_id\"]]\n",
    "                    >= order[\"min_acceptance_ratio\"] * model.x[order[\"bid_id\"]]\n",
    "                )\n",
    "                model.mar_constr.add(\n",
    "                    model.xb[order[\"bid_id\"]] <= model.x[order[\"bid_id\"]]\n",
    "                )\n",
    "    # add energy balance constraint\n",
    "    \"\"\"\n",
    "    Energy balance is defined as:\n",
    "    sum over all orders of (acceptance reatio (decision variable) * offered volume) = 0\n",
    "    \"\"\"            \n",
    "    balance_expr = {t: 0.0 for t in model.T}\n",
    "    for order in orders:\n",
    "        if order[\"bid_type\"] == \"SB\":\n",
    "            balance_expr[order[\"start_time\"]] += (\n",
    "                order[\"volume\"] * model.xs[order[\"bid_id\"]]\n",
    "            )\n",
    "        elif order[\"bid_type\"] in [\"BB\", \"LB\"]:\n",
    "            for start_time, volume in order[\"volume\"].items():\n",
    "                balance_expr[start_time] += volume * model.xb[order[\"bid_id\"]]\n",
    "\n",
    "    def energy_balance_rule(m, t):\n",
    "        return balance_expr[t] == 0\n",
    "\n",
    "    model.energy_balance = pyo.Constraint(model.T, rule=energy_balance_rule)\n",
    "\n",
    "    # limit the acceptance of child bids by the acceptance of their parent bid\n",
    "    \"\"\"\n",
    "    The linked bid constraints are defined as:\n",
    "    acceptance ratio of child bid (decision variable) <= acceptance ratio of parent bid (decision variable)\n",
    "    \"\"\"\n",
    "    if with_linked_bids:\n",
    "        model.linked_bid_constr = pyo.ConstraintList()\n",
    "        for order in orders:\n",
    "            if \"parent_bid_id\" in order.keys() and order[\"parent_bid_id\"] is not None:\n",
    "                parent_bid_id = order[\"parent_bid_id\"]\n",
    "                model.linked_bid_constr.add(\n",
    "                    model.xb[order[\"bid_id\"]] <= model.xb[parent_bid_id]\n",
    "                )\n",
    "\n",
    "    # define the objective function as cost minimization\n",
    "    \"\"\"\n",
    "    The objective function is defined as:\n",
    "    sum over all orders of (price * volume * acceptance ratio (decision variable))\n",
    "    The sense of the objective function is minimize.\n",
    "    \"\"\"\n",
    "    obj_expr = 0\n",
    "    for order in orders:\n",
    "        if order[\"bid_type\"] == \"SB\":\n",
    "            obj_expr += order[\"price\"] * order[\"volume\"] * model.xs[order[\"bid_id\"]]\n",
    "        elif order[\"bid_type\"] in [\"BB\", \"LB\"]:\n",
    "            for start_time, volume in order[\"volume\"].items():\n",
    "                obj_expr += order[\"price\"] * volume * model.xb[order[\"bid_id\"]]\n",
    "\n",
    "    model.objective = pyo.Objective(expr=obj_expr, sense=pyo.minimize)\n",
    "\n",
    "    # check available solvers, gurobi is preferred\n",
    "    solvers = check_available_solvers(*SOLVERS)\n",
    "    if len(solvers) < 1:\n",
    "        raise Exception(f\"None of {SOLVERS} are available\")\n",
    "\n",
    "    solver = SolverFactory(solvers[0])\n",
    "\n",
    "    if solver.name == \"gurobi\":\n",
    "        options = {\"cutoff\": -1.0, \"eps\": EPS}\n",
    "    elif solver.name == \"cplex\":\n",
    "        options = {\n",
    "            \"mip.tolerances.lowercutoff\": -1.0,\n",
    "            \"mip.tolerances.absmipgap\": EPS,\n",
    "        }\n",
    "    elif solver.name == \"cbc\":\n",
    "        options = {\"sec\": 60, \"ratio\": 0.1}\n",
    "    else:\n",
    "        options = {}\n",
    "\n",
    "    # Solve the model\n",
    "    instance = model.create_instance()\n",
    "    results = solver.solve(instance, options=options)\n",
    "\n",
    "    \"\"\"\n",
    "    After solving the model, \n",
    "    fix the acceptance of each order to the value in the solution and \n",
    "    solve the model again as simple linear problem.\n",
    "    This is necessary to get dual variables.\n",
    "    \"\"\"\n",
    "    # fix all model.x to the values in the solution\n",
    "    if mode == \"with_min_acceptance_ratio\":\n",
    "        for bid_id in instance.Bids:\n",
    "            instance.x[bid_id].fix(instance.x[bid_id].value)\n",
    "\n",
    "        # resolve the model\n",
    "        results = solver.solve(instance, options=options)\n",
    "\n",
    "    return instance, results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this function defines how the objective is solved. Let's create the market clearing algorithm as a MarketRole in the ASSUME framework.\n",
    "\n",
    "First, we define the class ComplexClearRole and initiate it.\n",
    "Since the \"bid_type\" is not an optional parameter in the orders (as seen from the function above), we also add the function validate_orderbook() to check, whether only allowed bid types are used in the orderbook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedClearingRole(MarketRole):\n",
    "\n",
    "    # here we need to define the additionally required fields\n",
    "    # but because the minimum acceptance ratio and the parent id has to be specified only for some orders,\n",
    "    # we only use bid_type as required field\n",
    "    required_fields = [\"bid_type\"]\n",
    "\n",
    "    def __init__(self, marketconfig: MarketConfig):\n",
    "        super().__init__(marketconfig)\n",
    "\n",
    "    # to assure that the orders use the allowed bid types, we can use the following function\n",
    "    def validate_orderbook(self, orderbook: Orderbook, agent_tuple) -> None:\n",
    "        \"\"\"\n",
    "        Validates the orderbook. Here we use the predefined function validate_orderbook, \n",
    "        if you want to take a closer look, please refer to our documentation.\n",
    "        \"\"\"\n",
    "        validate_orderbook(orderbook, agent_tuple)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we specifiy the main function to clear the market using the function market_clearing_opt() to calculate the market outcome as optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# magic to enable class definitions across colab cells\n",
    "%%add_to AdvancedClearingRole\n",
    "\n",
    "def clear(\n",
    "        self, orderbook: Orderbook, market_products\n",
    "    ) -> (Orderbook, Orderbook, list[dict]):\n",
    "        \"\"\"\n",
    "        Implements pay-as-clear with more complex bid structures, including acceptance ratios, bid types, and profiled volumes.\n",
    "\n",
    "        Args:\n",
    "            orderbook (Orderbook): The orderbook to be cleared.\n",
    "            market_products (list[MarketProduct]): The products to be traded.\n",
    "\n",
    "        Raises:\n",
    "            Exception: If the problem is infeasible.\n",
    "\n",
    "        Returns:\n",
    "            accepted_orders (Orderbook): The accepted orders.\n",
    "            rejected_orders (Orderbook): The rejected orders.\n",
    "            meta (list[dict]): The market clearing results.\n",
    "        \"\"\"\n",
    "\n",
    "        if len(orderbook) == 0:\n",
    "            return [], [], []\n",
    "\n",
    "        orderbook.sort(key=itemgetter(\"start_time\", \"end_time\", \"only_hours\"))\n",
    "\n",
    "        # create a list of all orders linked as child to a bid\n",
    "        # this helps to late check the surplus for linked bids\n",
    "        child_orders = []\n",
    "        for order in orderbook:\n",
    "            order[\"accepted_price\"] = {}\n",
    "            order[\"accepted_volume\"] = {}\n",
    "            # get child linked bids\n",
    "            if \"parent_bid_id\" in order.keys() and order[\"parent_bid_id\"] is not None:\n",
    "                # check whether the parent bid is in the orderbook\n",
    "                parent_bid_id = order[\"parent_bid_id\"]\n",
    "                parent_bid = next(\n",
    "                    (bid for bid in orderbook if bid[\"bid_id\"] == parent_bid_id), None\n",
    "                )\n",
    "                if parent_bid is None:\n",
    "                    order[\"parent_bid_id\"] = None\n",
    "                    log.warning(f\"Parent bid {parent_bid_id} not in orderbook\")\n",
    "                else:\n",
    "                    child_orders.append(order)\n",
    "\n",
    "        with_linked_bids = bool(child_orders)\n",
    "        rejected_orders: Orderbook = []\n",
    "\n",
    "        # check whether the minimum acceptance ratio is specified\n",
    "        mode = \"default\"\n",
    "        if \"min_acceptance_ratio\" in self.marketconfig.additional_fields:\n",
    "            mode = \"with_min_acceptance_ratio\"\n",
    "\n",
    "        # solve the market clearing problem\n",
    "        while True:\n",
    "            # solve the optimization with the current orderbook\n",
    "            instance, results = market_clearing_opt(\n",
    "                orders=orderbook,\n",
    "                market_products=market_products,\n",
    "                mode=mode,\n",
    "                with_linked_bids=with_linked_bids,\n",
    "            )\n",
    "\n",
    "            if results.solver.termination_condition == TerminationCondition.infeasible:\n",
    "                raise Exception(\"infeasible\")\n",
    "\n",
    "            # extract dual from model.energy_balance\n",
    "            market_clearing_prices = {\n",
    "                t: instance.dual[instance.energy_balance[t]] for t in instance.T\n",
    "            }\n",
    "\n",
    "            # check the surplus of each order and remove those with negative surplus\n",
    "            orders_surplus = []\n",
    "            for order in orderbook:\n",
    "                children = []\n",
    "                if with_linked_bids:\n",
    "                    # get all children of the current order\n",
    "                    children = [\n",
    "                        child\n",
    "                        for child in child_orders\n",
    "                        if child[\"parent_bid_id\"] == order[\"bid_id\"]\n",
    "                    ]\n",
    "\n",
    "                # here we use the predefined fluction calculate_order_surplus,\n",
    "                # the surplus is given as (market_clearing_price - order_price) * order_volume\n",
    "                # the surplus of children is added to the surplus of the parent bid if positive\n",
    "                order_surplus = calculate_order_surplus(\n",
    "                    order, market_clearing_prices, instance, children\n",
    "                )\n",
    "\n",
    "                # correct rounding\n",
    "                if order_surplus != 0 and abs(order_surplus) < EPS:\n",
    "                    order_surplus = 0\n",
    "\n",
    "                orders_surplus.append(order_surplus)\n",
    "\n",
    "                # remove orders with negative profit\n",
    "                if order_surplus < 0:\n",
    "                    rejected_orders.append(order)\n",
    "                    orderbook.remove(order)\n",
    "                    rejected_orders.extend(children)\n",
    "                    for child in children:\n",
    "                        orderbook.remove(child)\n",
    "\n",
    "            # check if all orders have positive surplus\n",
    "            if all(order_surplus >= 0 for order_surplus in orders_surplus):\n",
    "                break\n",
    "        \n",
    "        # here we use the predefined function extract_results,\n",
    "        # it returns the accepted and rejected orders, and the market meta data for each timestep\n",
    "        # if you want to take a closer look, please refer to our documentation.\n",
    "        return extract_results(\n",
    "            model=instance,\n",
    "            orders=orderbook,\n",
    "            rejected_orders=rejected_orders,\n",
    "            market_products=market_products,\n",
    "            market_clearing_prices=market_clearing_prices,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 24 single market product which have a duration of one hour.\n",
    "And every time the market opens, the next 24 hours can be traded (see count).\n",
    "The first delivery of the market is 24 hours after the opening of the market (to have some spare time before delivery).\n",
    "So this market mechansm can be added to world in the following manner: First, we specify the market_config and then save it in out example config.yaml.\n",
    "\n",
    "The market configuration given in the config.yaml does not change over the different scenarios, because we use the same market setting as day-ahead market (dam) with all additional fields required for block and linked orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_config = MarketConfig(\n",
    "    \"name\": \"EOM_dam\",\n",
    "    \"product_type\": \"energy\",\n",
    "    \"market_products\":\n",
    "    {\n",
    "        \"duration\": \"1h\",\n",
    "        \"count\": 24,\n",
    "        \"first_delivery\": \"24h\"\n",
    "    },\n",
    "    \"opening_frequency\": \"24h\",\n",
    "    \"opening_duration\": \"24h\",\n",
    "    \"volume_unit\": \"MWh\",\n",
    "    \"maximum_bid_volume\": 100000,\n",
    "    \"maximum_bid_price\": 3000,\n",
    "    \"minimum_bid_price\": -500,\n",
    "    \"price_unit\": \"EUR/MWh\",\n",
    "    \"market_mechanism\": \"pay_as_clear_advanced\",\n",
    "    \"additional_fields\":\n",
    "    {\n",
    "        \"bid_type\",\n",
    "        \"min_acceptance_ratio\",\n",
    "        \"parent_bid_id\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the YAML file\n",
    "with open(\"assume/examples/inputs/example_07_sho/config.yaml\", \"r\") as file:\n",
    "    data = yaml.safe_load(file)\n",
    "\n",
    "# store our modifications to the config file in all scenarios\n",
    "data[\"sho_case\"][\"markets_config\"] = market_config  # sho = single hourly orders\n",
    "data[\"bo_case\"][\"markets_config\"] = market_config   # bo = block orders\n",
    "data[\"lo_case\"][\"markets_config\"] = market_config   # lo = linked orders\n",
    "\n",
    "# Write the modified data back to the file\n",
    "with open(\"assume/examples/inputs/example_07/config.yaml\", \"w\") as file:\n",
    "    yaml.safe_dump(data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So lets add the advanced clearing algorithm to the possible clearing mechanisms in world and load the modified example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world = World(database_uri=DB_URI)\n",
    "\n",
    "world.clearing_mechanisms[\"pay_as_clear_advanced\"] = AdvancedClearingRole\n",
    "\n",
    "load_scenario_folder(\n",
    "    world,\n",
    "    inputs_path=\"assume/examples/inputs\",\n",
    "    scenario=\"example_07\",\n",
    "    study_case=\"sho_case\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check the used strategy, we can access the unit over the unit operator in world:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.unit_operators[\"CCGT_unit_operator\"].units[\"CCGT_unit\"].bidding_strategies['energy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This strategy is based on flexABLE and only uses single hourly orders for flexable and inflexale power as described before.\n",
    "\n",
    "Now we run the actual simulation with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading and running the scenario with the clearing mechanism implemented in ASSUME can also be done using the following CLI tool call in colab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The system cannot find the path specified.\n"
     ]
    }
   ],
   "source": [
    "!cd assume && assume -s example_07 -c sho_case -db \"sqlite:///./examples/local_db/assume_db_example_07.db\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Block orders\n",
    "\n",
    "Now we can create a new strategy, which transforms the inflexible bids into one block order over the whole 24 hour-clearing horizon.\n",
    "\n",
    "For this we copy the flexable strategy and modify it (marked with # ====== new)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import the functions, which we do not change:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from assume.strategies.flexable import (\n",
    "    calculate_EOM_price_if_off,\n",
    "    calculate_EOM_price_if_on,\n",
    "    calculate_reward_EOM,\n",
    ")\n",
    "from assume.common.base import (\n",
    "    BaseStrategy,\n",
    "    SupportsMinMax,\n",
    ")\n",
    "from assume.common.market_objects import Product, Orderbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class blockStrategy(BaseStrategy):\n",
    "    \"\"\"\n",
    "    A strategy that bids on the EOM-market with block bids.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        # check if kwargs contains eom_foresight argument\n",
    "        self.foresight = pd.Timedelta(kwargs.get(\"eom_foresight\", \"12h\"))\n",
    "\n",
    "    def calculate_bids(\n",
    "        self,\n",
    "        unit: SupportsMinMax,\n",
    "        market_config: MarketConfig,\n",
    "        product_tuples: list[Product],\n",
    "        **kwargs,\n",
    "    ) -> Orderbook:\n",
    "        \"\"\"\n",
    "        Calculates block bids for the EOM-market and returns a list of bids consisting of the start time, end time, only hours, price, volume and bid type.\n",
    "\n",
    "        The bids take the following form:\n",
    "        One block bid with the minimum acceptance ratio set to 1 spanning the total clearing period. \n",
    "        It uses the inflexible power and the weighted average price of the inflexible power as the price.\n",
    "        This price is based on the marginal cost of the inflexible power and the starting costs.\n",
    "        The starting costs are split across inflexible power and the average operation or down time of the unit depending on the operation status before.\n",
    "        Additionally, for every hour where the unit is on, a separate flexible bid is created using the flexible power and marginal costs as bidding price.\n",
    "\n",
    "        Args:\n",
    "            unit (SupportsMinMax): A unit that the unit operator manages.\n",
    "            market_config (MarketConfig): A market configuration.\n",
    "            product_tuples (list[Product]): A list of tuples containing the start and end time of each product.\n",
    "            kwargs (dict): Additional arguments.\n",
    "\n",
    "        Returns:\n",
    "            Orderbook: A list of bids.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        start = product_tuples[0][0]\n",
    "        end = product_tuples[-1][1]\n",
    "\n",
    "        previous_power = unit.get_output_before(start)\n",
    "        min_power, max_power = unit.calculate_min_max_power(start, end)\n",
    "\n",
    "        bids = []\n",
    "        op_time = unit.get_operation_time(start)\n",
    "        avg_op_time, avg_down_time = unit.get_average_operation_times(start)\n",
    "        \n",
    "        # we need to store the bid quantity for each hour \n",
    "        # and the bid price to calculate the weighted average\n",
    "        bid_quantity_block = {}                                     # ====== new\n",
    "        bid_price_block = []                                        # ====== new\n",
    "        \n",
    "\n",
    "        for product in product_tuples:\n",
    "            bid_quantity_flex, bid_price_flex = 0, 0\n",
    "            bid_price_inflex, bid_quantity_inflex = 0, 0\n",
    "\n",
    "            start = product[0]\n",
    "            end = product[1]\n",
    "\n",
    "            # =============================================================================\n",
    "            # Powerplant is either on, or is able to turn on\n",
    "            # Calculating possible bid amount and cost\n",
    "            # =============================================================================\n",
    "\n",
    "            current_power = unit.outputs[\"energy\"].at[start]\n",
    "\n",
    "            # adjust max_power for ramp speed\n",
    "            max_power[start] = unit.calculate_ramp(\n",
    "                op_time, previous_power, max_power[start], current_power\n",
    "            )\n",
    "            # adjust min_power for ramp speed\n",
    "            min_power[start] = unit.calculate_ramp(\n",
    "                op_time, previous_power, min_power[start], current_power\n",
    "            )\n",
    "\n",
    "            bid_quantity_inflex = min_power[start]\n",
    "\n",
    "            # =============================================================================\n",
    "            # Calculating marginal cost\n",
    "            # =============================================================================\n",
    "\n",
    "            marginal_cost_inflex = unit.calculate_marginal_cost(\n",
    "                start, current_power + bid_quantity_inflex\n",
    "            )\n",
    "            marginal_cost_flex = unit.calculate_marginal_cost(\n",
    "                start, current_power + max_power[start]\n",
    "            )\n",
    "\n",
    "            # =============================================================================\n",
    "            # Calculating possible price\n",
    "            # =============================================================================\n",
    "            if op_time > 0:\n",
    "                bid_price_inflex = calculate_EOM_price_if_on(\n",
    "                    unit,\n",
    "                    start,\n",
    "                    marginal_cost_flex,\n",
    "                    bid_quantity_inflex,\n",
    "                    self.foresight,\n",
    "                    avg_down_time,\n",
    "                )\n",
    "            else:\n",
    "                bid_price_inflex = calculate_EOM_price_if_off(\n",
    "                    unit,\n",
    "                    marginal_cost_inflex,\n",
    "                    bid_quantity_inflex,\n",
    "                    op_time,\n",
    "                    avg_op_time,\n",
    "                )\n",
    "\n",
    "            if unit.outputs[\"heat\"][start] > 0:\n",
    "                power_loss_ratio = (\n",
    "                    unit.outputs[\"power_loss\"][start] / unit.outputs[\"heat\"][start]\n",
    "                )\n",
    "            else:\n",
    "                power_loss_ratio = 0.0\n",
    "\n",
    "            # Flex-bid price formulation\n",
    "            if op_time <= -unit.min_down_time or op_time > 0:\n",
    "                bid_quantity_flex = max_power[start] - bid_quantity_inflex\n",
    "                bid_price_flex = (1 - power_loss_ratio) * marginal_cost_flex\n",
    "        \n",
    "            # add volume and price to block bid\n",
    "            bid_quantity_block[product[0]] = bid_quantity_inflex    # ====== new\n",
    "            if bid_quantity_inflex > 0:                             # ====== new\n",
    "                bid_price_block.append(bid_price_inflex)            # ====== new\n",
    "            \n",
    "            # add the flexible bid  \n",
    "            bids.append(                                            # ====== new                                        \n",
    "                {\n",
    "                    \"start_time\": start,                            # ====== new\n",
    "                    \"end_time\": end,                                # ====== new\n",
    "                    \"only_hours\": None,                             # ====== new                 \n",
    "                    \"price\": bid_price_flex,                        # ====== new        \n",
    "                    \"volume\": bid_quantity_flex,                    # ====== new                \n",
    "                    \"bid_type\": \"SB\",                               # ====== new\n",
    "                },\n",
    "            )\n",
    "            # calculate previous power with planned dispatch (bid_quantity)\n",
    "            previous_power = bid_quantity_inflex + bid_quantity_flex + current_power\n",
    "            op_time = max(op_time, 0) + 1 if previous_power > 0 else min(op_time, 0) - 1\n",
    "\n",
    "        # calculate weighted average of prices\n",
    "        volume = 0                                                  # ====== new\n",
    "        price = 0                                                   # ====== new                                           \n",
    "        for i in range(len(bid_price_block)):                       # ====== new           \n",
    "            price += bid_price_block[i] * list(bid_quantity_block.values())[i]      # ====== new\n",
    "            volume += list(bid_quantity_block.values())[i]          # ====== new\n",
    "        mean_price = price / volume                                 # ====== new\n",
    "\n",
    "        # add block bid\n",
    "        bids.append(                                                # ====== new\n",
    "            {   \n",
    "                \"start_time\": product_tuples[0][0],                 # ====== new     \n",
    "                \"end_time\": product_tuples[-1][1],                  # ====== new\n",
    "                \"only_hours\": product_tuples[0][2],                 # ====== new         \n",
    "                \"price\": mean_price,                                # ====== new            \n",
    "                \"volume\": bid_quantity_block,                       # ====== new   \n",
    "                \"bid_type\": \"BB\",                                   # ====== new       \n",
    "                \"min_acceptance_ratio\": 1,                          # ====== new\n",
    "                \"accepted_volume\": {product[0]: 0 for product in product_tuples}, # ====== new\n",
    "            }\n",
    "        )\n",
    "\n",
    "        return bids\n",
    "\n",
    "    def calculate_reward(\n",
    "            self,\n",
    "            unit,\n",
    "            marketconfig: MarketConfig,\n",
    "            orderbook: Orderbook,\n",
    "        ):\n",
    "            \"\"\"\n",
    "            Calculates and writes the reward (costs and profit).\n",
    "\n",
    "            Args:\n",
    "                unit (SupportsMinMax): A unit that the unit operator manages.\n",
    "                marketconfig (MarketConfig): A market configuration.\n",
    "                orderbook (Orderbook): An orderbook with accepted and rejected orders for the unit.\n",
    "            \"\"\"\n",
    "            # TODO: Calculate profits over all markets\n",
    "\n",
    "            calculate_reward_EOM(\n",
    "                unit=unit,\n",
    "                marketconfig=marketconfig,\n",
    "                orderbook=orderbook,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this the strategy is ready to test.\n",
    "As before, we add the new class to our world and load the scenario.\n",
    "Additionally, we now have to change the set bidding strategy for one example unit. Here we choose the combined cycle gas turbine and set its strategy to our modified class 'blockStrategy'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world = World(database_uri=DB_URI)\n",
    "\n",
    "world.bidding_strategies[\"block_strategy\"] = blockStrategy\n",
    "\n",
    "load_scenario_folder(\n",
    "    world,\n",
    "    inputs_path=\"examples/inputs\",\n",
    "    scenario=\"example_07\",\n",
    "    study_case=\"bo_case\",\n",
    ")\n",
    "\n",
    "world.unit_operators[\"CCGT_unit_operator\"].units[\"CCGT_unit\"].bidding_strategies['energy'] = \"block_strategy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets run this example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or use the CLI as shown:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!cd assume && assume -s example_07 -c bo_case -db \"sqlite:///./examples/local_db/assume_db_example_07.db\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Linked orders\n",
    "\n",
    "In the same way, we can further adjust the block bid strategy to integrate the flexible bids as linked bids. Deviations to blockStrategy are marked with # ====== new:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class linkedStrategy(BaseStrategy):\n",
    "    \"\"\"\n",
    "    A strategy that bids on the EOM-market with block and linked bids.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        # check if kwargs contains eom_foresight argument\n",
    "        self.foresight = pd.Timedelta(kwargs.get(\"eom_foresight\", \"12h\"))\n",
    "\n",
    "    def calculate_bids(\n",
    "        self,\n",
    "        unit: SupportsMinMax,\n",
    "        market_config: MarketConfig,\n",
    "        product_tuples: list[Product],\n",
    "        **kwargs,\n",
    "    ) -> Orderbook:\n",
    "        \"\"\"\n",
    "        Calculates block and linked bids for the EOM-market and returns a list of bids consisting of the start time, end time, only hours, price, volume and bid type.\n",
    "\n",
    "        The bids take the following form:\n",
    "        One block bid with the minimum acceptance ratio set to 1 spanning the total clearing period.\n",
    "        It uses the inflexible power and the weighted average price of the inflexible power as the price.\n",
    "        This price is based on the marginal cost of the inflexible power and the starting costs.\n",
    "        The starting costs are split across inflexible power and the average operation or down time of the unit depending on the operation status before.\n",
    "        Additionally, for every hour where the unit is on, a separate flexible bid is created using the flexible power and marginal costs as bidding price.\n",
    "        This bids are linked as children to the block bid.\n",
    "\n",
    "        Args:\n",
    "            unit (SupportsMinMax): A unit that the unit operator manages.\n",
    "            market_config (MarketConfig): A market configuration.\n",
    "            product_tuples (list[Product]): A list of tuples containing the start and end time of each product.\n",
    "            kwargs (dict): Additional arguments.\n",
    "\n",
    "        Returns:\n",
    "            Orderbook: A list of bids.\n",
    "        \"\"\"\n",
    "        start = product_tuples[0][0]\n",
    "        end = product_tuples[-1][1]\n",
    "\n",
    "        previous_power = unit.get_output_before(start)\n",
    "        min_power, max_power = unit.calculate_min_max_power(start, end)\n",
    "\n",
    "        bids = []\n",
    "        op_time = unit.get_operation_time(start)\n",
    "        avg_op_time, avg_down_time = unit.get_average_operation_times(start)\n",
    "\n",
    "        # we need to store the bid quantity for each hour \n",
    "        # and the bid price to calculate the weighted average\n",
    "        bid_quantity_block = {}\n",
    "        bid_price_block = []\n",
    "\n",
    "        # create a unique id for the block bid to link the flexible bids\n",
    "        block_id = unit.id + \"_block\"                               # ====== new\n",
    "\n",
    "        for product in product_tuples:\n",
    "            bid_quantity_flex, bid_price_flex = 0, 0\n",
    "            bid_price_inflex, bid_quantity_inflex = 0, 0\n",
    "\n",
    "            start = product[0]\n",
    "            end = product[1]\n",
    "\n",
    "            # =============================================================================\n",
    "            # Powerplant is either on, or is able to turn on\n",
    "            # Calculating possible bid amount and cost\n",
    "            # =============================================================================\n",
    "\n",
    "            current_power = unit.outputs[\"energy\"].at[start]\n",
    "\n",
    "            # adjust max_power for ramp speed\n",
    "            max_power[start] = unit.calculate_ramp(\n",
    "                op_time, previous_power, max_power[start], current_power\n",
    "            )\n",
    "            # adjust min_power for ramp speed\n",
    "            min_power[start] = unit.calculate_ramp(\n",
    "                op_time, previous_power, min_power[start], current_power\n",
    "            )\n",
    "\n",
    "            bid_quantity_inflex = min_power[start]\n",
    "\n",
    "            # =============================================================================\n",
    "            # Calculating marginal cost\n",
    "            # =============================================================================\n",
    "\n",
    "            marginal_cost_inflex = unit.calculate_marginal_cost(\n",
    "                start, current_power + bid_quantity_inflex\n",
    "            )\n",
    "            marginal_cost_flex = unit.calculate_marginal_cost(\n",
    "                start, current_power + max_power[start]\n",
    "            )\n",
    "\n",
    "            # =============================================================================\n",
    "            # Calculating possible price\n",
    "            # =============================================================================\n",
    "            if op_time > 0:\n",
    "                bid_price_inflex = calculate_EOM_price_if_on(\n",
    "                    unit,\n",
    "                    start,\n",
    "                    marginal_cost_flex,\n",
    "                    bid_quantity_inflex,\n",
    "                    self.foresight,\n",
    "                    avg_down_time,\n",
    "                )\n",
    "            else:\n",
    "                bid_price_inflex = calculate_EOM_price_if_off(\n",
    "                    unit,\n",
    "                    marginal_cost_inflex,\n",
    "                    bid_quantity_inflex,\n",
    "                    op_time,\n",
    "                    avg_op_time,\n",
    "                )\n",
    "\n",
    "            if unit.outputs[\"heat\"][start] > 0:\n",
    "                power_loss_ratio = (\n",
    "                    unit.outputs[\"power_loss\"][start] / unit.outputs[\"heat\"][start]\n",
    "                )\n",
    "            else:\n",
    "                power_loss_ratio = 0.0\n",
    "\n",
    "            # Flex-bid price formulation\n",
    "            if op_time <= -unit.min_down_time or op_time > 0:\n",
    "                bid_quantity_flex = max_power[start] - bid_quantity_inflex\n",
    "                bid_price_flex = (1 - power_loss_ratio) * marginal_cost_flex\n",
    "\n",
    "            bid_quantity_block[product[0]] = bid_quantity_inflex\n",
    "            if bid_quantity_inflex > 0:\n",
    "                bid_price_block.append(bid_price_inflex)\n",
    "                # use block id as parent id for flexible bids\n",
    "                parent_id = block_id                                # ====== new\n",
    "            else:\n",
    "                # if the bid quantity is 0, the bid is not linked to the block bid\n",
    "                parent_id = None                                    # ====== new\n",
    "\n",
    "            # add the flexible bid as linked bid\n",
    "            bids.append(\n",
    "                {\n",
    "                    \"start_time\": start,\n",
    "                    \"end_time\": end,\n",
    "                    \"only_hours\": None,\n",
    "                    \"price\": bid_price_flex,\n",
    "                    \"volume\": {start: bid_quantity_flex},           # ====== new\n",
    "                    \"bid_type\": \"LB\",                               # ====== new\n",
    "                    \"parent_bid_id\": parent_id,                     # ====== new\n",
    "                },\n",
    "            )\n",
    "            # calculate previous power with planned dispatch (bid_quantity)\n",
    "            previous_power = bid_quantity_inflex + bid_quantity_flex + current_power\n",
    "            op_time = max(op_time, 0) + 1 if previous_power > 0 else min(op_time, 0) - 1\n",
    "\n",
    "        # calculate weighted average of prices\n",
    "        volume = 0\n",
    "        price = 0\n",
    "        for i in range(len(bid_price_block)):\n",
    "            price += bid_price_block[i] * list(bid_quantity_block.values())[i]\n",
    "            volume += list(bid_quantity_block.values())[i]\n",
    "        mean_price = price / volume\n",
    "\n",
    "        # add block bid\n",
    "        bids.append(\n",
    "            {\n",
    "                \"start_time\": product_tuples[0][0],\n",
    "                \"end_time\": product_tuples[-1][1],\n",
    "                \"only_hours\": product_tuples[0][2],\n",
    "                \"price\": mean_price,\n",
    "                \"volume\": bid_quantity_block,\n",
    "                \"bid_type\": \"BB\",\n",
    "                \"min_acceptance_ratio\": 1,\n",
    "                \"accepted_volume\": {product[0]: 0 for product in product_tuples},\n",
    "                \"bid_id\": block_id,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        return bids\n",
    "\n",
    "    def calculate_reward(\n",
    "        self,\n",
    "        unit,\n",
    "        marketconfig: MarketConfig,\n",
    "        orderbook: Orderbook,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Calculates and writes the reward (costs and profit).\n",
    "\n",
    "        Args:\n",
    "            unit (SupportsMinMax): A unit that the unit operator manages.\n",
    "            marketconfig (MarketConfig): A market configuration.\n",
    "            orderbook (Orderbook): An orderbook with accepted and rejected orders for the unit.\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: Calculate profits over all markets\n",
    "\n",
    "        calculate_reward_EOM(\n",
    "            unit=unit,\n",
    "            marketconfig=marketconfig,\n",
    "            orderbook=orderbook,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we now add the new class linkedStrategy to our available bidding_strategies, load our scenario and the change the bidding strategy of the CCGT unit to \"linked_strategy\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world = World(database_uri=DB_URI)\n",
    "\n",
    "world.bidding_strategies[\"linked_strategy\"] = linkedStrategy\n",
    "\n",
    "load_scenario_folder(\n",
    "    world,\n",
    "    inputs_path=\"examples/inputs\",\n",
    "    scenario=\"example_07\",\n",
    "    study_case=\"lo_case\",\n",
    ")\n",
    "\n",
    "world.unit_operators[\"CCGT_unit_operator\"].units[\"CCGT_unit\"].bidding_strategies['energy'] = \"linked_strategy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run this version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or use the CLI as shown:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!cd assume && assume -s example_07 -c lo_case -db \"sqlite:///./examples/local_db/assume_db_example_07.db\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize the results\n",
    "\n",
    "We can visualize the results using the following functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "(sqlite3.OperationalError) unable to open database file\n(Background on this error at: https://sqlalche.me/e/20/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:145\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[1;34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbapi_connection \u001b[38;5;241m=\u001b[39m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m dialect\u001b[38;5;241m.\u001b[39mloaded_dbapi\u001b[38;5;241m.\u001b[39mError \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:3288\u001b[0m, in \u001b[0;36mEngine.raw_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3267\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a \"raw\" DBAPI connection from the connection pool.\u001b[39;00m\n\u001b[0;32m   3268\u001b[0m \n\u001b[0;32m   3269\u001b[0m \u001b[38;5;124;03mThe returned object is a proxied version of the DBAPI\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3286\u001b[0m \n\u001b[0;32m   3287\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m-> 3288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:452\u001b[0m, in \u001b[0;36mPool.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a DBAPI connection from the pool.\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \n\u001b[0;32m    447\u001b[0m \u001b[38;5;124;03mThe connection is instrumented such that when its\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    450\u001b[0m \n\u001b[0;32m    451\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 452\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionFairy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_checkout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:1268\u001b[0m, in \u001b[0;36m_ConnectionFairy._checkout\u001b[1;34m(cls, pool, threadconns, fairy)\u001b[0m\n\u001b[0;32m   1267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fairy:\n\u001b[1;32m-> 1268\u001b[0m     fairy \u001b[38;5;241m=\u001b[39m \u001b[43m_ConnectionRecord\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m threadconns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:716\u001b[0m, in \u001b[0;36m_ConnectionRecord.checkout\u001b[1;34m(cls, pool)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 716\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\pool\\impl.py:168\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m--> 168\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msafe_reraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dec_overflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\util\\langhelpers.py:147\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[1;34m(self, type_, value, traceback)\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[1;32m--> 147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\pool\\impl.py:166\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:393\u001b[0m, in \u001b[0;36mPool._create_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Called by subclasses to create a new ConnectionRecord.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionRecord\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:678\u001b[0m, in \u001b[0;36m_ConnectionRecord.__init__\u001b[1;34m(self, pool, connect)\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connect:\n\u001b[1;32m--> 678\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalize_callback \u001b[38;5;241m=\u001b[39m deque()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:902\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 902\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msafe_reraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    903\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mError on connect(): \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\util\\langhelpers.py:147\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[1;34m(self, type_, value, traceback)\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[1;32m--> 147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:898\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    897\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstarttime \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdbapi_connection \u001b[38;5;241m=\u001b[39m connection \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    899\u001b[0m pool\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreated new connection \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, connection)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\engine\\create.py:637\u001b[0m, in \u001b[0;36mcreate_engine.<locals>.connect\u001b[1;34m(connection_record)\u001b[0m\n\u001b[0;32m    635\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m connection\n\u001b[1;32m--> 637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:616\u001b[0m, in \u001b[0;36mDefaultDialect.connect\u001b[1;34m(self, *cargs, **cparams)\u001b[0m\n\u001b[0;32m    614\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mcargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcparams):\n\u001b[0;32m    615\u001b[0m     \u001b[38;5;66;03m# inherits the docstring from interfaces.Dialect.connect\u001b[39;00m\n\u001b[1;32m--> 616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloaded_dbapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOperationalError\u001b[0m: unable to open database file",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 13\u001b[0m\n\u001b[0;32m      1\u001b[0m engine \u001b[38;5;241m=\u001b[39m create_engine(DB_URI)\n\u001b[0;32m      3\u001b[0m sql \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124mSELECT ident, simulation,\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124msum(round(CAST(value AS numeric), 2))  FILTER (WHERE variable = \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_cost\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m) as total_cost,\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124mgroup by simulation, ident ORDER BY simulation\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m---> 13\u001b[0m kpis \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m kpis[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_volume\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e9\u001b[39m\n\u001b[0;32m     15\u001b[0m kpis[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_cost\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e6\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\sql.py:633\u001b[0m, in \u001b[0;36mread_sql\u001b[1;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize, dtype_backend, dtype)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_backend \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[0;32m    631\u001b[0m     dtype_backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mpandasSQL_builder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcon\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[0;32m    634\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pandas_sql, SQLiteDatabase):\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql\u001b[38;5;241m.\u001b[39mread_query(\n\u001b[0;32m    636\u001b[0m             sql,\n\u001b[0;32m    637\u001b[0m             index_col\u001b[38;5;241m=\u001b[39mindex_col,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    643\u001b[0m             dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    644\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\sql.py:832\u001b[0m, in \u001b[0;36mpandasSQL_builder\u001b[1;34m(con, schema, need_transaction)\u001b[0m\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing URI string without sqlalchemy installed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    831\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sqlalchemy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(con, (\u001b[38;5;28mstr\u001b[39m, sqlalchemy\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39mConnectable)):\n\u001b[1;32m--> 832\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSQLDatabase\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneed_transaction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    834\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    835\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas only supports SQLAlchemy connectable (engine/connection) or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    836\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatabase string URI or sqlite3 DBAPI2 connection. Other DBAPI2 \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    839\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    840\u001b[0m )\n\u001b[0;32m    841\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m SQLiteDatabase(con)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\sql.py:1539\u001b[0m, in \u001b[0;36mSQLDatabase.__init__\u001b[1;34m(self, con, schema, need_transaction)\u001b[0m\n\u001b[0;32m   1537\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexit_stack\u001b[38;5;241m.\u001b[39mcallback(con\u001b[38;5;241m.\u001b[39mdispose)\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(con, Engine):\n\u001b[1;32m-> 1539\u001b[0m     con \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexit_stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[43mcon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1540\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m need_transaction \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m con\u001b[38;5;241m.\u001b[39min_transaction():\n\u001b[0;32m   1541\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexit_stack\u001b[38;5;241m.\u001b[39menter_context(con\u001b[38;5;241m.\u001b[39mbegin())\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:3264\u001b[0m, in \u001b[0;36mEngine.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Connection:\n\u001b[0;32m   3242\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a new :class:`_engine.Connection` object.\u001b[39;00m\n\u001b[0;32m   3243\u001b[0m \n\u001b[0;32m   3244\u001b[0m \u001b[38;5;124;03m    The :class:`_engine.Connection` acts as a Python context manager, so\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3261\u001b[0m \n\u001b[0;32m   3262\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3264\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:147\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[1;34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbapi_connection \u001b[38;5;241m=\u001b[39m engine\u001b[38;5;241m.\u001b[39mraw_connection()\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m dialect\u001b[38;5;241m.\u001b[39mloaded_dbapi\u001b[38;5;241m.\u001b[39mError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 147\u001b[0m         \u001b[43mConnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_dbapi_exception_noconnection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m            \u001b[49m\u001b[43merr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2426\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception_noconnection\u001b[1;34m(cls, e, dialect, engine, is_disconnect, invalidate_pool_on_disconnect, is_pre_ping)\u001b[0m\n\u001b[0;32m   2424\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[0;32m   2425\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2426\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception\u001b[38;5;241m.\u001b[39mwith_traceback(exc_info[\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   2427\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2428\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:145\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[1;34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbapi_connection \u001b[38;5;241m=\u001b[39m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m dialect\u001b[38;5;241m.\u001b[39mloaded_dbapi\u001b[38;5;241m.\u001b[39mError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    147\u001b[0m         Connection\u001b[38;5;241m.\u001b[39m_handle_dbapi_exception_noconnection(\n\u001b[0;32m    148\u001b[0m             err, dialect, engine\n\u001b[0;32m    149\u001b[0m         )\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:3288\u001b[0m, in \u001b[0;36mEngine.raw_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraw_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PoolProxiedConnection:\n\u001b[0;32m   3267\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a \"raw\" DBAPI connection from the connection pool.\u001b[39;00m\n\u001b[0;32m   3268\u001b[0m \n\u001b[0;32m   3269\u001b[0m \u001b[38;5;124;03m    The returned object is a proxied version of the DBAPI\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3286\u001b[0m \n\u001b[0;32m   3287\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3288\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:452\u001b[0m, in \u001b[0;36mPool.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PoolProxiedConnection:\n\u001b[0;32m    445\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a DBAPI connection from the pool.\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \n\u001b[0;32m    447\u001b[0m \u001b[38;5;124;03m    The connection is instrumented such that when its\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    450\u001b[0m \n\u001b[0;32m    451\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 452\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionFairy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_checkout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:1268\u001b[0m, in \u001b[0;36m_ConnectionFairy._checkout\u001b[1;34m(cls, pool, threadconns, fairy)\u001b[0m\n\u001b[0;32m   1259\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m   1260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_checkout\u001b[39m(\n\u001b[0;32m   1261\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1264\u001b[0m     fairy: Optional[_ConnectionFairy] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1265\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _ConnectionFairy:\n\u001b[0;32m   1267\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fairy:\n\u001b[1;32m-> 1268\u001b[0m         fairy \u001b[38;5;241m=\u001b[39m \u001b[43m_ConnectionRecord\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1270\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m threadconns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1271\u001b[0m             threadconns\u001b[38;5;241m.\u001b[39mcurrent \u001b[38;5;241m=\u001b[39m weakref\u001b[38;5;241m.\u001b[39mref(fairy)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:716\u001b[0m, in \u001b[0;36m_ConnectionRecord.checkout\u001b[1;34m(cls, pool)\u001b[0m\n\u001b[0;32m    714\u001b[0m     rec \u001b[38;5;241m=\u001b[39m cast(_ConnectionRecord, pool\u001b[38;5;241m.\u001b[39m_do_get())\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 716\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    719\u001b[0m     dbapi_connection \u001b[38;5;241m=\u001b[39m rec\u001b[38;5;241m.\u001b[39mget_connection()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\pool\\impl.py:168\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection()\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m--> 168\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msafe_reraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dec_overflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\util\\langhelpers.py:147\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[1;34m(self, type_, value, traceback)\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[1;32m--> 147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\pool\\impl.py:166\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inc_overflow():\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 166\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    168\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:393\u001b[0m, in \u001b[0;36mPool._create_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ConnectionPoolEntry:\n\u001b[0;32m    391\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Called by subclasses to create a new ConnectionRecord.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 393\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionRecord\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:678\u001b[0m, in \u001b[0;36m_ConnectionRecord.__init__\u001b[1;34m(self, pool, connect)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__pool \u001b[38;5;241m=\u001b[39m pool\n\u001b[0;32m    677\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connect:\n\u001b[1;32m--> 678\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalize_callback \u001b[38;5;241m=\u001b[39m deque()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:902\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    900\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfresh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 902\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msafe_reraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    903\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mError on connect(): \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    904\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    905\u001b[0m     \u001b[38;5;66;03m# in SQLAlchemy 1.4 the first_connect event is not used by\u001b[39;00m\n\u001b[0;32m    906\u001b[0m     \u001b[38;5;66;03m# the engine, so this will usually not be set\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\util\\langhelpers.py:147\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[1;34m(self, type_, value, traceback)\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[1;32m--> 147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:898\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    896\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    897\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstarttime \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 898\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdbapi_connection \u001b[38;5;241m=\u001b[39m connection \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    899\u001b[0m     pool\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreated new connection \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, connection)\n\u001b[0;32m    900\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfresh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\engine\\create.py:637\u001b[0m, in \u001b[0;36mcreate_engine.<locals>.connect\u001b[1;34m(connection_record)\u001b[0m\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    635\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m connection\n\u001b[1;32m--> 637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:616\u001b[0m, in \u001b[0;36mDefaultDialect.connect\u001b[1;34m(self, *cargs, **cparams)\u001b[0m\n\u001b[0;32m    614\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mcargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcparams):\n\u001b[0;32m    615\u001b[0m     \u001b[38;5;66;03m# inherits the docstring from interfaces.Dialect.connect\u001b[39;00m\n\u001b[1;32m--> 616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloaded_dbapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOperationalError\u001b[0m: (sqlite3.OperationalError) unable to open database file\n(Background on this error at: https://sqlalche.me/e/20/e3q8)"
     ]
    }
   ],
   "source": [
    "engine = create_engine(DB_URI)\n",
    "\n",
    "sql = \"\"\"\n",
    "SELECT ident, simulation,\n",
    "sum(round(CAST(value AS numeric), 2))  FILTER (WHERE variable = 'total_cost') as total_cost,\n",
    "sum(round(CAST(value AS numeric), 2)*1000)  FILTER (WHERE variable = 'total_volume') as total_volume,\n",
    "sum(round(CAST(value AS numeric), 2))  FILTER (WHERE variable = 'avg_price') as average_cost\n",
    "FROM kpis\n",
    "where variable in ('total_cost', 'total_volume', 'avg_price')\n",
    "and simulation in ('example_07_sho_case', 'example_07_bo_case', 'example_07_lo_case')\n",
    "group by simulation, ident ORDER BY simulation\n",
    "\"\"\"\n",
    "kpis = pd.read_sql(sql, engine)\n",
    "kpis[\"total_volume\"] /= 1e9\n",
    "kpis[\"total_cost\"] /= 1e6\n",
    "savefig = partial(plt.savefig, transparent=False, bbox_inches=\"tight\")\n",
    "\n",
    "## Data preparation\n",
    "sho = kpis[kpis[\"simulation\"] == \"example_07_sho_case\"]\n",
    "bo = kpis[kpis[\"simulation\"] == \"example_07_bo_case\"].reset_index()\n",
    "lo = kpis[kpis[\"simulation\"] == \"example_07_lo_case\"].reset_index()\n",
    "xticks = list(sho[\"simulation\"])\n",
    "# xlabels = [f\"{i}%\" for i in range(0, 101, 10)]\n",
    "xlabels = [\"SHO\", \"BO\", \"LO\"]\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "# Total Dispatch cost\n",
    "ax1.bar(sho[\"simulation\"], sho[\"total_cost\"], label=\"SHO\")\n",
    "ax1.bar(\n",
    "    bo[\"simulation\"],\n",
    "    bo[\"total_cost\"],\n",
    "    label=\"BO\",\n",
    ")\n",
    "ax1.bar(\n",
    "    lo[\"simulation\"],\n",
    "    lo[\"total_cost\"],\n",
    "    label=\"LO\",\n",
    ")\n",
    "ax1.set_ylabel(\"Total dispatch cost \\n per market [mill. $€$]\")\n",
    "ax1.set_xticks(xticks, xlabels)\n",
    "ax1.legend()\n",
    "# Total Average Cost\n",
    "ax2.scatter(sho[\"simulation\"], sho[\"average_price\"], label=\"SHO\")\n",
    "ax2.scatter(bo[\"simulation\"], bo[\"average_price\"], label=\"BO\")\n",
    "ax2.scatter(lo[\"simulation\"], lo[\"average_price\"], label=\"LO\")\n",
    "#ax2.bar(eom[\"simulation\"], eom[\"total_cost\"] * 0)\n",
    "ax2.set_ylabel(\"Average cost \\n for each scenario [$€/MWh$]\")\n",
    "# ax2.set_xlabel(\"Fraction of base load traded on LTM in percent\")\n",
    "ax2.set_xlabel(\"Selected electricity market design\")\n",
    "ax2.set_xticks(xticks, xlabels)\n",
    "ax2.legend()\n",
    "savefig(\"overview-cost.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first plot, we can see, that the total costs and average prices differ between the cases.\n",
    "Because the bidding prices are formed using the same rules, it was expected, that the introduction of new order types with additional restrictions increase prices and costs, as shown in this plot.\n",
    "\n",
    "\n",
    "Now we create the second plot, showing the accepted volumes for the different simulations for the combined cycle gas turbine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qoWI_agIJOE4",
    "outputId": "9b40e670-bfef-4560-d6e8-61a1b29d1975"
   },
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "(sqlite3.OperationalError) unable to open database file\n(Background on this error at: https://sqlalche.me/e/20/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:145\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[1;34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbapi_connection \u001b[38;5;241m=\u001b[39m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m dialect\u001b[38;5;241m.\u001b[39mloaded_dbapi\u001b[38;5;241m.\u001b[39mError \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:3288\u001b[0m, in \u001b[0;36mEngine.raw_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3267\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a \"raw\" DBAPI connection from the connection pool.\u001b[39;00m\n\u001b[0;32m   3268\u001b[0m \n\u001b[0;32m   3269\u001b[0m \u001b[38;5;124;03mThe returned object is a proxied version of the DBAPI\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3286\u001b[0m \n\u001b[0;32m   3287\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m-> 3288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:452\u001b[0m, in \u001b[0;36mPool.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a DBAPI connection from the pool.\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \n\u001b[0;32m    447\u001b[0m \u001b[38;5;124;03mThe connection is instrumented such that when its\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    450\u001b[0m \n\u001b[0;32m    451\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 452\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionFairy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_checkout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:1268\u001b[0m, in \u001b[0;36m_ConnectionFairy._checkout\u001b[1;34m(cls, pool, threadconns, fairy)\u001b[0m\n\u001b[0;32m   1267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fairy:\n\u001b[1;32m-> 1268\u001b[0m     fairy \u001b[38;5;241m=\u001b[39m \u001b[43m_ConnectionRecord\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m threadconns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:716\u001b[0m, in \u001b[0;36m_ConnectionRecord.checkout\u001b[1;34m(cls, pool)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 716\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\pool\\impl.py:168\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m--> 168\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msafe_reraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dec_overflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\util\\langhelpers.py:147\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[1;34m(self, type_, value, traceback)\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[1;32m--> 147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\pool\\impl.py:166\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:393\u001b[0m, in \u001b[0;36mPool._create_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Called by subclasses to create a new ConnectionRecord.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionRecord\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:678\u001b[0m, in \u001b[0;36m_ConnectionRecord.__init__\u001b[1;34m(self, pool, connect)\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connect:\n\u001b[1;32m--> 678\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalize_callback \u001b[38;5;241m=\u001b[39m deque()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:902\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 902\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msafe_reraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    903\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mError on connect(): \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\util\\langhelpers.py:147\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[1;34m(self, type_, value, traceback)\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[1;32m--> 147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:898\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    897\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstarttime \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdbapi_connection \u001b[38;5;241m=\u001b[39m connection \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    899\u001b[0m pool\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreated new connection \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, connection)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\engine\\create.py:637\u001b[0m, in \u001b[0;36mcreate_engine.<locals>.connect\u001b[1;34m(connection_record)\u001b[0m\n\u001b[0;32m    635\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m connection\n\u001b[1;32m--> 637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:616\u001b[0m, in \u001b[0;36mDefaultDialect.connect\u001b[1;34m(self, *cargs, **cparams)\u001b[0m\n\u001b[0;32m    614\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mcargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcparams):\n\u001b[0;32m    615\u001b[0m     \u001b[38;5;66;03m# inherits the docstring from interfaces.Dialect.connect\u001b[39;00m\n\u001b[1;32m--> 616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloaded_dbapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOperationalError\u001b[0m: unable to open database file",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 18\u001b[0m\n\u001b[0;32m      2\u001b[0m sql \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124mSELECT\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124m  start_time as \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124mORDER BY 1\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m#timefilter = \"start_time >= '2020-01-30' AND start_time < '2020-02-02'\" / $__timeFilter(start_time) AND\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtime\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# fig, ax = plt.subplots(figsize=(8,6))\u001b[39;00m\n\u001b[0;32m     20\u001b[0m series \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\sql.py:633\u001b[0m, in \u001b[0;36mread_sql\u001b[1;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize, dtype_backend, dtype)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_backend \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[0;32m    631\u001b[0m     dtype_backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mpandasSQL_builder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcon\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[0;32m    634\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pandas_sql, SQLiteDatabase):\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql\u001b[38;5;241m.\u001b[39mread_query(\n\u001b[0;32m    636\u001b[0m             sql,\n\u001b[0;32m    637\u001b[0m             index_col\u001b[38;5;241m=\u001b[39mindex_col,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    643\u001b[0m             dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    644\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\sql.py:832\u001b[0m, in \u001b[0;36mpandasSQL_builder\u001b[1;34m(con, schema, need_transaction)\u001b[0m\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing URI string without sqlalchemy installed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    831\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sqlalchemy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(con, (\u001b[38;5;28mstr\u001b[39m, sqlalchemy\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39mConnectable)):\n\u001b[1;32m--> 832\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSQLDatabase\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneed_transaction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    834\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    835\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas only supports SQLAlchemy connectable (engine/connection) or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    836\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatabase string URI or sqlite3 DBAPI2 connection. Other DBAPI2 \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    839\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    840\u001b[0m )\n\u001b[0;32m    841\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m SQLiteDatabase(con)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\sql.py:1539\u001b[0m, in \u001b[0;36mSQLDatabase.__init__\u001b[1;34m(self, con, schema, need_transaction)\u001b[0m\n\u001b[0;32m   1537\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexit_stack\u001b[38;5;241m.\u001b[39mcallback(con\u001b[38;5;241m.\u001b[39mdispose)\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(con, Engine):\n\u001b[1;32m-> 1539\u001b[0m     con \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexit_stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[43mcon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1540\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m need_transaction \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m con\u001b[38;5;241m.\u001b[39min_transaction():\n\u001b[0;32m   1541\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexit_stack\u001b[38;5;241m.\u001b[39menter_context(con\u001b[38;5;241m.\u001b[39mbegin())\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:3264\u001b[0m, in \u001b[0;36mEngine.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Connection:\n\u001b[0;32m   3242\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a new :class:`_engine.Connection` object.\u001b[39;00m\n\u001b[0;32m   3243\u001b[0m \n\u001b[0;32m   3244\u001b[0m \u001b[38;5;124;03m    The :class:`_engine.Connection` acts as a Python context manager, so\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3261\u001b[0m \n\u001b[0;32m   3262\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3264\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:147\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[1;34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbapi_connection \u001b[38;5;241m=\u001b[39m engine\u001b[38;5;241m.\u001b[39mraw_connection()\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m dialect\u001b[38;5;241m.\u001b[39mloaded_dbapi\u001b[38;5;241m.\u001b[39mError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 147\u001b[0m         \u001b[43mConnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_dbapi_exception_noconnection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m            \u001b[49m\u001b[43merr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2426\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception_noconnection\u001b[1;34m(cls, e, dialect, engine, is_disconnect, invalidate_pool_on_disconnect, is_pre_ping)\u001b[0m\n\u001b[0;32m   2424\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[0;32m   2425\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2426\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception\u001b[38;5;241m.\u001b[39mwith_traceback(exc_info[\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   2427\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2428\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:145\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[1;34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbapi_connection \u001b[38;5;241m=\u001b[39m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m dialect\u001b[38;5;241m.\u001b[39mloaded_dbapi\u001b[38;5;241m.\u001b[39mError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    147\u001b[0m         Connection\u001b[38;5;241m.\u001b[39m_handle_dbapi_exception_noconnection(\n\u001b[0;32m    148\u001b[0m             err, dialect, engine\n\u001b[0;32m    149\u001b[0m         )\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:3288\u001b[0m, in \u001b[0;36mEngine.raw_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraw_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PoolProxiedConnection:\n\u001b[0;32m   3267\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a \"raw\" DBAPI connection from the connection pool.\u001b[39;00m\n\u001b[0;32m   3268\u001b[0m \n\u001b[0;32m   3269\u001b[0m \u001b[38;5;124;03m    The returned object is a proxied version of the DBAPI\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3286\u001b[0m \n\u001b[0;32m   3287\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3288\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:452\u001b[0m, in \u001b[0;36mPool.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PoolProxiedConnection:\n\u001b[0;32m    445\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a DBAPI connection from the pool.\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \n\u001b[0;32m    447\u001b[0m \u001b[38;5;124;03m    The connection is instrumented such that when its\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    450\u001b[0m \n\u001b[0;32m    451\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 452\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionFairy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_checkout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:1268\u001b[0m, in \u001b[0;36m_ConnectionFairy._checkout\u001b[1;34m(cls, pool, threadconns, fairy)\u001b[0m\n\u001b[0;32m   1259\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m   1260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_checkout\u001b[39m(\n\u001b[0;32m   1261\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1264\u001b[0m     fairy: Optional[_ConnectionFairy] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1265\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _ConnectionFairy:\n\u001b[0;32m   1267\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fairy:\n\u001b[1;32m-> 1268\u001b[0m         fairy \u001b[38;5;241m=\u001b[39m \u001b[43m_ConnectionRecord\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1270\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m threadconns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1271\u001b[0m             threadconns\u001b[38;5;241m.\u001b[39mcurrent \u001b[38;5;241m=\u001b[39m weakref\u001b[38;5;241m.\u001b[39mref(fairy)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:716\u001b[0m, in \u001b[0;36m_ConnectionRecord.checkout\u001b[1;34m(cls, pool)\u001b[0m\n\u001b[0;32m    714\u001b[0m     rec \u001b[38;5;241m=\u001b[39m cast(_ConnectionRecord, pool\u001b[38;5;241m.\u001b[39m_do_get())\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 716\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    719\u001b[0m     dbapi_connection \u001b[38;5;241m=\u001b[39m rec\u001b[38;5;241m.\u001b[39mget_connection()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\pool\\impl.py:168\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection()\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m--> 168\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msafe_reraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dec_overflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\util\\langhelpers.py:147\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[1;34m(self, type_, value, traceback)\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[1;32m--> 147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\pool\\impl.py:166\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inc_overflow():\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 166\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    168\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:393\u001b[0m, in \u001b[0;36mPool._create_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ConnectionPoolEntry:\n\u001b[0;32m    391\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Called by subclasses to create a new ConnectionRecord.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 393\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionRecord\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:678\u001b[0m, in \u001b[0;36m_ConnectionRecord.__init__\u001b[1;34m(self, pool, connect)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__pool \u001b[38;5;241m=\u001b[39m pool\n\u001b[0;32m    677\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connect:\n\u001b[1;32m--> 678\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalize_callback \u001b[38;5;241m=\u001b[39m deque()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:902\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    900\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfresh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 902\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msafe_reraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    903\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mError on connect(): \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    904\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    905\u001b[0m     \u001b[38;5;66;03m# in SQLAlchemy 1.4 the first_connect event is not used by\u001b[39;00m\n\u001b[0;32m    906\u001b[0m     \u001b[38;5;66;03m# the engine, so this will usually not be set\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\util\\langhelpers.py:147\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[1;34m(self, type_, value, traceback)\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[1;32m--> 147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:898\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    896\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    897\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstarttime \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 898\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdbapi_connection \u001b[38;5;241m=\u001b[39m connection \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    899\u001b[0m     pool\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreated new connection \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, connection)\n\u001b[0;32m    900\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfresh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\engine\\create.py:637\u001b[0m, in \u001b[0;36mcreate_engine.<locals>.connect\u001b[1;34m(connection_record)\u001b[0m\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    635\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m connection\n\u001b[1;32m--> 637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\assume-framework\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:616\u001b[0m, in \u001b[0;36mDefaultDialect.connect\u001b[1;34m(self, *cargs, **cparams)\u001b[0m\n\u001b[0;32m    614\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mcargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcparams):\n\u001b[0;32m    615\u001b[0m     \u001b[38;5;66;03m# inherits the docstring from interfaces.Dialect.connect\u001b[39;00m\n\u001b[1;32m--> 616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloaded_dbapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOperationalError\u001b[0m: (sqlite3.OperationalError) unable to open database file\n(Background on this error at: https://sqlalche.me/e/20/e3q8)"
     ]
    }
   ],
   "source": [
    "# second plot\n",
    "sql = \"\"\"\n",
    "SELECT\n",
    "  start_time as \"time\",\n",
    "  sum(accepted_volume) AS \"accepted_volume\",\n",
    "  unit_id,\n",
    "  simulation\n",
    "FROM market_orders\n",
    "WHERE\n",
    "  start_time >= '2020-01-30' AND \n",
    "  start_time < '2020-02-03' AND\n",
    "  unit_id = 'combined_gas_unit' AND\n",
    "  simulation in ('example_07_sho_dam', 'example_07_bo_dam', 'example_07_lo_dam')\n",
    "GROUP BY 1, unit_id, simulation\n",
    "ORDER BY 1\n",
    "\"\"\"\n",
    "#timefilter = \"start_time >= '2020-01-30' AND start_time < '2020-02-02'\" / $__timeFilter(start_time) AND\n",
    "df = pd.read_sql(sql, engine, index_col=\"time\")\n",
    "# fig, ax = plt.subplots(figsize=(8,6))\n",
    "series = []\n",
    "# for label, sub_df in df.groupby([\"market_id\", \"technology\"]):\n",
    "#     lab = \"-\".join(label)\n",
    "#     lab = lab.replace(\"LTM_OTC\", \"LTM\")\n",
    "\n",
    "#     if \"lignite\" not in lab and \"nuclear\" not in lab:\n",
    "#         continue\n",
    "#     group_sum = sub_df.market_dispatch.groupby(\"time\").sum()\n",
    "#     group_sum.name = lab\n",
    "#     series.append(group_sum.resample(\"1h\").ffill())\n",
    "\n",
    "for label, sub_df in df.groupby([\"simulation\"]):\n",
    "    lab = label.replace(\"example_07_\", \"\").replace(\"_dam\", \"\")\n",
    "    group_sum = sub_df.groupby(\"time\").sum()\n",
    "    group_sum.name = lab\n",
    "    series.append(group_sum.resample(\"1h\").ffill())\n",
    "\n",
    "ddf = pd.DataFrame(series)\n",
    "ddf = ddf.T.fillna(method=\"ffill\")\n",
    "\n",
    "ddf = ddf[sorted(ddf.columns, reverse=True)]\n",
    "ddf = ddf.fillna(0)\n",
    "ddf /= 1e3\n",
    "base = ddf[ddf.columns[0]] * 0\n",
    "for col in ddf.columns:\n",
    "    line = base + ddf[col]\n",
    "    if \"sho\" in col:\n",
    "        c = (0.3, 0.2, 0.6, 0.8)\n",
    "    elif \"bo\" in col:\n",
    "        c = \"r\"\n",
    "    else:\n",
    "        c = \"g\"\n",
    "    alpha = 0.3\n",
    "    plt.fill_between(line.index, line, base, alpha=alpha, label=col, color=c)\n",
    "    base += ddf[col]\n",
    "plt.ylabel(\"Hourly accepted power [$MW$]\")\n",
    "plt.xlabel(\"Datetime\")\n",
    "plt.xticks(rotation=25)\n",
    "plt.legend()\n",
    "savefig(\"accepted-power.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here one can see that the accepted volume of the combined cycle gas turbine depends on the order type.\n",
    "The unit has a minimum power output of 362.2 MW. It can be seen, that in the SHO-case this restriction is not always respected. \n",
    "But also in the BO-case the accepted volume is even more often between zero and the minimum power output.\n",
    "With the linked orders all technical restrictions can be represented in the strategy. \n",
    "Therefore, the dispatch of the unit can precisely follow the market outcome.\n",
    "\n",
    "This also brings us to the end of this short tutorial on multiple markets."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "assume-framework",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "nbsphinx": {
   "execute": "never"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
