{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Redispatch modelling using PyPSA\n",
    "\n",
    "This tutorial demonstrates modelling and simulation of redispatch mechanism using PyPSA as a plug and play module in ASSUME-framework. The model will be created mainly taking grid constraints into consideration to identify grid bottlenecks with dispatches from EOM and resolve them using the redispatch algorithm.\n",
    "\n",
    "## Concept of Redispatch\n",
    "\n",
    "The locational mismatch in demand and generation of electricity needs transmission of electricity from low demand regions to high demand regions. The transmission capacity limits the maximum amounts of electricity which can be transmitted at any point in time. If there is no enough capacity to transmit the required amount of electricity then there is a need of ramping down of generation at the locations of low demand and ramping up of generation at the locations of higher demand. This is typically called as Redispatch. Apart from spot markets there is redispatch mechanism to regulate this grid flows to avoid congestion issues. It is operated and controlled by the System operators (SO).\n",
    "\n",
    "## Objective \n",
    "The aim of redispatch is to reduce the overall cost of Redispatch(starting up, shutting down, ramping up, ramping down).\n",
    "\n",
    "## Structure in Redispatch model\n",
    "- The redispatch has following structure:\n",
    "    1. **Ramping up of market powerplants**\n",
    "    2. **Ramping down of market powerplants**:\n",
    "    3. **Ramping up/down of other flexibilites**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Objective of This Tutorial:\n",
    "In this tutorial, we will:\n",
    "1. Set up a **3-node** example of redispatch.\n",
    "2. Connect hypothetical **generators**,**loads** and **transmission lines** to illustrate flow of energy.\n",
    "3. Add **demand_side_units** to analyse their impact on overall redispatch.\n",
    "4. Simulate and visualize the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up grid network with infrastructure\n",
    "\n",
    "The grid infrastructure includes mainly three components:\n",
    "\n",
    "- **Generators**: Used to produce hydrogen for steel production.\n",
    "- **Loads**: Directly reduces iron ore using hydrogen.\n",
    "- **Transmission grid**: Converts the reduced iron into steel.\n",
    "\n",
    "\n",
    "Here the components are defined with their operational constraints (such as power, efficiency, ramp rates etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A PyPSA network model can be created by defining nodes as locations for power generation and consumption, interconnected by transmission lines with nominal transmission capacity (`s_nom`). These components can be further constrained operationally, for instance, by nominal power, efficiency, ramp rates, and other factors.\n",
    "\n",
    "Currently, a limitation of the PyPSA model is the inability to define flexible loads.\n",
    "\n",
    "Modelling Redispatch in ASSUME\n",
    "--------------------------------\n",
    "\n",
    "Modelling redispatch in the ASSUME framework using PyPSA primarily includes two parts:\n",
    "\n",
    "Congestion Identification\n",
    "--------------------------\n",
    "\n",
    "The first step is to check for congestion in the network. The linear power flow (LPF) method is particularly useful for quick assessments of congestion and redispatch needs. PyPSA provides the `network.lpf()` function for running linear power flow. This method is significantly faster than a full non-linear AC power flow, making it suitable for real-time analysis or large network studies.\n",
    "\n",
    "The active power flows through the lines can be retrieved using `network.lines_t.p0`. These can be compared to the nominal capacity of the lines (`s_nom`) to determine whether there is congestion.\n",
    "\n",
    "```python\n",
    "line_loading = network.lines_t.p0 / network.lines.s_nom\n",
    "```\n",
    "\n",
    "If line loading exceeds 1, it suggests there is congestion.\n",
    "\n",
    "Redispatch of Power Plants\n",
    "---------------------------\n",
    "\n",
    "Once congestion is identified at any line or timestep, the redispatch mechanism is applied to alleviate it.\n",
    "\n",
    "**Steps for Redispatch**\n",
    "\n",
    "\n",
    "1. **Fixing Dispatches from the EOM Market**\n",
    "   EOM market dispatches are fixed to model redispatch from power plants with accurate cost considerations. EOM dispatches are treated as a `Load` in the network, with dispatches specified via `p_set`. Generators are assigned a positive sign, and demands are given a negative sign.\n",
    "\n",
    "2. **Upward Redispatch from Market and Reserved Power Plants**\n",
    "   Due to PyPSA’s limitations in modelling load flexibility, upward redispatch is added as a `Generator` with a positive sign. The maximum available capacity for upward redispatch is restricted using the `p_max_pu` factor, estimated as the difference between the current generation and the maximum power of the power plant.\n",
    "\n",
    "   ```python\n",
    "   p_max_pu_up = (max_power - volume) / max_power\n",
    "   ```\n",
    "\n",
    "3. **Downward Redispatch from Market Power Plants**\n",
    "   Similarly, downward redispatch is modelled as a `Generator` with a negative sign. The maximum available capacity for downward redispatch is restricted by the `p_max_pu` factor.\n",
    "\n",
    "4. **Upward and Downward Redispatch from Other Flexibilities**\n",
    "   Flexibility for redispatch is also modelled as generators, with positive signs for upward redispatch and negative signs for downward redispatch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loads csv files from the given path and returns a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **You can find this code in loader_csv.py inside assume/scenario folder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pypsa\n",
    "\n",
    "\n",
    "# Simplified function to add read required CSV files\n",
    "def read_grid(network_path: str | Path) -> dict[str, pd.DataFrame]:\n",
    "    network_path = Path(network_path)\n",
    "    buses = pd.read_csv(network_path / \"buses.csv\", index_col=0)\n",
    "    lines = pd.read_csv(network_path / \"lines.csv\", index_col=0)\n",
    "    generators = pd.read_csv(network_path / \"powerplant_units.csv\", index_col=0)\n",
    "    loads = pd.read_csv(network_path / \"demand_units.csv\", index_col=0)\n",
    "\n",
    "    return {\n",
    "        \"buses\": buses,\n",
    "        \"lines\": lines,\n",
    "        \"generators\": generators,\n",
    "        \"loads\": loads,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Simplified function to add generators to the grid network\n",
    "- generator capacity which is cleared in a DAM (fixed capacity) as a **load**\n",
    "- the sold capacity which is available for downward redispatch as **generator** with negative sign\n",
    "- the unsold capacity which is available for upward redispatch as **generator** with positive sign\n",
    "- **backup generator** capacities for both **upward** and **downward** redispatch to avoid infeasible solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **You can find this code in grid_utils.py inside assume/common folder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_redispatch_generators(\n",
    "    network: pypsa.Network,\n",
    "    generators: pd.DataFrame,\n",
    "    backup_marginal_cost: float = 1e5,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Adds the given generators for redispatch.\n",
    "    This includes functions to optimize up as well as down and adds backup capacities of powerplants to be able to adjust accordingly when a congestion happens.\n",
    "\n",
    "    Args:\n",
    "        network (pypsa.Network): the pypsa network to which the generators are\n",
    "        generators (pandas.DataFrame): the generators dataframe\n",
    "        backup_marginal_cost (float, optional): The cost of dispatching the backup units in [€/MW]. Defaults to 1e5.\n",
    "    \"\"\"\n",
    "    p_set = pd.DataFrame(\n",
    "        np.zeros((len(network.snapshots), len(generators.index))),\n",
    "        index=network.snapshots,\n",
    "        columns=generators.index,\n",
    "    )\n",
    "\n",
    "    # add generators and their sold capacities as load with reversed sign to have fixed feed in\n",
    "    network.add(\n",
    "        \"Load\",\n",
    "        name=generators.index,\n",
    "        bus=generators[\"node\"],  # bus to which the generator is connected to\n",
    "        p_set=p_set,\n",
    "        sign=1,\n",
    "    )\n",
    "\n",
    "    # add upward redispatch generators\n",
    "    network.add(\n",
    "        \"Generator\",\n",
    "        name=generators.index,\n",
    "        suffix=\"_up\",\n",
    "        bus=generators[\"node\"],  # bus to which the generator is connected to\n",
    "        p_nom=generators[\"max_power\"],  # Nominal capacity of the powerplant/generator\n",
    "        p_min_pu=p_set,\n",
    "        p_max_pu=p_set + 1,\n",
    "        marginal_cost=p_set,\n",
    "    )\n",
    "\n",
    "    # add downward redispatch generators\n",
    "    network.add(\n",
    "        \"Generator\",\n",
    "        name=generators.index,\n",
    "        suffix=\"_down\",\n",
    "        bus=generators[\"node\"],  # bus to which the generator is connected to\n",
    "        p_nom=generators[\"max_power\"],  # Nominal capacity of the powerplant/generator\n",
    "        p_min_pu=p_set,\n",
    "        p_max_pu=p_set + 1,\n",
    "        marginal_cost=p_set,\n",
    "        sign=-1,\n",
    "    )\n",
    "\n",
    "    # add upward and downward backup generators at each node\n",
    "    network.add(\n",
    "        \"Generator\",\n",
    "        name=network.buses.index,\n",
    "        suffix=\"_backup_up\",\n",
    "        bus=network.buses.index,  # bus to which the generator is connected to\n",
    "        p_nom=10e4,\n",
    "        marginal_cost=backup_marginal_cost,\n",
    "    )\n",
    "\n",
    "    network.add(\n",
    "        \"Generator\",\n",
    "        name=network.buses.index,\n",
    "        suffix=\"_backup_down\",\n",
    "        bus=network.buses.index,  # bus to which the generator is connected to\n",
    "        p_nom=10e4,\n",
    "        marginal_cost=backup_marginal_cost,\n",
    "        sign=-1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Simplified function to add loads to the redispatch network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_fix_units(\n",
    "    network: pypsa.Network,\n",
    "    units: pd.DataFrame,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    This adds loads to the redispatch PyPSA network with respective bus data to which they are connected\n",
    "    \"\"\"\n",
    "    if units is None or units.empty:\n",
    "        return\n",
    "\n",
    "    units_c = units.copy()\n",
    "    if \"sign\" in units_c.columns:\n",
    "        del units_c[\"sign\"]\n",
    "\n",
    "    # add loads with opposite sign (default for loads is -1). This is needed to properly model the redispatch\n",
    "    network.add(\n",
    "        \"Load\",\n",
    "        name=units.index,\n",
    "        bus=units[\"node\"],  # bus to which the generator is connected to\n",
    "        sign=1,\n",
    "        **units_c,\n",
    "    )\n",
    "\n",
    "    if \"p_set\" not in units.columns:\n",
    "        network.loads_t[\"p_set\"] = pd.DataFrame(\n",
    "            np.zeros((len(network.snapshots), len(units.index))),\n",
    "            index=network.snapshots,\n",
    "            columns=units.index,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Simplified function to add dsm units to the redispatch network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_redispatch_dsm(network: pypsa.Network,\n",
    "    industrial_dsm_units: pd.DataFrame) -> None:\n",
    "\n",
    "    # simply copy the DataFrame straight over\n",
    "    dsm_units = industrial_dsm_units.copy()\n",
    "\n",
    "    # now build p_set exactly as before...\n",
    "    p_set = pd.DataFrame(\n",
    "        0,\n",
    "        index=network.snapshots,\n",
    "        columns=dsm_units.index,\n",
    "    )\n",
    "\n",
    "    network.madd(\n",
    "        \"Load\",\n",
    "        names=dsm_units.index,\n",
    "        bus=dsm_units[\"node\"],\n",
    "        p_set=p_set,\n",
    "        sign=1,\n",
    "    )\n",
    "\n",
    "    # upward redispatch\n",
    "    network.madd(\n",
    "        \"Generator\",\n",
    "        names=dsm_units.index,\n",
    "        suffix=\"_up\",\n",
    "        bus=dsm_units[\"node\"],\n",
    "        p_nom=1,\n",
    "        p_min_pu=p_set,\n",
    "        p_max_pu=p_set,\n",
    "        marginal_cost=p_set,\n",
    "        sign=-1,\n",
    "    )\n",
    "\n",
    "    # downward redispatch\n",
    "    network.madd(\n",
    "        \"Generator\",\n",
    "        names=dsm_units.index,\n",
    "        suffix=\"_down\",\n",
    "        bus=dsm_units[\"node\"],\n",
    "        p_nom=1,\n",
    "        p_min_pu=p_set,\n",
    "        p_max_pu=p_set,\n",
    "        marginal_cost=p_set,\n",
    "        sign=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Simplified function to add Buses and Lines to the redispatch network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified function to add grid buses and lines to the redispatch network\n",
    "def read_pypsa_grid(\n",
    "    network: pypsa.Network,\n",
    "    grid_dict: dict[str, pd.DataFrame],\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates the pypsa grid from a grid dictionary.\n",
    "    Does not add the generators, as they are added in different ways, depending on wether redispatch is used.\n",
    "\n",
    "    Args:\n",
    "        network (pypsa.Network): the pypsa network to which the components will be added\n",
    "        grid_dict (dict[str, pd.DataFrame]): the dictionary containing dataframes for generators, loads, buses and links\n",
    "    \"\"\"\n",
    "\n",
    "    def add_buses(network: pypsa.Network, buses: pd.DataFrame) -> None:\n",
    "        network.import_components_from_dataframe(buses, \"Bus\")\n",
    "\n",
    "    def add_lines(network: pypsa.Network, lines: pd.DataFrame) -> None:\n",
    "        network.import_components_from_dataframe(lines, \"Line\")\n",
    "\n",
    "    # setup the network\n",
    "    add_buses(network, grid_dict[\"buses\"])\n",
    "    add_lines(network, grid_dict[\"lines\"])\n",
    "    return network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Congestion/Redispatch clearing function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Performs redispatch to resolve congestion in the electricity market.**\n",
    "- It first checks for congestion in the network and if it finds any, it performs redispatch to resolve it.\n",
    "- The returned orderbook contains accepted orders with the redispatched volumes and prices.\n",
    "- The prices are positive for upward redispatch and negative for downward redispatch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **You can find this code in redispatch.py inside assume/market/clearing_algorithm folder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from assume.common.grid_utils import calculate_network_meta\n",
    "from assume.common.market_objects import Orderbook\n",
    "\n",
    "\n",
    "def clear(\n",
    "    self, orderbook: Orderbook, market_products\n",
    ") -> tuple[Orderbook, Orderbook, list[dict]]:\n",
    "    orderbook_df = pd.DataFrame(orderbook)\n",
    "    orderbook_df[\"accepted_volume\"] = 0.0\n",
    "    orderbook_df[\"accepted_price\"] = 0.0\n",
    "\n",
    "    # Now you can pivot the DataFrame\n",
    "    volume_pivot = orderbook_df.pivot(\n",
    "        index=\"start_time\", columns=\"unit_id\", values=\"volume\"\n",
    "    )\n",
    "    max_power_pivot = orderbook_df.pivot(\n",
    "        index=\"start_time\", columns=\"unit_id\", values=\"max_power\"\n",
    "    )\n",
    "    min_power_pivot = orderbook_df.pivot(\n",
    "        index=\"start_time\", columns=\"unit_id\", values=\"min_power\"\n",
    "    )\n",
    "    price_pivot = orderbook_df.pivot(\n",
    "        index=\"start_time\", columns=\"unit_id\", values=\"price\"\n",
    "    )\n",
    "\n",
    "    # Calculate p_set, p_max_pu_up, and p_max_pu_down directly using DataFrame operations\n",
    "    p_set = volume_pivot\n",
    "\n",
    "    # Calculate p_max_pu_up as difference between max_power and accepted volume\n",
    "    p_max_pu_up = (max_power_pivot - volume_pivot).div(\n",
    "        max_power_pivot.where(max_power_pivot != 0, np.inf)\n",
    "    )\n",
    "\n",
    "    # Calculate p_max_pu_down as difference between accepted volume and min_power\n",
    "    p_max_pu_down = (volume_pivot - min_power_pivot).div(\n",
    "        max_power_pivot.where(max_power_pivot != 0, np.inf)\n",
    "    )\n",
    "    p_max_pu_down = p_max_pu_down.clip(lower=0)  # Ensure no negative values\n",
    "\n",
    "    # Determine the costs directly from the price pivot\n",
    "    costs = price_pivot\n",
    "\n",
    "    # Drop units with only negative volumes (if necessary)\n",
    "    negative_only_units = volume_pivot.lt(0).all()\n",
    "    p_max_pu_up = p_max_pu_up.drop(\n",
    "        columns=negative_only_units.index[negative_only_units]\n",
    "    )\n",
    "    p_max_pu_down = p_max_pu_down.drop(\n",
    "        columns=negative_only_units.index[negative_only_units]\n",
    "    )\n",
    "    costs = costs.drop(columns=negative_only_units.index[negative_only_units])\n",
    "\n",
    "    # reset indexes for all dataframes\n",
    "    p_set.reset_index(inplace=True, drop=True)\n",
    "    p_max_pu_up.reset_index(inplace=True, drop=True)\n",
    "    p_max_pu_down.reset_index(inplace=True, drop=True)\n",
    "    costs.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    # Update the network parameters\n",
    "    redispatch_network = self.network.copy()\n",
    "    redispatch_network.loads_t.p_set = p_set\n",
    "\n",
    "    # Update p_max_pu for generators with _up and _down suffixes\n",
    "    redispatch_network.generators_t.p_max_pu.update(p_max_pu_up.add_suffix(\"_up\"))\n",
    "    redispatch_network.generators_t.p_max_pu.update(p_max_pu_down.add_suffix(\"_down\"))\n",
    "\n",
    "    # Add _up and _down suffix to costs and update the network\n",
    "    redispatch_network.generators_t.marginal_cost.update(costs.add_suffix(\"_up\"))\n",
    "    redispatch_network.generators_t.marginal_cost.update(\n",
    "        costs.add_suffix(\"_down\") * (-1)\n",
    "    )\n",
    "\n",
    "    # run linear powerflow\n",
    "    redispatch_network.lpf()\n",
    "\n",
    "    # check lines for congestion where power flow is larget than s_nom\n",
    "    line_loading = redispatch_network.lines_t.p0.abs() / redispatch_network.lines.s_nom\n",
    "\n",
    "    # if any line is congested, perform redispatch\n",
    "    if line_loading.max().max() > 1:\n",
    "        status, termination_condition = redispatch_network.optimize(\n",
    "            solver_name=self.solver,\n",
    "            env=self.env,\n",
    "        )\n",
    "\n",
    "        if status != \"ok\":\n",
    "            raise Exception(\"Solver in redispatch market did not converge\")\n",
    "\n",
    "        # process dispatch data\n",
    "        self.process_dispatch_data(\n",
    "            network=redispatch_network, orderbook_df=orderbook_df\n",
    "        )\n",
    "\n",
    "    # return orderbook_df back to orderbook format as list of dicts\n",
    "    accepted_orders = orderbook_df.to_dict(\"records\")\n",
    "    rejected_orders = []\n",
    "    meta = []\n",
    "\n",
    "    # calculate meta data such as total upwared and downward redispatch, total backup dispatch\n",
    "    # and total redispatch cost\n",
    "    for i, product in enumerate(market_products):\n",
    "        meta.extend(\n",
    "            calculate_network_meta(network=redispatch_network, product=product, i=i)\n",
    "        )\n",
    "\n",
    "    return accepted_orders, rejected_orders, meta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
