{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Redispatch modeling using PyPSA\n",
    "\n",
    "This tutorial demonstrates modeling and simulation of redispatch mechanism using PyPSA as a plug and play module in ASSUME-framework. The model will be created mainly taking grid constraints into consideration to identify grid bottlenecks with dispatches from EOM and resolve them using the redispatch algorithm.\n",
    "\n",
    "## Concept of Redispatch\n",
    "\n",
    "The locational mismatch in demand and generation of electricity needs transmission of electricity from low demand regions to high demand regions. The transmission capacity limits the maximum amounts of electricity which can be transmitted at any point in time. If there is no enough capacity to transmit the required amount of electricity then there is a need of ramping down of generation at the locations of low demand and ramping up of generation at the locations of higher demand. This is typically called as Redispatch. Apart from spot markets there is redispatch mechanism to regulate this grid flows to avoid congestion issues. It is operated and controlled by the System operators (SO).\n",
    "\n",
    "## Objective \n",
    "The aim of redispatch is to reduce the overall cost of Redispatch(starting up, shutting down, ramping up, ramping down).\n",
    "\n",
    "## Structure in Redispatch model\n",
    "- The redispatch has following structure:\n",
    "    1. **Ramping up of reserved powerplants**:\n",
    "    2. **Ramping up of market powerplants**\n",
    "    2. **Ramping down of market powerplants**:\n",
    "    3. **Ramping up/down of other flexibilites**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Objective of This Tutorial:\n",
    "In this tutorial, we will:\n",
    "1. Set up a **2-node** example of redispatch.\n",
    "2. Connect hypothetical **generators**,**loads** and **transmission lines** to illustrate flow of energy.\n",
    "3. Add **demand_side_units** to analyse their impact on overall redispatch.\n",
    "4. Simulate and visualize the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up grid network with infrastructure\n",
    "\n",
    "The grid infrastructure includes mainly three components:\n",
    "\n",
    "- **Generators**: Used to produce hydrogen for steel production.\n",
    "- **Loads**: Directly reduces iron ore using hydrogen.\n",
    "- **Transmission grid**: Converts the reduced iron into steel.\n",
    "\n",
    "\n",
    "Here the components are defined with their operational constraints (such as power, efficiency, ramp rates etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loads csv files from the given path and returns a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pypsa\n",
    "\n",
    "\n",
    "# Simplified function to add read required CSV files\n",
    "def read_grid(network_path: str | Path) -> dict[str, pd.DataFrame]:\n",
    "    network_path = Path(network_path)\n",
    "    buses = pd.read_csv(network_path / \"buses.csv\", index_col=0)\n",
    "    lines = pd.read_csv(network_path / \"lines.csv\", index_col=0)\n",
    "    generators = pd.read_csv(network_path / \"powerplant_units.csv\", index_col=0)\n",
    "    loads = pd.read_csv(network_path / \"demand_units.csv\", index_col=0)\n",
    "\n",
    "    return {\n",
    "        \"buses\": buses,\n",
    "        \"lines\": lines,\n",
    "        \"generators\": generators,\n",
    "        \"loads\": loads,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Simplified function to add generators to the grid network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified function to add generators to the grid network\n",
    "def add_generators(\n",
    "    network: pypsa.Network,\n",
    "    generators: pd.DataFrame,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Add generators normally to the grid\n",
    "\n",
    "    Args:\n",
    "        network (pypsa.Network): the pypsa network to which the generators are\n",
    "        generators (pandas.DataFrame): the generators dataframe\n",
    "    \"\"\"\n",
    "    p_set = pd.DataFrame(\n",
    "        np.zeros((len(network.snapshots), len(generators.index))),\n",
    "        index=network.snapshots,\n",
    "        columns=generators.index,\n",
    "    )\n",
    "    # add generators\n",
    "    network.add(\n",
    "        \"Generator\",\n",
    "        name=generators.index,\n",
    "        bus=generators[\"node\"],  # bus to which the generator is connected to\n",
    "        p_nom=generators[\"max_power\"],  # Nominal capacity of the powerplant/generator\n",
    "        p_min_pu=p_set,\n",
    "        p_max_pu=p_set + 1,\n",
    "        marginal_cost=p_set,\n",
    "        **generators,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Simplified function to add loads to the grid network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified function to add loads to the grid network\n",
    "def add_loads(\n",
    "    network: pypsa.Network,\n",
    "    loads: pd.DataFrame,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Add loads normally to the grid\n",
    "\n",
    "    Args:\n",
    "        network (pypsa.Network): the pypsa network to which the loads are\n",
    "        loads (pandas.DataFrame): the loads dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    # add loads\n",
    "    network.add(\n",
    "        \"Load\",\n",
    "        name=loads.index,\n",
    "        bus=loads[\"node\"],  # bus to which the generator is connected to\n",
    "        **loads,\n",
    "    )\n",
    "\n",
    "    if \"p_set\" not in loads.columns:\n",
    "        network.loads_t[\"p_set\"] = pd.DataFrame(\n",
    "            np.zeros((len(network.snapshots), len(loads.index))),\n",
    "            index=network.snapshots,\n",
    "            columns=loads.index,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Simplified function to add loads to the redispatch network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified function to add loads to the redispatch network\n",
    "def add_redispatch_loads(\n",
    "    network: pypsa.Network,\n",
    "    loads: pd.DataFrame,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    This adds loads to the redispatch PyPSA network with respective bus data to which they are connected\n",
    "    \"\"\"\n",
    "    loads_c = loads.copy()\n",
    "    if \"sign\" in loads_c.columns:\n",
    "        del loads_c[\"sign\"]\n",
    "\n",
    "    # add loads with opposite sign (default for loads is -1). This is needed to properly model the redispatch\n",
    "    network.add(\n",
    "        \"Load\",\n",
    "        name=loads.index,\n",
    "        bus=loads[\"node\"],  # bus to which the generator is connected to\n",
    "        sign=1,\n",
    "        **loads_c,\n",
    "    )\n",
    "\n",
    "    if \"p_set\" not in loads.columns:\n",
    "        network.loads_t[\"p_set\"] = pd.DataFrame(\n",
    "            np.zeros((len(network.snapshots), len(loads.index))),\n",
    "            index=network.snapshots,\n",
    "            columns=loads.index,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Simplified function to add Buses and Lines to the redispatch network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified function to add grid buses and lines to the redispatch network\n",
    "def read_pypsa_grid(\n",
    "    network: pypsa.Network,\n",
    "    grid_dict: dict[str, pd.DataFrame],\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates the pypsa grid from a grid dictionary.\n",
    "    Does not add the generators, as they are added in different ways, depending on wether redispatch is used.\n",
    "\n",
    "    Args:\n",
    "        network (pypsa.Network): the pypsa network to which the components will be added\n",
    "        grid_dict (dict[str, pd.DataFrame]): the dictionary containing dataframes for generators, loads, buses and links\n",
    "    \"\"\"\n",
    "\n",
    "    def add_buses(network: pypsa.Network, buses: pd.DataFrame) -> None:\n",
    "        network.import_components_from_dataframe(buses, \"Bus\")\n",
    "\n",
    "    def add_lines(network: pypsa.Network, lines: pd.DataFrame) -> None:\n",
    "        network.import_components_from_dataframe(lines, \"Line\")\n",
    "\n",
    "    # setup the network\n",
    "    add_buses(network, grid_dict[\"buses\"])\n",
    "    add_lines(network, grid_dict[\"lines\"])\n",
    "    return network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Congestion/Redispatch clearning function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Performs redispatch to resolve congestion in the electricity market.**\n",
    "- It first checks for congestion in the network and if it finds any, it performs redispatch to resolve it.\n",
    "- The returned orderbook contains accepted orders with the redispatched volumes and prices.\n",
    "- The prices are positive for upward redispatch and negative for downward redispatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from assume.common.grid_utils import calculate_network_meta\n",
    "from assume.common.market_objects import Orderbook\n",
    "\n",
    "\n",
    "def clear(\n",
    "    self, orderbook: Orderbook, market_products\n",
    ") -> tuple[Orderbook, Orderbook, list[dict]]:\n",
    "    orderbook_df = pd.DataFrame(orderbook)\n",
    "    orderbook_df[\"accepted_volume\"] = 0.0\n",
    "    orderbook_df[\"accepted_price\"] = 0.0\n",
    "\n",
    "    # Now you can pivot the DataFrame\n",
    "    volume_pivot = orderbook_df.pivot(\n",
    "        index=\"start_time\", columns=\"unit_id\", values=\"volume\"\n",
    "    )\n",
    "    max_power_pivot = orderbook_df.pivot(\n",
    "        index=\"start_time\", columns=\"unit_id\", values=\"max_power\"\n",
    "    )\n",
    "    min_power_pivot = orderbook_df.pivot(\n",
    "        index=\"start_time\", columns=\"unit_id\", values=\"min_power\"\n",
    "    )\n",
    "    price_pivot = orderbook_df.pivot(\n",
    "        index=\"start_time\", columns=\"unit_id\", values=\"price\"\n",
    "    )\n",
    "\n",
    "    # Calculate p_set, p_max_pu_up, and p_max_pu_down directly using DataFrame operations\n",
    "    p_set = volume_pivot\n",
    "\n",
    "    # Calculate p_max_pu_up as difference between max_power and accepted volume\n",
    "    p_max_pu_up = (max_power_pivot - volume_pivot).div(\n",
    "        max_power_pivot.where(max_power_pivot != 0, np.inf)\n",
    "    )\n",
    "\n",
    "    # Calculate p_max_pu_down as difference between accepted volume and min_power\n",
    "    p_max_pu_down = (volume_pivot - min_power_pivot).div(\n",
    "        max_power_pivot.where(max_power_pivot != 0, np.inf)\n",
    "    )\n",
    "    p_max_pu_down = p_max_pu_down.clip(lower=0)  # Ensure no negative values\n",
    "\n",
    "    # Determine the costs directly from the price pivot\n",
    "    costs = price_pivot\n",
    "\n",
    "    # Drop units with only negative volumes (if necessary)\n",
    "    negative_only_units = volume_pivot.lt(0).all()\n",
    "    p_max_pu_up = p_max_pu_up.drop(\n",
    "        columns=negative_only_units.index[negative_only_units]\n",
    "    )\n",
    "    p_max_pu_down = p_max_pu_down.drop(\n",
    "        columns=negative_only_units.index[negative_only_units]\n",
    "    )\n",
    "    costs = costs.drop(columns=negative_only_units.index[negative_only_units])\n",
    "\n",
    "    # reset indexes for all dataframes\n",
    "    p_set.reset_index(inplace=True, drop=True)\n",
    "    p_max_pu_up.reset_index(inplace=True, drop=True)\n",
    "    p_max_pu_down.reset_index(inplace=True, drop=True)\n",
    "    costs.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    # Update the network parameters\n",
    "    redispatch_network = self.network.copy()\n",
    "    redispatch_network.loads_t.p_set = p_set\n",
    "\n",
    "    # Update p_max_pu for generators with _up and _down suffixes\n",
    "    redispatch_network.generators_t.p_max_pu.update(p_max_pu_up.add_suffix(\"_up\"))\n",
    "    redispatch_network.generators_t.p_max_pu.update(p_max_pu_down.add_suffix(\"_down\"))\n",
    "\n",
    "    # Add _up and _down suffix to costs and update the network\n",
    "    redispatch_network.generators_t.marginal_cost.update(costs.add_suffix(\"_up\"))\n",
    "    redispatch_network.generators_t.marginal_cost.update(\n",
    "        costs.add_suffix(\"_down\") * (-1)\n",
    "    )\n",
    "\n",
    "    # run linear powerflow\n",
    "    redispatch_network.lpf()\n",
    "\n",
    "    # check lines for congestion where power flow is larget than s_nom\n",
    "    line_loading = redispatch_network.lines_t.p0.abs() / redispatch_network.lines.s_nom\n",
    "\n",
    "    # if any line is congested, perform redispatch\n",
    "    if line_loading.max().max() > 1:\n",
    "        status, termination_condition = redispatch_network.optimize(\n",
    "            solver_name=self.solver,\n",
    "            env=self.env,\n",
    "        )\n",
    "\n",
    "        if status != \"ok\":\n",
    "            raise Exception(\"Solver in redispatch market did not converge\")\n",
    "\n",
    "        # process dispatch data\n",
    "        self.process_dispatch_data(\n",
    "            network=redispatch_network, orderbook_df=orderbook_df\n",
    "        )\n",
    "\n",
    "    # return orderbook_df back to orderbook format as list of dicts\n",
    "    accepted_orders = orderbook_df.to_dict(\"records\")\n",
    "    rejected_orders = []\n",
    "    meta = []\n",
    "\n",
    "    # calculate meta data such as total upwared and downward redispatch, total backup dispatch\n",
    "    # and total redispatch cost\n",
    "    for i, product in enumerate(market_products):\n",
    "        meta.extend(\n",
    "            calculate_network_meta(network=redispatch_network, product=product, i=i)\n",
    "        )\n",
    "\n",
    "    return accepted_orders, rejected_orders, meta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
