{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtaining data for MA-DPG evaluation form example 02b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module imports\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# assume module imports\n",
    "import examples.examples as examples\n",
    "from assume import World\n",
    "from assume.scenario.loader_csv import load_file, load_scenario_folder\n",
    "from examples.notebooks.MPEC.utils import (\n",
    "    load_config,\n",
    "    plot_profit_comparison,\n",
    "    plot_sample_distribution,\n",
    "    retrieve_best_episode_actions,\n",
    "    run_MPEC,\n",
    "    sample_seasonal_weeks,\n",
    "    store_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting scenario parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = \"small_learning_2\"\n",
    "db_uri = \"postgresql://assume:assume@localhost:5432/assume\"\n",
    "inputs_dir = \"examples/inputs\"\n",
    "\n",
    "scenario = examples.available_examples[example][\"scenario\"]\n",
    "study_case = examples.available_examples[example][\"study_case\"]\n",
    "\n",
    "# Set up the database connection\n",
    "db = create_engine(db_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if current_dir := os.path.basename(os.getcwd()) == \"notebooks\":\n",
    "    %cd ../.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Retrieving the data from the best run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best actors directory\n",
    "best_actors_dir = os.path.join(\n",
    "    inputs_dir,\n",
    "    scenario,\n",
    "    \"learned_strategies\",\n",
    "    study_case,\n",
    "    \"avg_reward_eval_policies/actors/\",\n",
    ")\n",
    "# Retrieving all trained actors from the best actors directory\n",
    "actors = os.listdir(best_actors_dir)\n",
    "actors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Retrieving best run actions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_df = retrieve_best_episode_actions(inputs_dir, scenario, study_case, db)\n",
    "actions_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Getting the demand dataframe and power plant units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_case_config = load_config(inputs_dir, scenario, study_case)\n",
    "start = pd.Timestamp(study_case_config[\"start_date\"])\n",
    "end = pd.Timestamp(study_case_config[\"end_date\"])\n",
    "\n",
    "index = pd.date_range(\n",
    "    start=start,\n",
    "    end=end,\n",
    "    freq=study_case_config[\"time_step\"],\n",
    ")\n",
    "\n",
    "demand_df = load_file(\n",
    "    os.path.join(inputs_dir, scenario), study_case_config, \"demand_df\", index\n",
    ")\n",
    "demand_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_units = pd.read_csv(\n",
    "    os.path.join(inputs_dir, scenario, \"powerplant_units.csv\"), index_col=0\n",
    ")\n",
    "pp_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(inputs_dir, scenario)\n",
    "if f\"{study_case}_dispatch\" in config:\n",
    "    del config[f\"{study_case}_dispatch\"]\n",
    "# Copy the base and new base_dispatch configuration\n",
    "base_config = config[study_case].copy()\n",
    "base_dispatch = config[study_case].copy()\n",
    "base_dispatch[\"learning_config\"] = base_config[\"learning_config\"].copy()\n",
    "\n",
    "# Modify learning config parameters for base_dispatch\n",
    "base_dispatch[\"learning_config\"].update(\n",
    "    {\n",
    "        \"continue_learning\": False,\n",
    "        \"trained_policies_save_path\": \"learned_strategies/base_dispatch/last_policies\",\n",
    "        \"trained_policies_load_path\": \"learned_strategies/base_dispatch/avg_reward_eval_policies\",\n",
    "        \"training_episodes\": 0,\n",
    "        \"episodes_collecting_initial_experience\": 0,\n",
    "    }\n",
    ")\n",
    "\n",
    "base_dispatch.update(\n",
    "    {\n",
    "        \"learning_mode\": False,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Update the config with both sections\n",
    "config[study_case] = base_config\n",
    "config[f\"{study_case}_dispatch\"] = base_dispatch\n",
    "\n",
    "# Write the updated config back to file\n",
    "store_config(config, inputs_dir, scenario)\n",
    "\n",
    "# Define paths\n",
    "base_dir = Path(os.path.join(inputs_dir, scenario, f\"learned_strategies/{study_case}\"))\n",
    "dispatch_dir = Path(\n",
    "    os.path.join(inputs_dir, scenario, f\"learned_strategies/{study_case}_dispatch\")\n",
    ")\n",
    "\n",
    "# Check if source directory exists\n",
    "if not base_dir.exists():\n",
    "    print(f\"Source directory {base_dir} does not exist!\")\n",
    "elif dispatch_dir.exists():\n",
    "    print(f\"Target directory {dispatch_dir} already exists!\")\n",
    "else:\n",
    "    # Create target directory if it doesn't exist\n",
    "    dispatch_dir.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Copy directory\n",
    "    shutil.copytree(base_dir, dispatch_dir)\n",
    "    print(f\"Successfully copied {base_dir} to {dispatch_dir}\")\n",
    "\n",
    "world = World(database_uri=db_uri)\n",
    "\n",
    "load_scenario_folder(world, inputs_dir, scenario, f\"{study_case}_dispatch\")\n",
    "\n",
    "world.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = (\n",
    "    f\"SELECT * FROM unit_dispatch where simulation = '{scenario}_{study_case}_dispatch'\"\n",
    ")\n",
    "dispatch_df = pd.read_sql(query, db)\n",
    "dispatch_df = dispatch_df.drop_duplicates(subset=[\"time\", \"unit\"], keep=\"first\")\n",
    "\n",
    "dispatch_df = dispatch_df.sort_values(\"time\")\n",
    "dispatch_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"SELECT * FROM market_orders where simulation = '{scenario}_{study_case}'\"\n",
    "market_orders_df = pd.read_sql(query, db)\n",
    "\n",
    "market_orders_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Establish Sampling of days to be analysed\n",
    "\n",
    "Here we sample from the entire training data a subset of days, for which we test if the profit of all drl agents is similar to their MPEC formulation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = sample_seasonal_weeks(demand_df.index)\n",
    "sampled_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Get sample subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_df[\"date\"] = demand_df.index.date\n",
    "sample_demand_df = demand_df.loc[demand_df[\"date\"].isin(sampled_indices)]\n",
    "rest_demand_df = demand_df.loc[~demand_df[\"date\"].isin(sampled_indices)]\n",
    "sample_demand_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_df[\"date\"] = actions_df.index.date\n",
    "\n",
    "sample_actions_df = actions_df.loc[actions_df[\"date\"].isin(sampled_indices)]\n",
    "rest_actions_df = actions_df.loc[~actions_df[\"date\"].isin(sampled_indices)]\n",
    "sample_actions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatch_df.index = pd.to_datetime(dispatch_df[\"time\"])\n",
    "dispatch_df.drop(columns=[\"time\"], inplace=True)\n",
    "dispatch_df[\"date\"] = dispatch_df.index.date\n",
    "\n",
    "sample_dispatch_df = dispatch_df.loc[dispatch_df[\"date\"].isin(sampled_indices)]\n",
    "rest_dispatch_df = dispatch_df.loc[~dispatch_df[\"date\"].isin(sampled_indices)]\n",
    "sample_dispatch_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample market orders as well\n",
    "market_orders_df.index = pd.to_datetime(market_orders_df[\"start_time\"])\n",
    "market_orders_df = market_orders_df.drop(columns=[\"start_time\"])\n",
    "market_orders_df[\"date\"] = market_orders_df.index.date\n",
    "\n",
    "sample_market_orders_df = market_orders_df.loc[\n",
    "    market_orders_df[\"date\"].isin(sampled_indices)\n",
    "]\n",
    "rest_market_orders_df = market_orders_df.loc[\n",
    "    ~market_orders_df[\"date\"].isin(sampled_indices)\n",
    "]\n",
    "sample_market_orders_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Analyse sample distribution in comparison to entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sample_distribution(sample_demand_df, rest_demand_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Bi-Level Optimisation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defintion for case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_w = 100000  # weight for duality gap objective\n",
    "k_max = 2  # maximum multiplier for strategic bidding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input data transformation for Optimisation Problem "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gens\n",
    "gens_df = pp_units.copy()\n",
    "\n",
    "# Transform gen_df into the format that is expected by the optimization problem\n",
    "# g_max\tmc\tu_0\tg_0\tr_up\tr_down\tk_up\tk_down\n",
    "gens_df = gens_df.reset_index()\n",
    "gens_df = gens_df.rename(columns={\"max_power\": \"g_max\", \"min_power\": \"u_0\"})\n",
    "gens_df[\"r_up\"] = gens_df[\"g_max\"]  # ramping up constraints\n",
    "gens_df[\"r_down\"] = gens_df[\"g_max\"]  # ramping down constraints\n",
    "gens_df[\"k_up\"] = 0  # start up costs\n",
    "gens_df[\"k_down\"] = 0  # shut down costs\n",
    "gens_df[\"g_0\"] = 0  # start with no power output\n",
    "\n",
    "# get average mc from dispatch_df per unit name\n",
    "mc = dispatch_df.groupby(\"unit\")[\"energy_marginal_costs\"].mean()\n",
    "\n",
    "# based on name and unit column join mc into gens_df\n",
    "gens_df = gens_df.merge(mc, left_on=\"name\", right_on=\"unit\", how=\"left\")\n",
    "gens_df = gens_df.rename(columns={\"energy_marginal_costs\": \"mc\"})\n",
    "gens_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translate actions of RL model into k_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge on both 'unit_id' and 'time' columns\n",
    "merged_df = sample_market_orders_df.merge(\n",
    "    sample_dispatch_df.reset_index(),\n",
    "    left_on=[\"unit_id\", \"start_time\"],\n",
    "    right_on=[\"unit\", \"time\"],\n",
    "    how=\"right\",\n",
    ")\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: how to translate the 2 actions per unit into one k_value? Currently:\n",
    "# get max price per unit_id and date in the dataframe\n",
    "id_k = merged_df.groupby([\"unit_id\", \"time\"])[\"price\"].idxmax()\n",
    "k_df = merged_df.loc[id_k]\n",
    "k_df = k_df[k_df[\"unit_id\"].isin(gens_df[\"name\"])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_mapping = dict(zip(gens_df[\"name\"], gens_df[\"mc\"]))\n",
    "k_df[\"gens_df_mc\"] = k_df[\"unit_id\"].map(mc_mapping)\n",
    "\n",
    "# transformed actions into k_values, one per generator\n",
    "k_df[\"k\"] = k_df[\"price\"] / k_df[\"gens_df_mc\"]\n",
    "\n",
    "# replace inf with 0\n",
    "k_df[\"k\"] = k_df[\"k\"].replace(np.inf, 0)\n",
    "\n",
    "k_values_df = k_df.pivot(index=\"time\", columns=\"unit_id\", values=\"k\")\n",
    "# k_values_df.reset_index(inplace=True)\n",
    "\n",
    "# sort columns to match the order of the columns in the gens_df\n",
    "k_values_df = k_values_df[gens_df[\"name\"].values]\n",
    "k_values_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join demand and price bid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join sample demand df and sample market orders where unit id is demand_EOM based on index\n",
    "sample_demand_df[\"price\"] = sample_market_orders_df[\n",
    "    sample_market_orders_df[\"unit_id\"] == \"demand_EOM\"\n",
    "][\"price\"]\n",
    "\n",
    "# drop time column\n",
    "sample_demand_df = sample_demand_df.drop(columns=[\"date\"])\n",
    "\n",
    "# rename index and columns\n",
    "sample_demand_df.index.name = \"datetime\"\n",
    "sample_demand_df.columns = [\"volume\", \"price\"]\n",
    "demand_df = sample_demand_df.copy()\n",
    "demand_df.index = pd.to_datetime(demand_df.index)\n",
    "demand_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run MPEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = pd.to_datetime(\"2019-05-13 09:00\")\n",
    "end = pd.to_datetime(\"2019-05-13 13:00\")\n",
    "index = pd.date_range(start, end, freq=\"h\")\n",
    "\n",
    "opt_gen = 5\n",
    "\n",
    "profits_1, profits_2 = run_MPEC(\n",
    "    opt_gen, index, gens_df, demand_df, k_values_df, k_max, big_w\n",
    ")\n",
    "\n",
    "print(\"\")\n",
    "print('Optimisation results:')\n",
    "print(f\"Estimated Profits: {profits_1[opt_gen].sum():.2f}\")\n",
    "print(f\"True profits: {profits_2[opt_gen].sum():.2f}\")\n",
    "\n",
    "cashflow = sample_dispatch_df[\n",
    "    sample_dispatch_df[\"unit\"] == gens_df.loc[opt_gen][\"name\"]\n",
    "].loc[start:end][\"energy_cashflow\"]\n",
    "costs = sample_dispatch_df[\n",
    "    sample_dispatch_df[\"unit\"] == gens_df.loc[opt_gen][\"name\"]\n",
    "].loc[start:end][\"total_costs\"]\n",
    "\n",
    "profit = (cashflow - costs).sum()\n",
    "\n",
    "print(\"\")\n",
    "print(\"Learning results:\")\n",
    "print(f\"Profits: {profit:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop over different units and weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_gens = sorted(\n",
    "    [int(actor.split(\"_\")[-1].split(\".\")[0]) for actor in actors], key=int\n",
    ")\n",
    "# Get unique year-month combinations to filter for different weeks\n",
    "unique_year_months = set((date.year, date.month) for date in sampled_indices)\n",
    "\n",
    "df_estimated = pd.DataFrame(columns=[f\"Unit_{opt_gen}\" for opt_gen in opt_gens])\n",
    "df_true = pd.DataFrame(columns=[f\"Unit_{opt_gen}\" for opt_gen in opt_gens])\n",
    "\n",
    "for i, (year, month) in enumerate(unique_year_months):\n",
    "    filtered_indices = [\n",
    "        date for date in sampled_indices if date.year == year and date.month == month\n",
    "    ]\n",
    "    df_estimated_tmp = pd.DataFrame(columns=[f\"Unit_{opt_gen}\" for opt_gen in opt_gens])\n",
    "    df_true_tmp = pd.DataFrame(columns=[f\"Unit_{opt_gen}\" for opt_gen in opt_gens])\n",
    "    for opt_gen in opt_gens:\n",
    "        profits_1, profits_2 = run_MPEC(\n",
    "            opt_gen, index, gens_df, demand_df, k_values_df, k_max, big_w\n",
    "        )\n",
    "        df_estimated_tmp[f\"Unit_{opt_gen}\"] = profits_1[opt_gen]\n",
    "        df_true_tmp[f\"Unit_{opt_gen}\"] = profits_2[opt_gen]\n",
    "    df_estimated = pd.concat([df_estimated, df_estimated_tmp])\n",
    "    df_true = pd.concat([df_true, df_true_tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check why double the amount of columns\n",
    "\n",
    "df_estimated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame zur Speicherung der Profite pro Unit\n",
    "df_rl = pd.DataFrame()\n",
    "\n",
    "# Über alle Units iterieren\n",
    "for opt_gen in gens_df.index:\n",
    "    unit_name = gens_df.loc[opt_gen][\"name\"]\n",
    "\n",
    "    # Cashflow und Kosten für die spezifische Unit und Zeitraum extrahieren\n",
    "    unit_data = sample_dispatch_df[sample_dispatch_df[\"unit\"] == unit_name].loc[start:end]\n",
    "    cashflow = unit_data[\"energy_cashflow\"]\n",
    "    costs = unit_data[\"total_costs\"]\n",
    "\n",
    "    # Profit als Differenz\n",
    "    profit_series = cashflow - costs\n",
    "\n",
    "    # Ergebnisse in den DataFrame einfügen\n",
    "    df_rl[unit_name] = profit_series.reset_index(drop=True)\n",
    "    \n",
    "    #rename pp_x columns zu unit_x columns\n",
    "    df_rl = df_rl.rename(columns={col: col.replace('pp_', 'Unit_') for col in df_rl.columns})\n",
    "    \n",
    "# drop all unit columns that are not in df_real columns\n",
    "df_rl = df_rl[df_true.columns] \n",
    "\n",
    "df_rl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fix plot?\n",
    "\n",
    "# Create and show the plot\n",
    "fig = plot_profit_comparison(df_rl, df_true)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assume",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
