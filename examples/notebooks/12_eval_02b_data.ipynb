{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtaining data for MA-DPG evaluation form example 02b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module imports\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# assume module imports\n",
    "import examples.examples as examples\n",
    "import examples.notebooks.MPEC.utils as utils\n",
    "from assume import World\n",
    "from assume.scenario.loader_csv import load_file, load_scenario_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting scenario parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tg3533\\Documents\\Code\\assume\n"
     ]
    }
   ],
   "source": [
    "if current_dir := os.path.basename(os.getcwd()) == \"notebooks\":\n",
    "    %cd ../..\n",
    "\n",
    "example = \"small_learning_2\"\n",
    "db_uri = \"postgresql://assume:assume@localhost:5432/assume\"\n",
    "inputs_dir = \"examples/inputs\"\n",
    "\n",
    "scenario = examples.available_examples[example][\"scenario\"]\n",
    "study_case = examples.available_examples[example][\"study_case\"]\n",
    "\n",
    "# Set up the database connection\n",
    "db = create_engine(db_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Retrieving the data from the best run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Retrieving best run actions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tg3533\\Documents\\Code\\assume\\examples\\notebooks\\MPEC\\utils.py:269: FutureWarning:\n",
      "\n",
      "The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "nan",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m actions_df \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve_best_episode_actions\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscenario\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstudy_case\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m actions_df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32m~\\Documents\\Code\\assume\\examples\\notebooks\\MPEC\\utils.py:271\u001b[0m, in \u001b[0;36mretrieve_best_episode_actions\u001b[1;34m(inputs_dir, scenario, study_case, db)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;66;03m# Use the episode with the best reward to get the respective actions\u001b[39;00m\n\u001b[0;32m    269\u001b[0m best_episode \u001b[38;5;241m=\u001b[39m reward_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavg_reward\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39midxmax()\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m--> 271\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest episode: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_episode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m found with an average reward of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mreward_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mat\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbest_episode\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mavg_reward\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    272\u001b[0m )\n\u001b[0;32m    274\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT datetime as dt, unit, actions_0, actions_1 FROM rl_params where simulation = \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msimulation\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_episode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    275\u001b[0m actions_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_sql(query, db)\n",
      "File \u001b[1;32mc:\\Users\\tg3533\\AppData\\Local\\miniconda3\\envs\\assume-framework\\Lib\\site-packages\\pandas\\core\\indexing.py:2575\u001b[0m, in \u001b[0;36m_AtIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2572\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid call for scalar access (getting)!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2573\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mloc[key]\n\u001b[1;32m-> 2575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tg3533\\AppData\\Local\\miniconda3\\envs\\assume-framework\\Lib\\site-packages\\pandas\\core\\indexing.py:2527\u001b[0m, in \u001b[0;36m_ScalarAccessIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2524\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid call for scalar access (getting)!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2526\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_key(key)\n\u001b[1;32m-> 2527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtakeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_takeable\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tg3533\\AppData\\Local\\miniconda3\\envs\\assume-framework\\Lib\\site-packages\\pandas\\core\\frame.py:4221\u001b[0m, in \u001b[0;36mDataFrame._get_value\u001b[1;34m(self, index, col, takeable)\u001b[0m\n\u001b[0;32m   4215\u001b[0m engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_engine\n\u001b[0;32m   4217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, MultiIndex):\n\u001b[0;32m   4218\u001b[0m     \u001b[38;5;66;03m# CategoricalIndex: Trying to use the engine fastpath may give incorrect\u001b[39;00m\n\u001b[0;32m   4219\u001b[0m     \u001b[38;5;66;03m#  results if our categories are integers that dont match our codes\u001b[39;00m\n\u001b[0;32m   4220\u001b[0m     \u001b[38;5;66;03m# IntervalIndex: IntervalTree has no get_loc\u001b[39;00m\n\u001b[1;32m-> 4221\u001b[0m     row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m series\u001b[38;5;241m.\u001b[39m_values[row]\n\u001b[0;32m   4224\u001b[0m \u001b[38;5;66;03m# For MultiIndex going through engine effectively restricts us to\u001b[39;00m\n\u001b[0;32m   4225\u001b[0m \u001b[38;5;66;03m#  same-length tuples; see test_get_set_value_no_partial_indexing\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tg3533\\AppData\\Local\\miniconda3\\envs\\assume-framework\\Lib\\site-packages\\pandas\\core\\indexes\\range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[1;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: nan"
     ]
    }
   ],
   "source": [
    "actions_df = utils.retrieve_best_episode_actions(inputs_dir, scenario, study_case, db)\n",
    "actions_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Getting the demand dataframe and power plant units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_case_config = utils.load_config(inputs_dir, scenario, study_case)\n",
    "start = pd.Timestamp(study_case_config[\"start_date\"])\n",
    "end = pd.Timestamp(study_case_config[\"end_date\"])\n",
    "\n",
    "index = pd.date_range(\n",
    "    start=start,\n",
    "    end=end,\n",
    "    freq=study_case_config[\"time_step\"],\n",
    ")\n",
    "\n",
    "demand_df = load_file(\n",
    "    os.path.join(inputs_dir, scenario), study_case_config, \"demand_df\", index\n",
    ")\n",
    "demand_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_units = pd.read_csv(\n",
    "    os.path.join(inputs_dir, scenario, \"powerplant_units.csv\"), index_col=0\n",
    ")\n",
    "pp_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = utils.load_config(inputs_dir, scenario)\n",
    "if f\"{study_case}_dispatch\" in config:\n",
    "    del config[f\"{study_case}_dispatch\"]\n",
    "# Copy the base and new base_dispatch configuration\n",
    "base_config = config[study_case].copy()\n",
    "base_dispatch = config[study_case].copy()\n",
    "base_dispatch[\"learning_config\"] = base_config[\"learning_config\"].copy()\n",
    "\n",
    "# Modify learning config parameters for base_dispatch\n",
    "base_dispatch[\"learning_config\"].update(\n",
    "    {\n",
    "        \"continue_learning\": False,\n",
    "        \"trained_policies_save_path\": \"learned_strategies/base_dispatch/last_policies\",\n",
    "        \"trained_policies_load_path\": \"learned_strategies/base_dispatch/avg_reward_eval_policies\",\n",
    "        \"training_episodes\": 0,\n",
    "        \"episodes_collecting_initial_experience\": 0,\n",
    "    }\n",
    ")\n",
    "\n",
    "base_dispatch.update(\n",
    "    {\n",
    "        \"learning_mode\": False,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Update the config with both sections\n",
    "config[study_case] = base_config\n",
    "config[f\"{study_case}_dispatch\"] = base_dispatch\n",
    "\n",
    "# Write the updated config back to file\n",
    "utils.store_config(config, inputs_dir, scenario)\n",
    "\n",
    "# Define paths\n",
    "base_dir = Path(\n",
    "    os.path.join(inputs_dir, scenario, f\"learned_strategies/{scenario}_{study_case}\")\n",
    ")\n",
    "dispatch_dir = Path(\n",
    "    os.path.join(inputs_dir, scenario, f\"learned_strategies/{study_case}_dispatch\")\n",
    ")\n",
    "\n",
    "# Check if source directory exists\n",
    "if not base_dir.exists():\n",
    "    print(f\"Source directory {base_dir} does not exist!\")\n",
    "elif dispatch_dir.exists():\n",
    "    print(f\"Target directory {dispatch_dir} already exists!\")\n",
    "else:\n",
    "    # Create target directory if it doesn't exist\n",
    "    dispatch_dir.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Copy directory\n",
    "    shutil.copytree(base_dir, dispatch_dir)\n",
    "    print(f\"Successfully copied {base_dir} to {dispatch_dir}\")\n",
    "\n",
    "world = World(database_uri=db_uri)\n",
    "\n",
    "load_scenario_folder(world, inputs_dir, scenario, f\"{study_case}_dispatch\")\n",
    "\n",
    "world.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = (\n",
    "    f\"SELECT * FROM unit_dispatch where simulation = '{scenario}_{study_case}_dispatch'\"\n",
    ")\n",
    "dispatch_df = pd.read_sql(query, db)\n",
    "dispatch_df = dispatch_df.drop_duplicates(subset=[\"time\", \"unit\"], keep=\"first\")\n",
    "\n",
    "dispatch_df = dispatch_df.sort_values(\"time\")\n",
    "dispatch_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"SELECT * FROM market_orders where simulation = '{scenario}_{study_case}'\"\n",
    "market_orders_df = pd.read_sql(query, db)\n",
    "market_orders_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Establish Sampling of days to be analysed\n",
    "\n",
    "Here we sample from the entire training data a subset of days, for which we test if the profit of all drl agents is similar to their MPEC formulation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = utils.sample_seasonal_weeks(demand_df.index)\n",
    "# TODO: LÖSCHEN NUR FÜR FASTER SOLAVBIILTY AS 1 Week runs into run time limit\n",
    "sampled_indices = sampled_indices[:1]\n",
    "\n",
    "sampled_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Get sample subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_df[\"date\"] = demand_df.index.date\n",
    "sample_demand_df = demand_df.loc[demand_df[\"date\"].isin(sampled_indices)]\n",
    "rest_demand_df = demand_df.loc[~demand_df[\"date\"].isin(sampled_indices)]\n",
    "sample_demand_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_df[\"date\"] = actions_df.index.date\n",
    "\n",
    "sample_actions_df = actions_df.loc[actions_df[\"date\"].isin(sampled_indices)]\n",
    "rest_actions_df = actions_df.loc[~actions_df[\"date\"].isin(sampled_indices)]\n",
    "sample_actions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatch_df.index = pd.to_datetime(dispatch_df[\"time\"])\n",
    "dispatch_df.drop(columns=[\"time\"], inplace=True)\n",
    "dispatch_df[\"date\"] = dispatch_df.index.date\n",
    "\n",
    "sample_dispatch_df = dispatch_df.loc[dispatch_df[\"date\"].isin(sampled_indices)]\n",
    "rest_dispatch_df = dispatch_df.loc[~dispatch_df[\"date\"].isin(sampled_indices)]\n",
    "sample_dispatch_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample market orders as well\n",
    "market_orders_df.index = pd.to_datetime(market_orders_df[\"start_time\"])\n",
    "market_orders_df = market_orders_df.drop(columns=[\"start_time\"])\n",
    "market_orders_df[\"date\"] = market_orders_df.index.date\n",
    "\n",
    "sample_market_orders_df = market_orders_df.loc[\n",
    "    market_orders_df[\"date\"].isin(sampled_indices)\n",
    "]\n",
    "rest_market_orders_df = market_orders_df.loc[\n",
    "    ~market_orders_df[\"date\"].isin(sampled_indices)\n",
    "]\n",
    "sample_market_orders_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Analyse sample distribution in comparison to entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_sample_distribution(sample_demand_df, rest_demand_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Bi-Level Optimisation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defintion for case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_w = 100000  # weight for duality gap objective\n",
    "k_max = 2  # maximum multiplier for strategic bidding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input data transformation for Optimisation Problem "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gens\n",
    "gens_df = utils.create_gens_df(pp_units, dispatch_df)\n",
    "gens_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translate actions of RL model into k_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge on both 'unit_id' and 'time' columns\n",
    "merged_df = sample_market_orders_df.merge(\n",
    "    sample_dispatch_df.reset_index(),\n",
    "    left_on=[\"unit_id\", \"start_time\"],\n",
    "    right_on=[\"unit\", \"time\"],\n",
    "    how=\"right\",\n",
    ")\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: how to translate the 2 actions per unit into one k_value? Currently:\n",
    "# get max price per unit_id and date in the dataframe\n",
    "id_k = merged_df.groupby([\"unit_id\", \"time\"])[\"price\"].idxmax()\n",
    "k_df = merged_df.loc[id_k]\n",
    "\n",
    "# overwrite price with 0 if price is negative\n",
    "# TODO: LÖSCHEN nur für Debugging\n",
    "k_df[\"price\"] = k_df[\"price\"].clip(lower=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values_df = utils.obtain_k_values(k_df, gens_df)\n",
    "k_values_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join demand and price bid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_df = utils.join_demand_market_orders(sample_demand_df, sample_market_orders_df)\n",
    "demand_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run MPEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = pd.to_datetime(\"2019-03-04 06:00\")\n",
    "end = pd.to_datetime(\"2019-03-04 16:00\")\n",
    "index = pd.date_range(start, end, freq=\"h\")\n",
    "\n",
    "opt_gen = 5\n",
    "\n",
    "\n",
    "demand_df_short = demand_df.copy().loc[index]\n",
    "demand_df_short.drop(columns=[\"date\"], inplace=True)\n",
    "\n",
    "k_values_df_short = k_values_df.copy().loc[index]\n",
    "k_values_df_short.drop(columns=[\"date\"], inplace=True)\n",
    "\n",
    "profits_1, profits_2 = utils.run_MPEC(\n",
    "    opt_gen, gens_df, demand_df_short, k_values_df_short, k_max, big_w\n",
    ")\n",
    "\n",
    "print(\"\")\n",
    "print(\"Optimisation results:\")\n",
    "print(f\"Estimated Profits: {profits_1[opt_gen].sum():.2f}\")\n",
    "print(f\"True profits: {profits_2[opt_gen].sum():.2f}\")\n",
    "\n",
    "cashflow = sample_dispatch_df[\n",
    "    sample_dispatch_df[\"unit\"] == gens_df.loc[opt_gen][\"name\"]\n",
    "].loc[start:end][\"energy_cashflow\"]\n",
    "costs = sample_dispatch_df[\n",
    "    sample_dispatch_df[\"unit\"] == gens_df.loc[opt_gen][\"name\"]\n",
    "].loc[start:end][\"total_costs\"]\n",
    "\n",
    "profit = (cashflow - costs).sum()\n",
    "\n",
    "print(\"\")\n",
    "print(\"Learning results:\")\n",
    "print(f\"Profits: {profit:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop over different units and weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_units = gens_df[gens_df[\"bidding_EOM\"] == \"pp_learning\"][\"name\"].values\n",
    "opt_gens = sorted([int(unit.split(\"_\")[-1]) for unit in rl_units], key=int)\n",
    "\n",
    "# Get unique year-month combinations to filter for different weeks\n",
    "unique_year_months = set((date.year, date.month) for date in sampled_indices)\n",
    "\n",
    "df_estimated = pd.DataFrame(columns=[f\"Unit_{opt_gen}\" for opt_gen in opt_gens])\n",
    "df_true = pd.DataFrame(columns=[f\"Unit_{opt_gen}\" for opt_gen in opt_gens])\n",
    "\n",
    "for i, (year, month) in enumerate(unique_year_months):\n",
    "    filtered_indices = [\n",
    "        date for date in sampled_indices if date.year == year and date.month == month\n",
    "    ]\n",
    "    demand_df_filtered = demand_df.copy().loc[demand_df[\"date\"].isin(filtered_indices)]\n",
    "    demand_df_filtered.drop(columns=[\"date\"], inplace=True)\n",
    "\n",
    "    k_values_df_filtered = k_values_df.copy().loc[\n",
    "        k_values_df[\"date\"].isin(filtered_indices)\n",
    "    ]\n",
    "    k_values_df_filtered.drop(columns=[\"date\"], inplace=True)\n",
    "    df_estimated_tmp = pd.DataFrame(columns=[f\"Unit_{opt_gen}\" for opt_gen in opt_gens])\n",
    "    df_true_tmp = pd.DataFrame(columns=[f\"Unit_{opt_gen}\" for opt_gen in opt_gens])\n",
    "    for opt_gen in opt_gens:\n",
    "        print(\"We now optimize the decison for unit_\", opt_gen)\n",
    "        profits_1, profits_2 = utils.run_MPEC(\n",
    "            opt_gen - 1, gens_df, demand_df_filtered, k_values_df_filtered, k_max, big_w\n",
    "        )\n",
    "        df_estimated_tmp[f\"Unit_{opt_gen}\"] = profits_1[opt_gen - 1]\n",
    "        df_true_tmp[f\"Unit_{opt_gen}\"] = profits_2[opt_gen - 1]\n",
    "    df_estimated = pd.concat([df_estimated, df_estimated_tmp])\n",
    "    df_true = pd.concat([df_true, df_true_tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_estimated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame zur Speicherung der Profite pro Unit\n",
    "df_rl = pd.DataFrame()\n",
    "\n",
    "# Über alle Units iterieren\n",
    "for opt_gen in gens_df.index:\n",
    "    unit_name = gens_df.loc[opt_gen][\"name\"]\n",
    "\n",
    "    # Cashflow und Kosten für die spezifische Unit und Zeitraum extrahieren\n",
    "    unit_data = sample_dispatch_df[sample_dispatch_df[\"unit\"] == unit_name]\n",
    "    cashflow = unit_data[\"energy_cashflow\"]\n",
    "    costs = unit_data[\"total_costs\"]\n",
    "\n",
    "    # Profit als Differenz\n",
    "    profit_series = cashflow - costs\n",
    "\n",
    "    # Ergebnisse in den DataFrame einfügen\n",
    "    df_rl[unit_name] = profit_series.reset_index(drop=True)\n",
    "\n",
    "    # rename pp_x columns zu unit_x columns\n",
    "    df_rl = df_rl.rename(\n",
    "        columns={col: col.replace(\"pp_\", \"Unit_\") for col in df_rl.columns}\n",
    "    )\n",
    "\n",
    "# drop all unit columns that are not in df_real columns\n",
    "df_rl = df_rl[df_true.columns]\n",
    "\n",
    "df_rl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare sum per unit betwenn df_rl and df_true\n",
    "df_rl.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and show the plot\n",
    "# TODO: Use daily mean for plot\n",
    "fig = utils.plot_profit_comparison(df_rl, df_true)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assume-framework",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
