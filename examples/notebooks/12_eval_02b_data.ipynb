{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtaining data for MA-DPG evaluation form example 02b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module imports\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# assume module imports\n",
    "import examples.examples as examples\n",
    "from assume import World\n",
    "from assume.scenario.loader_csv import load_scenario_folder, run_learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Running example 02b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = \"small_learning_2\"\n",
    "db_uri = \"sqlite:///../local_db/assume_db.db\"\n",
    "inputs_dir = \"../inputs\"\n",
    "scenario = examples.available_examples[example][\"scenario\"]\n",
    "study_case = examples.available_examples[example][\"study_case\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run example 02b\n",
    "world = World(database_uri=db_uri, export_csv_path=\"../\" + examples.csv_path)\n",
    "load_scenario_folder(world, inputs_dir, scenario, study_case)\n",
    "run_learning(\n",
    "    world,\n",
    "    inputs_dir,\n",
    "    scenario,\n",
    "    study_case,\n",
    ")\n",
    "world.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Retrieving the actions of the actors from the best run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best actors directory\n",
    "best_actors_dir = os.path.join(\n",
    "    inputs_dir,\n",
    "    scenario,\n",
    "    \"learned_strategies\",\n",
    "    study_case,\n",
    "    \"avg_reward_eval_policies/actors/\",\n",
    ")\n",
    "actors = os.listdir(best_actors_dir)\n",
    "actors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Option 1: Retrieving the actions from the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the config file\n",
    "config_path = os.path.join(inputs_dir, scenario, \"config.yaml\")\n",
    "\n",
    "# Read the number of validation episodes from the config file\n",
    "with open(config_path) as file:\n",
    "    config = yaml.safe_load(file)\n",
    "learning_config = config[study_case][\"learning_config\"]\n",
    "no_of_val_episodes = (\n",
    "    learning_config[\"training_episodes\"]\n",
    "    - learning_config[\"episodes_collecting_initial_experience\"]\n",
    ") // learning_config.get(\"validation_episodes_interval\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the database connection\n",
    "db = create_engine(db_uri)\n",
    "simulation = f\"{scenario}_{study_case}_eval\"\n",
    "\n",
    "# Get the average reward for each episode in order to determine the best episode.\n",
    "reward_df = pd.DataFrame(columns=[\"avg_reward\"], index=range(1, no_of_val_episodes + 1))\n",
    "for episode in range(1, no_of_val_episodes + 1):\n",
    "    query = f\"SELECT AVG(reward) as avg_reward FROM rl_params where simulation = '{simulation}_{episode}'\"\n",
    "    reward_df.at[episode, \"avg_reward\"] = pd.read_sql(query, db).values[0][0]\n",
    "reward_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode = reward_df[\"avg_reward\"].idxmax()\n",
    "query = f\"SELECT datetime as dt, unit, actions_0, actions_1 FROM rl_params where simulation = '{simulation}_{episode}'\"\n",
    "actions_df = pd.read_sql(query, db)\n",
    "actions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Option 2: Getting the actions through the model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "# obs_dim = len(feature_names)\n",
    "# act_dim = 2  # Adjust if your model outputs a different number of actions\n",
    "# model = MLPActor(obs_dim=obs_dim, act_dim=act_dim, float_type=th.float)\n",
    "\n",
    "# # Path to actors we want to get actions from\n",
    "# for actor in actors:\n",
    "#     actor_path = os.path.join(best_actors_dir, actor)\n",
    "\n",
    "#     # Load the trained model parameters\n",
    "#     model_state = th.load(actor_path, map_location=th.device(\"cpu\"))\n",
    "#     model.load_state_dict(model_state[\"actor\"])\n",
    "\n",
    "#     actions = []\n",
    "#     for obs in input_data:\n",
    "#         obs_tensor = th.tensor(obs, dtype=th.float)\n",
    "#         action = model(obs_tensor)\n",
    "#         actions.append(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Getting the demand dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_df = pd.read_csv(os.path.join(inputs_dir, scenario, \"demand_df.csv\"))\n",
    "demand_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assume",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
