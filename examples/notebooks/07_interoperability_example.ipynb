{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4JeBorbE6FYr"
   },
   "source": [
    "# 7. Interoperability and Input-Output\n",
    "\n",
    "This tutorial describes how ASSUME can be used to create market simulations from energy system simulations as well as other market simulations like AMIRIS.\n",
    "A broad comparison towards AMIRIS is submitted to the EEM2024.\n",
    "\n",
    "This tutorial describes how one can create scenarios from different input sets and use existing scenarios from it.\n",
    "\n",
    "\n",
    "**As a whole, this tutorial covers the following**\n",
    "\n",
    "1. running a small scenario from CSV folder with the CLI\n",
    "\n",
    "2. creating a small simulation from scratch as shown in tutorial 01\n",
    "\n",
    "3. load a scenario from an AMIRIS scenario.yaml\n",
    "\n",
    "4. load a scenario from a pypsa network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Scenario from CLI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to install assume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the ASSUME framework with the PyPSA library for network optimization\n",
    "import importlib.util\n",
    "\n",
    "# Check if 'google.colab' is available\n",
    "IN_COLAB = importlib.util.find_spec(\"google.colab\") is not None\n",
    "if IN_COLAB:\n",
    "    !pip install assume-framework[network]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we run in Google Colab, we need to first clone the ASSUME repository there to access the tutorial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    !git clone --depth=1 https://github.com/assume-framework/assume.git assume-repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the CLI script to run a simulation - relative to the examples folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    !cd assume-repo && assume -s example_01a -c tiny -db \"sqlite:///local_db/assume_db.db\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Protip: with argcomplete - one can create very nice tab completion for python scripts.\n",
    "\n",
    "Though one has to run `eval \"$(register-python-argcomplete assume)\"` once in the env before (for Linux and Mac). On Windows, one needs to run:\n",
    "`register-python-argcomplete --shell powershell assume | Out-String | Invoke-Expression`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did not use the postgresql database - therefore we can not use our visualization - lets fix this. **You need to have have postgresql and grafana installed (available through docker).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!assume -s example_01a -c base -db \"postgresql://assume:assume@localhost:5432/assume\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are running locally and have our docker with the database and the Grafan dashboards installed, we can now look at the results here:\n",
    "\n",
    "http://localhost:3000/?orgId=1&var-simulation=example_01a_base&from=1546300800000&to=1548892800000&refresh=5s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run from a script to customize scenario yourself\n",
    "\n",
    "This is a more advanced option - though it gives full control on what we are doing here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:assume.world:connected to db\n",
      "INFO:assume.world:activating container\n",
      "INFO:assume.world:all agents up - starting simulation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "world_script_simulation 2023-03-31 00:00:00: : 7689601.0it [00:28, 274545.65it/s]                           \n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "from dateutil import rrule as rr\n",
    "\n",
    "from assume import World\n",
    "from assume.common.forecasts import NaiveForecast\n",
    "from assume.common.market_objects import MarketConfig, MarketProduct\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "os.makedirs(\"./local_db\", exist_ok=True)\n",
    "\n",
    "db_uri = \"sqlite:///./local_db/assume_db.db\"\n",
    "\n",
    "world = World(database_uri=db_uri)\n",
    "\n",
    "start = datetime(2023, 1, 1)\n",
    "end = datetime(2023, 3, 31)\n",
    "index = pd.date_range(\n",
    "    start=start,\n",
    "    end=end + timedelta(hours=24),\n",
    "    freq=\"h\",\n",
    ")\n",
    "sim_id = \"world_script_simulation\"\n",
    "\n",
    "world.loop.run_until_complete(\n",
    "    world.setup(\n",
    "        start=start,\n",
    "        end=end,\n",
    "        save_frequency_hours=48,\n",
    "        simulation_id=sim_id,\n",
    "        index=index,\n",
    "    )\n",
    ")\n",
    "\n",
    "marketdesign = [\n",
    "    MarketConfig(\n",
    "        market_id=\"EOM\",\n",
    "        opening_hours=rr.rrule(rr.HOURLY, interval=24, dtstart=start, until=end),\n",
    "        opening_duration=timedelta(hours=1),\n",
    "        market_mechanism=\"pay_as_clear\",\n",
    "        market_products=[MarketProduct(timedelta(hours=1), 24, timedelta(hours=1))],\n",
    "        additional_fields=[\"block_id\", \"link\", \"exclusive_id\"],\n",
    "    )\n",
    "]\n",
    "\n",
    "mo_id = \"market_operator\"\n",
    "world.add_market_operator(id=mo_id)\n",
    "\n",
    "for market_config in marketdesign:\n",
    "    world.add_market(market_operator_id=mo_id, market_config=market_config)\n",
    "\n",
    "    world.add_unit_operator(\"demand_operator\")\n",
    "\n",
    "demand_forecast = NaiveForecast(index, demand=100)\n",
    "\n",
    "world.add_unit(\n",
    "    id=\"demand_unit\",\n",
    "    unit_type=\"demand\",\n",
    "    unit_operator_id=\"demand_operator\",\n",
    "    unit_params={\n",
    "        \"min_power\": 0,\n",
    "        \"max_power\": 1000,\n",
    "        \"bidding_strategies\": {\"EOM\": \"naive_eom\"},\n",
    "        \"technology\": \"demand\",\n",
    "    },\n",
    "    forecaster=demand_forecast,\n",
    ")\n",
    "\n",
    "world.add_unit_operator(\"unit_operator\")\n",
    "\n",
    "nuclear_forecast = NaiveForecast(index, availability=1, fuel_price=3, co2_price=0.1)\n",
    "\n",
    "world.add_unit(\n",
    "    id=\"nuclear_unit\",\n",
    "    unit_type=\"power_plant\",\n",
    "    unit_operator_id=\"unit_operator\",\n",
    "    unit_params={\n",
    "        \"min_power\": 200,\n",
    "        \"max_power\": 1000,\n",
    "        \"bidding_strategies\": {\"EOM\": \"naive_eom\"},\n",
    "        \"technology\": \"nuclear\",\n",
    "    },\n",
    "    forecaster=nuclear_forecast,\n",
    ")\n",
    "\n",
    "world.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load AMIRIS scenario\n",
    "\n",
    "First we need to download the examples repository from amiris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'amiris-examples' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!cd .. && git clone https://gitlab.com/dlr-ve/esy/amiris/examples.git amiris-examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the repository at the right place, we can run the amiris scenario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:assume.world:connected to db\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Output'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 19\u001b[0m\n\u001b[0;32m     15\u001b[0m     db_uri \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpostgresql://assume:assume@localhost:5432/assume\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     17\u001b[0m world \u001b[38;5;241m=\u001b[39m World(database_uri\u001b[38;5;241m=\u001b[39mdb_uri)\n\u001b[1;32m---> 19\u001b[0m \u001b[43mload_amiris\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworld\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamiris\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscenario\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdid load \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscenario\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - now simulating\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     27\u001b[0m world\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[1;32m~\\OneDrive\\Dokumente\\Studium\\2024-25 Winersemester\\Hiwi IISM\\assume\\assume\\scenario\\loader_amiris.py:482\u001b[0m, in \u001b[0;36mload_amiris\u001b[1;34m(world, scenario, study_case, base_path)\u001b[0m\n\u001b[0;32m    480\u001b[0m end \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m timedelta(minutes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    481\u001b[0m sim_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscenario\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstudy_case\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 482\u001b[0m save_interval \u001b[38;5;241m=\u001b[39m \u001b[43mamiris_scenario\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGeneralProperties\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOutput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterval\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    483\u001b[0m prices \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    484\u001b[0m index \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mdate_range(start\u001b[38;5;241m=\u001b[39mstart, end\u001b[38;5;241m=\u001b[39mend, freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1h\u001b[39m\u001b[38;5;124m\"\u001b[39m, inclusive\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Output'"
     ]
    }
   ],
   "source": [
    "from assume import World\n",
    "from assume.scenario.loader_amiris import load_amiris\n",
    "\n",
    "scenario = \"Simple\"  # Germany20{15-19}, Austria2019 or Simple\n",
    "base_path = f\"../amiris-examples/{scenario}/\"\n",
    "\n",
    "# make sure that you have a database server up and running - preferabely in docker\n",
    "# DB_URI = \"postgresql://assume:assume@localhost:5432/assume\"\n",
    "# but you can use a file-based sqlite database too:\n",
    "data_format = \"local_db\"  # \"local_db\" or \"timescale\"\n",
    "\n",
    "if data_format == \"local_db\":\n",
    "    db_uri = \"sqlite:///local_db/assume_db.db\"\n",
    "elif data_format == \"timescale\":\n",
    "    db_uri = \"postgresql://assume:assume@localhost:5432/assume\"\n",
    "\n",
    "world = World(database_uri=db_uri)\n",
    "load_amiris(\n",
    "    world,\n",
    "    \"amiris\",\n",
    "    scenario.lower(),\n",
    "    base_path,\n",
    ")\n",
    "print(f\"did load {scenario} - now simulating\")\n",
    "world.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are running locally and have our docker with the database and the Grafana dashboards installed, we can now look at the results here:\n",
    "\n",
    "http://localhost:3000/d/mQ3Lvkr4k/assume3a-main-overview?orgId=1&var-simulation=amiris_simple&from=1609459200000&to=1609545600000&refresh=5s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load PyPSA scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:assume.world:connected to db\n",
      "WARNING:pypsa.io:Importing network from PyPSA version v0.17.1 while current version is v0.30.3. Read the release notes at https://pypsa.readthedocs.io/en/latest/release_notes.html to prepare your network for import.\n",
      "INFO:assume.scenario.loader_pypsa:loading scenario world_pypsa_ac_dc_meshed\n",
      "INFO:assume.world:activating container\n",
      "INFO:assume.common.outputs:tried writing grid data to non postGIS database\n",
      "INFO:assume.world:all agents up - starting simulation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "world_pypsa_ac_dc_meshed 2015-01-01 09:00:00: : 32401.0it [00:00, 32438.80it/s]                         \n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from datetime import timedelta\n",
    "\n",
    "import pypsa\n",
    "\n",
    "# python-dateutil\n",
    "from dateutil import rrule as rr\n",
    "\n",
    "from assume import MarketConfig, MarketProduct, World\n",
    "from assume.scenario.loader_pypsa import load_pypsa\n",
    "\n",
    "# make sure that you have a database server up and running - preferabely in docker\n",
    "# DB_URI = \"postgresql://assume:assume@localhost:5432/assume\"\n",
    "# but you can use a file-based sqlite database too:\n",
    "data_format = \"local_db\"  # \"local_db\" or \"timescale\"\n",
    "\n",
    "if data_format == \"local_db\":\n",
    "    db_uri = \"sqlite:///local_db/assume_db.db\"\n",
    "elif data_format == \"timescale\":\n",
    "    db_uri = \"postgresql://assume:assume@localhost:5432/assume\"\n",
    "\n",
    "\n",
    "world = World(database_uri=db_uri)\n",
    "\n",
    "scenario = \"world_pypsa\"\n",
    "study_case = \"ac_dc_meshed\"\n",
    "# \"pay_as_clear\", \"redispatch\" or \"nodal\"\n",
    "market_mechanism = \"pay_as_clear\"\n",
    "\n",
    "network = pypsa.examples.ac_dc_meshed(from_master=True)\n",
    "# network = pypsa.examples.storage_hvdc(True)\n",
    "# network = pypsa.examples.scigrid_de(True, from_master=True)\n",
    "\n",
    "start = network.snapshots[0]\n",
    "end = network.snapshots[-1]\n",
    "marketdesign = [\n",
    "    MarketConfig(\n",
    "        \"EOM\",\n",
    "        rr.rrule(rr.HOURLY, interval=1, dtstart=start, until=end),\n",
    "        timedelta(hours=1),\n",
    "        market_mechanism,\n",
    "        [MarketProduct(timedelta(hours=1), 1, timedelta(hours=1))],\n",
    "        additional_fields=[\"node\", \"max_power\", \"min_power\"],\n",
    "        maximum_bid_volume=1e9,\n",
    "        maximum_bid_price=1e9,\n",
    "    )\n",
    "]\n",
    "default_strategies = {\n",
    "    mc.market_id: (\n",
    "        \"naive_redispatch\" if mc.market_mechanism == \"redispatch\" else \"naive_eom\"\n",
    "    )\n",
    "    for mc in marketdesign\n",
    "}\n",
    "\n",
    "bidding_strategies = defaultdict(lambda: default_strategies)\n",
    "\n",
    "load_pypsa(world, scenario, study_case, network, marketdesign, bidding_strategies)\n",
    "\n",
    "world.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are running locally and have our docker with the database and the Grafan dashboards installed, we can now look at the results here:\n",
    "\n",
    "http://localhost:3000/d/nodalview/assume-nodal-view?orgId=1&var-simulation=world_pypsa_ac_dc_meshed&var-market=EOM\n",
    "\n",
    "This also shows a visualization of the grid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this tutorial, we have shown how different input formats can be used with ASSUME to create interoperability between different energy market simulations.\n",
    "It can also be used to load data from your personal existing simulations created in one of the other cases.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "assume",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "nbsphinx": {
   "execute": "never"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
