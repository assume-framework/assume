{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4JeBorbE6FYr"
   },
   "source": [
    "# 7. Interoperability and Input-Output\n",
    "\n",
    "This tutorial describes how ASSUME can be used to create market simulations from energy system simulations as well as other market simulations like AMIRIS.\n",
    "A broad comparison towards AMIRIS is submitted to the EEM2024.\n",
    "\n",
    "This tutorial describes how one can create scenarios from different input sets and use existing scenarios from it.\n",
    "\n",
    "\n",
    "**As a whole, this tutorial covers the following**\n",
    "\n",
    "1. [running a small scenario from CSV folder with the CLI](#1.-scenario-from-cli)\n",
    "\n",
    "2. [creating a small simulation from scratch as shown in tutorial 01](#2.-run-from-a-script-to-customize-scenario-yourself)\n",
    "\n",
    "3. [load a scenario from an AMIRIS scenario.yaml](#3.-load-amiris-scenario)\n",
    "\n",
    "4. [load a scenario from a pypsa network](#4.-load-pypsa-scenario)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Scenario from CLI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to install assume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the ASSUME framework with the PyPSA library for network optimization\n",
    "import importlib.util\n",
    "\n",
    "# Check if 'google.colab' is available\n",
    "IN_COLAB = importlib.util.find_spec(\"google.colab\") is not None\n",
    "#if IN_COLAB:\n",
    "#    !pip install assume-framework[network]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we run in Google Colab, we need to first clone the ASSUME repository there to access the tutorial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    !git clone --depth=1 https://github.com/assume-framework/assume.git assume-repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the CLI script to run a simulation - relative to the examples folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    !cd assume-repo && assume -s example_01a -c tiny -db \"sqlite:///local_db/assume_db.db\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Protip: with argcomplete - one can create very nice tab completion for python scripts.\n",
    "\n",
    "Though one has to run `eval \"$(register-python-argcomplete assume)\"` once in the env before (for Linux and Mac). On Windows, one needs to run:\n",
    "`register-python-argcomplete --shell powershell assume | Out-String | Invoke-Expression`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did not use the postgresql database - therefore we can not use our visualization - lets fix this. **You need to have have postgresql and grafana installed (available through docker).** Please make sure that you have Docker running. Otherwise this code will not work and only run endlessly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:assume.world:Connected to the database\n",
      "INFO:assume.scenario.loader_csv:Input files path: examples/inputs/example_01a\n",
      "INFO:assume.scenario.loader_csv:Study case: base\n",
      "INFO:assume.scenario.loader_csv:Simulation ID: example_01a_base\n",
      "INFO:assume.scenario.loader_csv:unit_operators not found. Returning None\n",
      "INFO:assume.scenario.loader_csv:storage_units not found. Returning None\n",
      "INFO:assume.scenario.loader_csv:industrial_dsm_units not found. Returning None\n",
      "INFO:assume.scenario.loader_csv:residential_dsm_units not found. Returning None\n",
      "INFO:assume.scenario.loader_csv:forecasts_df not found. Returning None\n",
      "WARNING:assume.scenario.loader_csv:Resolution of demand_df (<15 * Minutes>) is higher than the simulation (<Hour>). Resampling using mean(). Make sure this is what you want.\n",
      "INFO:assume.scenario.loader_csv:Downsampling demand_df successful.\n",
      "WARNING:assume.scenario.loader_csv:Resolution of exchanges_df (<15 * Minutes>) is higher than the simulation (<Hour>). Resampling using mean(). Make sure this is what you want.\n",
      "INFO:assume.scenario.loader_csv:Downsampling exchanges_df successful.\n",
      "INFO:assume.scenario.loader_csv:availability_df not found. Returning None\n",
      "INFO:assume.scenario.loader_csv:buses not found. Returning None\n",
      "INFO:assume.scenario.loader_csv:lines not found. Returning None\n",
      "INFO:assume.scenario.loader_csv:Adding markets\n",
      "INFO:assume.scenario.loader_csv:Read units from dataframe\n",
      "INFO:assume.scenario.loader_csv:Adding power_plant units\n",
      "INFO:assume.scenario.loader_csv:Adding demand units\n",
      "INFO:assume.scenario.loader_csv:Adding unit operators and units\n",
      "INFO:root:loaded example_01a - base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/2592000 [00:00<?, ?it/s]\n",
      "  0%|          | 1.0/2592000 [00:00<105:29:06,  6.83it/s]\n",
      "example_01a_base 2019-01-01 14:00:00:   2%|▏         | 54001.0/2592000 [00:00<00:09, 258753.59it/s]\n",
      "example_01a_base 2019-01-02 02:00:00:   4%|▍         | 97201.0/2592000 [00:00<00:12, 195087.49it/s]\n",
      "example_01a_base 2019-01-02 19:00:00:   6%|▌         | 158401.0/2592000 [00:00<00:08, 297315.61it/s]\n",
      "example_01a_base 2019-01-03 13:00:00:   9%|▊         | 223201.0/2592000 [00:00<00:06, 387500.43it/s]\n",
      "example_01a_base 2019-01-04 07:00:00:  11%|█         | 288001.0/2592000 [00:00<00:05, 451650.61it/s]\n",
      "example_01a_base 2019-01-05 00:00:00:  13%|█▎        | 349201.0/2592000 [00:00<00:04, 489743.11it/s]\n",
      "example_01a_base 2019-01-05 16:00:00:  16%|█▌        | 406801.0/2592000 [00:01<00:04, 511236.49it/s]\n",
      "example_01a_base 2019-01-06 08:00:00:  18%|█▊        | 464401.0/2592000 [00:01<00:04, 523751.11it/s]\n",
      "example_01a_base 2019-01-07 01:00:00:  20%|██        | 525601.0/2592000 [00:01<00:03, 543319.26it/s]\n",
      "example_01a_base 2019-01-07 18:00:00:  23%|██▎       | 586801.0/2592000 [00:01<00:03, 551290.83it/s]\n",
      "example_01a_base 2019-01-08 11:00:00:  25%|██▌       | 648001.0/2592000 [00:01<00:03, 560893.58it/s]\n",
      "example_01a_base 2019-01-09 03:00:00:  27%|██▋       | 705601.0/2592000 [00:01<00:03, 555042.23it/s]\n",
      "example_01a_base 2019-01-09 19:00:00:  29%|██▉       | 763201.0/2592000 [00:01<00:03, 552678.31it/s]\n",
      "example_01a_base 2019-01-10 11:00:00:  32%|███▏      | 820801.0/2592000 [00:01<00:03, 481137.31it/s]\n",
      "example_01a_base 2019-01-11 01:00:00:  34%|███▎      | 871201.0/2592000 [00:02<00:04, 409177.15it/s]\n",
      "example_01a_base 2019-01-11 14:00:00:  35%|███▌      | 918001.0/2592000 [00:02<00:04, 407033.18it/s]\n",
      "example_01a_base 2019-01-12 02:00:00:  37%|███▋      | 961201.0/2592000 [00:02<00:03, 409063.82it/s]\n",
      "example_01a_base 2019-01-12 14:00:00:  39%|███▉      | 1004401.0/2592000 [00:02<00:03, 413812.61it/s]\n",
      "example_01a_base 2019-01-13 03:00:00:  41%|████      | 1051201.0/2592000 [00:02<00:03, 422879.24it/s]\n",
      "example_01a_base 2019-01-13 15:00:00:  42%|████▏     | 1094401.0/2592000 [00:02<00:03, 397961.23it/s]\n",
      "example_01a_base 2019-01-14 03:00:00:  44%|████▍     | 1137601.0/2592000 [00:02<00:03, 396076.98it/s]\n",
      "example_01a_base 2019-01-14 15:00:00:  46%|████▌     | 1180801.0/2592000 [00:02<00:03, 402418.80it/s]\n",
      "example_01a_base 2019-01-15 03:00:00:  47%|████▋     | 1224001.0/2592000 [00:02<00:03, 399269.42it/s]\n",
      "example_01a_base 2019-01-15 15:00:00:  49%|████▉     | 1267201.0/2592000 [00:02<00:03, 395792.10it/s]\n",
      "example_01a_base 2019-01-16 03:00:00:  51%|█████     | 1310401.0/2592000 [00:03<00:03, 373854.75it/s]\n",
      "example_01a_base 2019-01-16 14:00:00:  52%|█████▏    | 1350001.0/2592000 [00:03<00:03, 364344.36it/s]\n",
      "example_01a_base 2019-01-17 01:00:00:  54%|█████▎    | 1389601.0/2592000 [00:03<00:03, 343340.55it/s]\n",
      "example_01a_base 2019-01-17 11:00:00:  55%|█████▌    | 1425601.0/2592000 [00:03<00:03, 338326.00it/s]\n",
      "example_01a_base 2019-01-17 21:00:00:  56%|█████▋    | 1461601.0/2592000 [00:03<00:03, 334456.49it/s]\n",
      "example_01a_base 2019-01-18 07:00:00:  58%|█████▊    | 1497601.0/2592000 [00:03<00:03, 338789.20it/s]\n",
      "example_01a_base 2019-01-18 17:00:00:  59%|█████▉    | 1533601.0/2592000 [00:03<00:03, 342293.53it/s]\n",
      "example_01a_base 2019-01-19 03:00:00:  61%|██████    | 1569601.0/2592000 [00:03<00:02, 344387.91it/s]\n",
      "example_01a_base 2019-01-19 13:00:00:  62%|██████▏   | 1605601.0/2592000 [00:04<00:02, 347489.02it/s]\n",
      "example_01a_base 2019-01-20 01:00:00:  64%|██████▎   | 1648801.0/2592000 [00:04<00:02, 369565.02it/s]\n",
      "example_01a_base 2019-01-20 15:00:00:  66%|██████▌   | 1699201.0/2592000 [00:04<00:02, 401749.29it/s]\n",
      "example_01a_base 2019-01-21 03:00:00:  67%|██████▋   | 1742401.0/2592000 [00:04<00:02, 389619.88it/s]\n",
      "example_01a_base 2019-01-21 14:00:00:  69%|██████▉   | 1782001.0/2592000 [00:04<00:02, 362090.31it/s]\n",
      "example_01a_base 2019-01-22 03:00:00:  71%|███████   | 1828801.0/2592000 [00:04<00:01, 389776.25it/s]\n",
      "example_01a_base 2019-01-22 15:00:00:  72%|███████▏  | 1872001.0/2592000 [00:04<00:01, 398453.49it/s]\n",
      "example_01a_base 2019-01-23 03:00:00:  74%|███████▍  | 1915201.0/2592000 [00:04<00:01, 393325.19it/s]\n",
      "example_01a_base 2019-01-23 18:00:00:  76%|███████▌  | 1969201.0/2592000 [00:04<00:01, 421513.52it/s]\n",
      "example_01a_base 2019-01-24 08:00:00:  78%|███████▊  | 2019601.0/2592000 [00:04<00:01, 438369.41it/s]\n",
      "example_01a_base 2019-01-24 21:00:00:  80%|███████▉  | 2066401.0/2592000 [00:05<00:01, 441091.99it/s]\n",
      "example_01a_base 2019-01-25 11:00:00:  82%|████████▏ | 2116801.0/2592000 [00:05<00:01, 454038.30it/s]\n",
      "example_01a_base 2019-01-26 00:00:00:  83%|████████▎ | 2163601.0/2592000 [00:05<00:00, 443516.34it/s]\n",
      "example_01a_base 2019-01-26 13:00:00:  85%|████████▌ | 2210401.0/2592000 [00:05<00:00, 431548.53it/s]\n",
      "example_01a_base 2019-01-27 03:00:00:  87%|████████▋ | 2260801.0/2592000 [00:05<00:00, 446114.06it/s]\n",
      "example_01a_base 2019-01-27 16:00:00:  89%|████████▉ | 2307601.0/2592000 [00:05<00:00, 434764.75it/s]\n",
      "example_01a_base 2019-01-28 05:00:00:  91%|█████████ | 2354401.0/2592000 [00:05<00:00, 418470.55it/s]\n",
      "example_01a_base 2019-01-28 19:00:00:  93%|█████████▎| 2404801.0/2592000 [00:05<00:00, 441750.45it/s]\n",
      "example_01a_base 2019-01-29 10:00:00:  95%|█████████▍| 2458801.0/2592000 [00:05<00:00, 457460.34it/s]\n",
      "example_01a_base 2019-01-29 23:00:00:  97%|█████████▋| 2505601.0/2592000 [00:06<00:00, 451235.00it/s]\n",
      "example_01a_base 2019-01-30 12:00:00:  98%|█████████▊| 2552401.0/2592000 [00:06<00:00, 439681.79it/s]\n",
      "example_01a_base 2019-01-31 00:00:00: : 2592001.0it [00:06, 412488.31it/s]                           \n"
     ]
    }
   ],
   "source": [
    "if not IN_COLAB:\n",
    "    !cd ../.. && assume -s example_01a -c base -db \"postgresql://assume:assume@localhost:5432/assume\"\n",
    "else:\n",
    "    !assume -s example_01a -c base -db \"postgresql://assume:assume@localhost:5432/assume\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are running locally and have our docker with the database and the Grafan dashboards installed, we can now look at the results here:\n",
    "\n",
    "http://localhost:3000/?orgId=1&var-simulation=example_01a_base&from=1546300800000&to=1548892800000&refresh=5s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run from a script to customize scenario yourself\n",
    "\n",
    "This is a more advanced option - though it gives full control on what we are doing here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:assume.world:Connected to the database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "world_script_simulation 2023-03-30 00:00:00:  99%|█████████▉| 7603201.0/7689600 [00:08<00:00, 912369.69it/s]\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "from dateutil import rrule as rr\n",
    "\n",
    "from assume import World\n",
    "from assume.common.forecaster import DemandForecaster, PowerplantForecaster\n",
    "from assume.common.market_objects import MarketConfig, MarketProduct\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "os.makedirs(\"./local_db\", exist_ok=True)\n",
    "\n",
    "db_uri = \"sqlite:///./local_db/assume_db.db\"\n",
    "\n",
    "world = World(database_uri=db_uri)\n",
    "\n",
    "start = datetime(2023, 1, 1)\n",
    "end = datetime(2023, 3, 31)\n",
    "index = pd.date_range(\n",
    "    start=start,\n",
    "    end=end + timedelta(hours=24),\n",
    "    freq=\"h\",\n",
    ")\n",
    "simulation_id = \"world_script_simulation\"\n",
    "\n",
    "\n",
    "world.setup(\n",
    "    start=start,\n",
    "    end=end,\n",
    "    save_frequency_hours=48,\n",
    "    simulation_id=simulation_id,\n",
    "    index=index,\n",
    ")\n",
    "\n",
    "\n",
    "marketdesign = [\n",
    "    MarketConfig(\n",
    "        market_id=\"EOM\",\n",
    "        opening_hours=rr.rrule(rr.HOURLY, interval=24, dtstart=start, until=end),\n",
    "        opening_duration=timedelta(hours=1),\n",
    "        market_mechanism=\"pay_as_clear\",\n",
    "        market_products=[MarketProduct(timedelta(hours=1), 24, timedelta(hours=1))],\n",
    "        additional_fields=[\"block_id\", \"link\", \"exclusive_id\"],\n",
    "    )\n",
    "]\n",
    "\n",
    "mo_id = \"market_operator\"\n",
    "world.add_market_operator(id=mo_id)\n",
    "\n",
    "for market_config in marketdesign:\n",
    "    world.add_market(market_operator_id=mo_id, market_config=market_config)\n",
    "\n",
    "    world.add_unit_operator(\"demand_operator\")\n",
    "\n",
    "demand_forecast = DemandForecaster(index, demand=-100)\n",
    "\n",
    "world.add_unit(\n",
    "    id=\"demand_unit\",\n",
    "    unit_type=\"demand\",\n",
    "    unit_operator_id=\"demand_operator\",\n",
    "    unit_params={\n",
    "        \"min_power\": 0,\n",
    "        \"max_power\": -1000,\n",
    "        \"bidding_strategies\": {\"EOM\": \"demand_energy_naive\"},\n",
    "        \"technology\": \"demand\",\n",
    "    },\n",
    "    forecaster=demand_forecast,\n",
    ")\n",
    "\n",
    "world.add_unit_operator(\"unit_operator\")\n",
    "\n",
    "nuclear_forecast = PowerplantForecaster(\n",
    "    index, availability=1, fuel_prices={\"uranium\": 3, \"co2\": 0.1}\n",
    ")\n",
    "\n",
    "world.add_unit(\n",
    "    id=\"nuclear_unit\",\n",
    "    unit_type=\"power_plant\",\n",
    "    unit_operator_id=\"unit_operator\",\n",
    "    unit_params={\n",
    "        \"min_power\": 200,\n",
    "        \"max_power\": 1000,\n",
    "        \"fuel_type\": \"uranium\",\n",
    "        \"bidding_strategies\": {\"EOM\": \"powerplant_energy_naive\"},\n",
    "        \"technology\": \"nuclear\",\n",
    "    },\n",
    "    forecaster=nuclear_forecast,\n",
    ")\n",
    "\n",
    "world.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load AMIRIS scenario\n",
    "\n",
    "First we need to download the examples repository from amiris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'amiris-examples' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!cd inputs && git clone https://gitlab.com/dlr-ve/esy/amiris/examples.git amiris-examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the repository at the right place, we can run the amiris scenario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:assume.world:Connected to the database\n",
      "did load Simple - now simulating\n"
     ]
    }
   ],
   "source": [
    "from assume import World\n",
    "from assume.scenario.loader_amiris import load_amiris\n",
    "\n",
    "scenario = \"Simple\"  # Germany20{15-19}, Austria2019 or Simple\n",
    "base_path = f\"inputs/amiris-examples/demo/{scenario}/\"\n",
    "\n",
    "# make sure that you have a database server up and running - preferabely in docker\n",
    "# DB_URI = \"postgresql://assume:assume@localhost:5432/assume\"\n",
    "# but you can use a file-based sqlite database too:\n",
    "data_format = \"timescale\"  # \"local_db\" or \"timescale\"\n",
    "\n",
    "if data_format == \"local_db\":\n",
    "    db_uri = \"sqlite:///local_db/assume_db.db\"\n",
    "elif data_format == \"timescale\":\n",
    "    db_uri = \"postgresql://assume:assume@localhost:5432/assume\"\n",
    "\n",
    "world = World(database_uri=db_uri)\n",
    "load_amiris(\n",
    "    world,\n",
    "    \"amiris\",\n",
    "    scenario.lower(),\n",
    "    base_path,\n",
    ")\n",
    "print(f\"did load {scenario} - now simulating\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are running locally and have our docker with the database and the Grafana dashboards installed, we can now look at the results here:\n",
    "\n",
    "http://localhost:3000/d/mQ3Lvkr4k/assume3a-main-overview?orgId=1&var-simulation=amiris_simple&from=1609459200000&to=1609545600000&refresh=5s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load PyPSA scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:assume.world:Connected to the database\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# \"pay_as_clear\", \"redispatch\" or \"nodal\"\u001b[39;00m\n\u001b[32m     28\u001b[39m market_mechanism = \u001b[33m\"\u001b[39m\u001b[33mpay_as_clear\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m network = \u001b[43mpypsa\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m.\u001b[49m\u001b[43mac_dc_meshed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfrom_master\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# network = pypsa.examples.storage_hvdc(True)\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# network = pypsa.examples.scigrid_de(True, from_master=True)\u001b[39;00m\n\u001b[32m     34\u001b[39m start = network.snapshots[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gunter\\miniconda3\\envs\\assume\\Lib\\site-packages\\pypsa\\examples.py:90\u001b[39m, in \u001b[36mac_dc_meshed\u001b[39m\u001b[34m(update, from_master, remove_link_p_set)\u001b[39m\n\u001b[32m     88\u001b[39m name = \u001b[33m\"\u001b[39m\u001b[33mac-dc-meshed\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     89\u001b[39m repofile = \u001b[33m\"\u001b[39m\u001b[33mexamples/ac-dc-meshed/ac-dc-data.nc\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m path = \u001b[43m_retrieve_if_not_local\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_master\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_master\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m n = Network(path)\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m remove_link_p_set:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gunter\\miniconda3\\envs\\assume\\Lib\\site-packages\\pypsa\\examples.py:65\u001b[39m, in \u001b[36m_retrieve_if_not_local\u001b[39m\u001b[34m(name, repofile, update, from_master)\u001b[39m\n\u001b[32m     63\u001b[39m     url = _repo_url(from_master) + repofile\n\u001b[32m     64\u001b[39m     logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRetrieving network data from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[43murlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gunter\\miniconda3\\envs\\assume\\Lib\\urllib\\request.py:240\u001b[39m, in \u001b[36murlretrieve\u001b[39m\u001b[34m(url, filename, reporthook, data)\u001b[39m\n\u001b[32m    223\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    224\u001b[39m \u001b[33;03mRetrieve a URL into a temporary location on disk.\u001b[39;00m\n\u001b[32m    225\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    236\u001b[39m \u001b[33;03mdata file as well as the resulting HTTPMessage object.\u001b[39;00m\n\u001b[32m    237\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    238\u001b[39m url_type, path = _splittype(url)\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m contextlib.closing(\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[32m    241\u001b[39m     headers = fp.info()\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# Just return the local path and the \"headers\" for file://\u001b[39;00m\n\u001b[32m    244\u001b[39m     \u001b[38;5;66;03m# URLs. No sense in performing a copy unless requested.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gunter\\miniconda3\\envs\\assume\\Lib\\urllib\\request.py:215\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    214\u001b[39m     opener = _opener\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gunter\\miniconda3\\envs\\assume\\Lib\\urllib\\request.py:521\u001b[39m, in \u001b[36mOpenerDirector.open\u001b[39m\u001b[34m(self, fullurl, data, timeout)\u001b[39m\n\u001b[32m    519\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.process_response.get(protocol, []):\n\u001b[32m    520\u001b[39m     meth = \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m521\u001b[39m     response = \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gunter\\miniconda3\\envs\\assume\\Lib\\urllib\\request.py:630\u001b[39m, in \u001b[36mHTTPErrorProcessor.http_response\u001b[39m\u001b[34m(self, request, response)\u001b[39m\n\u001b[32m    627\u001b[39m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[32m    628\u001b[39m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[32m    629\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[32m200\u001b[39m <= code < \u001b[32m300\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m630\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m.\u001b[49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    631\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhttp\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    633\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gunter\\miniconda3\\envs\\assume\\Lib\\urllib\\request.py:559\u001b[39m, in \u001b[36mOpenerDirector.error\u001b[39m\u001b[34m(self, proto, *args)\u001b[39m\n\u001b[32m    557\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[32m    558\u001b[39m     args = (\u001b[38;5;28mdict\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mhttp_error_default\u001b[39m\u001b[33m'\u001b[39m) + orig_args\n\u001b[32m--> \u001b[39m\u001b[32m559\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gunter\\miniconda3\\envs\\assume\\Lib\\urllib\\request.py:492\u001b[39m, in \u001b[36mOpenerDirector._call_chain\u001b[39m\u001b[34m(self, chain, kind, meth_name, *args)\u001b[39m\n\u001b[32m    490\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[32m    491\u001b[39m     func = \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m492\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    494\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gunter\\miniconda3\\envs\\assume\\Lib\\urllib\\request.py:639\u001b[39m, in \u001b[36mHTTPDefaultErrorHandler.http_error_default\u001b[39m\u001b[34m(self, req, fp, code, msg, hdrs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[32m--> \u001b[39m\u001b[32m639\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "\u001b[31mHTTPError\u001b[39m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from datetime import timedelta\n",
    "\n",
    "import pypsa\n",
    "\n",
    "# python-dateutil\n",
    "from dateutil import rrule as rr\n",
    "\n",
    "from assume import MarketConfig, MarketProduct, World\n",
    "from assume.scenario.loader_pypsa import load_pypsa\n",
    "\n",
    "# make sure that you have a database server up and running - preferabely in docker\n",
    "# DB_URI = \"postgresql://assume:assume@localhost:5432/assume\"\n",
    "# but you can use a file-based sqlite database too:\n",
    "data_format = \"local_db\"  # \"local_db\" or \"timescale\"\n",
    "\n",
    "if data_format == \"local_db\":\n",
    "    db_uri = \"sqlite:///local_db/assume_db.db\"\n",
    "elif data_format == \"timescale\":\n",
    "    db_uri = \"postgresql://assume:assume@localhost:5432/assume\"\n",
    "\n",
    "\n",
    "world = World(database_uri=db_uri)\n",
    "\n",
    "scenario = \"world_pypsa\"\n",
    "study_case = \"ac_dc_meshed\"\n",
    "# \"pay_as_clear\", \"redispatch\" or \"nodal\"\n",
    "market_mechanism = \"pay_as_clear\"\n",
    "\n",
    "network = pypsa.examples.ac_dc_meshed(from_master=True)\n",
    "# network = pypsa.examples.storage_hvdc(True)\n",
    "# network = pypsa.examples.scigrid_de(True, from_master=True)\n",
    "\n",
    "start = network.snapshots[0]\n",
    "end = network.snapshots[-1]\n",
    "marketdesign = [\n",
    "    MarketConfig(\n",
    "        \"EOM\",\n",
    "        rr.rrule(rr.HOURLY, interval=1, dtstart=start, until=end),\n",
    "        timedelta(hours=1),\n",
    "        market_mechanism,\n",
    "        [MarketProduct(timedelta(hours=1), 1, timedelta(hours=1))],\n",
    "        additional_fields=[\"node\", \"max_power\", \"min_power\"],\n",
    "        maximum_bid_volume=1e9,\n",
    "        maximum_bid_price=1e9,\n",
    "    )\n",
    "]\n",
    "default_strategies = {\n",
    "    mc.market_id: (\n",
    "        \"powerplant_energy_naive_redispatch\"\n",
    "        if mc.market_mechanism == \"redispatch\"\n",
    "        else \"powerplant_energy_naive\"\n",
    "    )\n",
    "    for mc in marketdesign\n",
    "}\n",
    "default_demand_strategies = {\n",
    "    mc.market_id: (\n",
    "        \"demand_energy_naive_redispatch\"\n",
    "        if mc.market_mechanism == \"redispatch\"\n",
    "        else \"demand_energy_naive\"\n",
    "    )\n",
    "    for mc in marketdesign\n",
    "}\n",
    "\n",
    "bidding_strategies = {\n",
    "    \"power_plant\": defaultdict(lambda: default_strategies),\n",
    "    \"demand\": defaultdict(lambda: default_demand_strategies),\n",
    "    \"storage\": defaultdict(lambda: default_strategies),\n",
    "}\n",
    "\n",
    "load_pypsa(world, scenario, study_case, network, marketdesign, bidding_strategies)\n",
    "\n",
    "world.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are running locally and have our docker with the database and the Grafana dashboards installed, we can now look at the results here:\n",
    "\n",
    "http://localhost:3000/d/nodalview/assume-nodal-view?orgId=1&var-simulation=world_pypsa_ac_dc_meshed&var-market=EOM\n",
    "\n",
    "This also shows a visualization of the grid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this tutorial, we have shown how different input formats can be used with ASSUME to create interoperability between different energy market simulations.\n",
    "It can also be used to load data from your personal existing simulations created in one of the other cases.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "assume",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "nbsphinx": {
   "execute": "never"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
