from assume.strategies.learning_strategies import TorchLearningStrategy
from assume.strategies.portfolio_strategies import UnitOperatorStrategy
from assume.common.market_objects import MarketConfig, Orderbook, Product
from assume.common.fast_pandas import FastSeries
from assume.common.utils import min_max_scale, min_max_rescale
from datetime import datetime, timedelta
from itertools import groupby
from operator import itemgetter
import numpy as np
import torch as th
        


class PortfolioRLStrategy(TorchLearningStrategy, UnitOperatorStrategy):
    """
    Reinforcement Learning Strategy that enables the agent to learn optimal bidding strategies for
    the portfolio of a units_operator on an Energy-Only Market.

    The agent submits a discrete price according to their available flexible capacity.
    This strategy utilizes a set of observations to generate actions, which are then transformed into 
    market bids. 
    
    Observations include the following components:

    - **Forecasted Residual Load**: Forecasted load over the foresight period, scaled by the maximum
      demand, indicating anticipated grid conditions.
    - **Forecasted Price**: Price forecast over the foresight period, scaled by the maximum bid price,
      providing a sense of expected market prices.
    - **Total Flexible Capacity**
    - **Marginal cost quantiles**

    Actions are: total flexible capacity to be bid and prices for flexible generation, rescaled 
    from a range of [-1, 1] in the `calculate_bids` method, then translated into unit-specific bids.

    Rewards are based on profit from transactions, minus operational and opportunity costs. Key components include:

    - **Profit**: Determined from the income generated by accepted bids, calculated as the product of
      accepted price, volume, and duration.
    - **Operational Costs**: Includes marginal costs and start-up costs when a unit transitions between
      on and off states.

    Attributes
    ----------
    foresight : int
        Number of time steps for which the agent forecasts market conditions. Defaults to 24.
    max_bid_price : float
        Maximum allowable bid price. Defaults to 100.
    min_bid_price : float
        Maximum allowable bid price. Defaults to -100.
    max_demand : float
        Maximum demand capacity of the unit. Defaults to 10e3.
    device : str
        Device for computation, such as "cpu" or "cuda". Defaults to "cpu".
    float_type : str
        Data type for floating-point calculations, typically "float32". Defaults to "float32".
    learning_mode : bool
        Indicates whether the agent is in learning mode. Defaults to False.
    algorithm : str
        Name of the RL algorithm in use. Defaults to "matd3".
    actor_architecture_class : type[torch.nn.Module]
        Class of the neural network architecture used for the actor network. Defaults to MLPActor.
    actor : torch.nn.Module
        Actor network for determining actions.
    order_types : list[str]
        Types of market orders supported by the strategy. Defaults to ["SB"].
    action_noise : NormalActionNoise
        Noise model added to actions during learning to encourage exploration. Defaults to None.
    collect_initial_experience_mode : bool
        Whether the agent is collecting initial experience through exploration. Defaults to True.

    Args
    ----
    *args : Variable length argument list.
    **kwargs : Arbitrary keyword arguments.
    """

    def __init__(self, *args, **kwargs):

        # 'foresight' represents the number of time steps into the future that we will consider
        # when constructing the observations. This value is fixed for each strategy, as the
        # neural network architecture is predefined, and the size of the observations must remain consistent.

        self.foresight = kwargs.pop("foresight", 12)    # number of forecasting step
        self.nbins = kwargs.pop("nbins", 4)             # numbers of cost bins
        self.steps = kwargs.pop("steps", 1)             # numbers of steps to bid
        act_dim = self.nbins * self.steps               # actions for each time step in the foresight
        unique_obs_dim = self.nbins * 2                 # tuple of volumes and costs for each quantile
        obs_dim = kwargs.pop("obs_dim", 3 * self.foresight + unique_obs_dim) 

        # Hyperparameters for action and reward
        self.alpha = kwargs.get("alpha", 0.0)           # risk appetite of unit operator 
        self.min_markup = kwargs.pop("min_markup", 1)   # min markup on marginal cost
        self.max_markup = kwargs.pop("max_markup", 3)   # max markup on marginal cost
        
        super().__init__(
            foresight=self.foresight,
            obs_dim=obs_dim,
            act_dim=act_dim,  
            unique_obs_dim=unique_obs_dim,
            *args,
            **kwargs,
        )

        # define allowed order types
        self.order_types = kwargs.get("order_types", ["SB"])


    def calculate_bids(
        self,
        units_operator,  # type: UnitsOperator
        market_config: MarketConfig,
        product_tuples: list[Product],
        **kwargs,
    ) -> Orderbook:
        """
        Calculates bids based on the current observations and actions derived from the actor network.

        Args
        ----
            units_operator (UnitsOperator): The operator that bids on the market.
            market_config (MarketConfig): The configuration of the market.
            product_tuples (list[Product]): List of products with start and end times for bidding.
            **kwargs : Additional keyword arguments.

        Returns
        -------
        Orderbook
            Contains bid entries for each product, including start time, end time, price, and volume.

        Notes
        -----
        This method obtains actions as a tensor of bid prices and total flexible quantity to bid. 
        Prices per quantile are then translated into unit-specific bids, which are submitted by sorting  
        units by their marginal cost, bidding their inflexible generation at their marginal capacity 
        and their flex capacity for their cost quantile.
        """

        start = product_tuples[0][0]
        end = product_tuples[-1][1]
        market_id = market_config.market_id
        bids = []

        assert market_config.market_products[0].count <= self.steps, f"{market_id} market contains less than {self.steps} products."
        assert len(units_operator.units) >= self.nbins, f"{units_operator.id} operates less than {self.nbins} units."

        ### STEP 1: CREATE OBSERVATION ###
        
        next_observation = self.create_observation(
            units_operator=units_operator,
            market_id=market_config.market_id,
            start=start,
            end=end,
        )
        scaled_costs = next_observation[-self.nbins:]
 

        ### STEP 2: RESCALE THE AGENT INPUTS AND OUTPUTS ###
               
        actions, noise = self.get_actions(next_observation)
        
        costs = min_max_rescale(scaled_costs.cpu().numpy(), 
                                min_val=0, 
                                max_val=self.max_price)

        markups = min_max_rescale(actions.cpu().numpy(), 
                                  self.min_markup, 
                                  self.max_markup,
                                  lower_bound=-1,
                                  upper_bound=1)  

        ### STEP 3. BID INFLEXIBLE GENERATION OF ONLINE UNITS ###    

        # 3a. Map each unit to the corresponding price quantile based on its marginal cost   
        for i, product in enumerate(product_tuples):
            prod_start = product[0]
            prod_end = product[1]
            
            for unit_id, unit in units_operator.units.items():
                min_power, max_power = unit.calculate_min_max_power(start,end) 
                inflex_gen, max_mw = min_power[0], max_power[0] 
                flex_gen = max_mw - inflex_gen
                marginal_cost = unit.calculate_marginal_cost(start, max_mw)

                # j = next((k for k, c in enumerate(costs) if c >= marginal_cost), self.nbins-1)
                j = np.searchsorted(costs, marginal_cost, side="right")
                j = min(j, self.nbins-1)

                # 3b. Bid INFLEXIBLE generation of online units for their mc 
        
                if inflex_gen > 0:
                    bids.append({           
                        "start_time": prod_start,
                        "end_time": prod_end,
                        "only_hours": None,
                        "price": marginal_cost,                                 
                        "volume": inflex_gen,
                        "unit_id": unit_id,
                        "bid_id": f"{units_operator.id}_{unit_id}_inflex",
                        "node": units_operator.units[unit_id].node,
                        })
                
                # 3c. Bid FLEXIBLE generation of online units for the price of corresponding quantile
                bids.append({           
                "start_time": prod_start,
                "end_time": prod_end,
                "only_hours": None,
                "price": marginal_cost * markups[self.nbins*i+j],  # price for quantile j at time i
                "volume": flex_gen,
                "unit_id": unit_id,
                "bid_id": f"{units_operator.id}_{unit_id}_flex", 
                "node": units_operator.units[unit_id].node,
                })
                        
        if self.learning_mode:
            self.learning_role.add_actions_to_cache(units_operator.id, start, actions, noise)

        return bids


    def get_actions(self, next_observation:th.Tensor) -> tuple[th.Tensor, th.Tensor]:
        """
        Compute actions based on the current observation.

        Args
        ----
        next_observation (torch.Tensor): The current observation, where the last element is assumed to be the marginal cost.

        Returns
        -------
        tuple of torch.Tensor
            A tuple containing: Actions to be taken (with or without noise). The noise component (if any), useful for diagnostics.
            The output action is a list of bid prices for flexible generation. 
            Output is scaled to the range [-1, 1].

        Notes
        -----
        During learning, exploratory noise is applied and already part of the curr_action unless in evaluation mode.
        In initial exploration mode, bids price are around the quantiles. 
        This assumes the last self.nbins elements of `next_observation`
        have the following structure: [flex_mc_0, flex_mc_1, ..., flex_mc_dim]
        """

        # Get the base action and associated noise from the parent implementation
        curr_action, noise = super().get_actions(next_observation)

        if self.learning_mode and not self.evaluation_mode:
            # Uniformly random actions in [-1.0, 1.0)
            if self.collect_initial_experience_mode:
                curr_action = -2 * th.rand_like(curr_action) + 1

        return curr_action, noise

    def prepare_observations(self, units_operator, market_id):

        total_capacity = self.total_capacity(units_operator)
        self.installed_capacity = total_capacity[market_id]

        gen_obs = 0

        for u_id, unit in units_operator.units.items():
            unit_gen = FastSeries(index=unit.index, value=0)
            price_forecast = unit.forecaster.price[market_id] 
            residual_load = unit.forecaster.residual_load[market_id]

            for start in price_forecast.index:
                marginal_cost = unit.calculate_marginal_cost(start, unit.max_power)
                unit_state = price_forecast[start] > marginal_cost
                unit_gen[start] = unit_state * unit.max_power
            
            gen_obs+= unit_gen
        
        # Limits the range for scaling and ensures 
        # scaling is well defined well-definedness 
        self.min_price = min(price_forecast)
        self.max_price = max(price_forecast)
        self.max_res_load = max(residual_load)

        # Residual load forecast
        self.scaled_res_load_obs = min_max_scale(
            residual_load, 0, self.max_res_load)
        
        # Competitive price forecast
        self.scaled_prices_obs = min_max_scale(
            price_forecast, self.min_price, self.max_price)
        
        # Inframarginal generation forecast
        self.scaled_gen_obs = gen_obs / residual_load    
        
    
    def create_observation(self, units_operator, market_id, start, end):

        # ensure scaled observations are prepared
        if not hasattr(self, "scaled_res_load_obs") or not hasattr(
            self, "scaled_prices_obs"
        ):
            self.prepare_observations(units_operator, market_id)

        # --- 1. Forecasted residual load and price (forward-looking) ---
        scaled_res_load_forecast = self.scaled_res_load_obs.window(
            start, self.foresight, direction="forward"
        )
        scaled_price_forecast = self.scaled_prices_obs.window(
            start, self.foresight, direction="forward"
        )

        scaled_gen_forecast = self.scaled_gen_obs.window(
            start, self.foresight, direction="forward"
        )

        # --- 2. Individual observations ---
        
        individual_observations = self.get_individual_observations(units_operator, start, end)    

        # concat all observations into one array
        observation = np.concatenate(
            [
                scaled_res_load_forecast,
                scaled_price_forecast,
                scaled_gen_forecast,
                individual_observations,
            ]
        )

        # transfer array to GPU for NN processing
        observation = th.as_tensor(
            observation, dtype=self.float_type, device=self.device
        ).flatten()

        if self.learning_mode:
            self.learning_role.add_observation_to_cache(
                units_operator.id, start, observation
            )

        return observation


    def get_individual_observations(
        self, 
        units_operator, # type: UnitsOperator
        start: datetime, end: datetime
    ):
        """
        Retrieves the observations specific to the units_operator. Returns a scaled array
        in range [-1,1] with the structure: [scaled_cost_1, scaled_cost_2, ...],
        where:
            scaled_cost: self.nbins quantiles of flex marginal costs for units
            that are bid in the market.

        Args
        ----
            units_on (dict): The units that the operator bids on the market.
            start (datetime.datetime): Start time for the observation period.
            end (datetime.datetime): End time for the observation period.

        Returns
        -------
        individual_observations (np.array): total flexible capacity,
        weighted quantiles of marginal costs.

        Notes
        -----
            Outputs are in range [-1,1], where
            costs are min-max scaled by [self.min_bid_price, self.max_bid_price].
        """
        
        # Sort unit tuples by marginal cost
        unit_tuples = {}
            
        for u_id, unit in units_operator.units.items():
            min_power, max_power = unit.calculate_min_max_power(start,end) 
            inflex_gen, max_mw = min_power[0], max_power[0] 
            flex_gen = max_mw - inflex_gen
            marginal_cost = unit.calculate_marginal_cost(start, max_mw)
            unit_tuples[u_id] = inflex_gen, flex_gen, marginal_cost
        
        sorted_tuples = sorted(list(unit_tuples.values()), key=lambda x: x[-1]) 
        _, flex_quant, flex_cost = zip(*sorted_tuples)
       
        bins = [i/self.nbins for i in range(1, self.nbins+1)]
        cost_bins = np.quantile(flex_cost, q=bins)
        
        
        # Creates bins of marginal costs
        scaled_costs = min_max_scale(cost_bins, 
                                     min_val=0, 
                                     max_val=self.max_price)
        
        # Calculates the total capacity of units in those bins
        index = np.searchsorted(cost_bins, flex_cost, side="right")
        
        # clipping and enforcing minlength ensure that scaled_quant has length self.nbins
        index = index.clip(max=self.nbins-1)
        quant = np.bincount(index, weights=flex_quant, minlength=self.nbins)
        scaled_quant = quant / self.installed_capacity
        self.cost_bins = cost_bins

        return np.concat([scaled_quant, scaled_costs])

    def calculate_reward(
        self,
        units_operator,  # type: UnitsOperator
        marketconfig: MarketConfig,
        orderbook: Orderbook,
    ):
        """
        Calculates the reward for the unit based on profits, costs, and opportunity costs from market transactions.

        Args
        ----
            units_operator (UnitsOperator): The operator for which to calculate the reward.
            marketconfig (MarketConfig): The configuration of the market.
            orderbook (Orderbook): Orderbook containing executed bids and details.

        Notes
        -----
        The reward includes the following:
        tot_profits:        Profit from accepted bids minus marginal and start-up costs.
        comp_profits:       Competitive profit benchmark, computed using the price forecast.
        scaling_factor:     A scaling factor to normalize the reward.
        mp_risk:            Accounts for risk attitude of operator. Net profits are increased if 
                            operator has profitably raised clearing prices, but decreased if it
                            did so unprofitably.

        The reward is scaled and stored along with other outputs in the data to support learning.
        """

        market_getter = itemgetter("start_time", "end_time", "only_hours")
        orderbook.sort(key=market_getter)
        # Function is called after the market is cleared, and we get the market feedback,
        # allowing us to calculate profit based on the realized transactions.
        product_type = marketconfig.product_type
        market_id = marketconfig.market_id
        # # Depending on how the unit calculates marginal costs, retrieve cost values.
        tot_profits = 0.0
        comp_profits = 0.0
        scaled_accepted_vol = 0
        scaling_factor = 1 / (self.installed_capacity * self.max_price * self.steps)
  
        # Iterate over all orders in the orderbook to calculate order-specific profit.
        for product, product_orders in groupby(orderbook, market_getter):
            start, end, _ = product            
            
            for order in product_orders:
                unit_id = order["unit_id"]
                unit = units_operator.units[unit_id]

                comp_price = unit.forecaster.price[market_id][start]
                clearing_price = order["accepted_price"]
                accepted_volume = order.get("accepted_volume", 0)
                
                marginal_cost = unit.calculate_marginal_cost(
                    start, unit.outputs[product_type].at[start])
               
                # Compute profits
                unit_profit = (clearing_price - marginal_cost) * accepted_volume
                tot_profits+= unit_profit

                # Compute competitive profits (assumes that unit offer is accepted
                # if mc = comp_price
                comp_volume = 0 if comp_price < marginal_cost else order["volume"]
                unit_comp_profit = (comp_price - marginal_cost) * comp_volume
                comp_profits+= unit_comp_profit           
                
                scaled_accepted_vol += accepted_volume * scaling_factor      

         
        rel_profits = (tot_profits - comp_profits) * scaling_factor
        # reward = np.tanh(rel_profits)
        reward = rel_profits
        
 
        if self.learning_mode:
            self.learning_role.add_reward_to_cache(
                units_operator.id, start, reward, rel_profits, tot_profits
            )
