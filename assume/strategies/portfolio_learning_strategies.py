# SPDX-FileCopyrightText: ASSUME Developers
#
# SPDX-License-Identifier: AGPL-3.0-or-later

from datetime import datetime, timedelta
from itertools import groupby
from operator import itemgetter

import numpy as np
import torch as th

from assume.common.fast_pandas import FastSeries
from assume.common.market_objects import MarketConfig, Orderbook, Product
from assume.common.utils import min_max_rescale, min_max_scale
from assume.strategies.learning_strategies import TorchLearningStrategy
from assume.strategies.portfolio_strategies import UnitOperatorStrategy


class PortfolioRLStrategy(TorchLearningStrategy, UnitOperatorStrategy):
    """
    Reinforcement Learning Strategy that enables the agent to learn optimal bidding strategies for
    the portfolio of a units_operator on an Energy-Only Market.

    The agent submits a discrete price according to their available flexible capacity.
    This strategy utilizes a set of observations to generate actions, which are then transformed into
    market bids.

    Observations include the following components:

    - **Forecasted Residual Load**: Forecasted load over the foresight period, scaled by the maximum
      demand, indicating anticipated grid conditions.
    - **Forecasted Price**: Price forecast over the foresight period, scaled by the maximum bid price,
      providing a sense of expected market prices.
    - **Total Flexible Capacity**
    - **Marginal cost quantiles**

    Actions are: total flexible capacity to be bid and prices for flexible generation, rescaled
    from a range of [-1, 1] in the `calculate_bids` method, then translated into unit-specific bids.

    Rewards are based on profit from transactions, minus operational and profit of marginal costs bidding. Key components include:

    - **Profit**: Determined from the income generated by accepted bids, calculated as the product of
      accepted price, volume, and duration.
    - **Operational Costs**: Includes marginal costs and start-up costs when a unit transitions between
      on and off states.
    - **Benchmark Marginal Cost Bidding**: A baseline strategy where all capacity is bid at marginal cost.

    Attributes
    ----------
    foresight : int
        Number of time steps for which the agent forecasts market conditions. Defaults to 24.
    nbins : int
        Number of price quantiles for bidding. Defaults to 4.
    steps : int
        Number of time steps to bid ahead. For clearing algorithms that clear more than one hour ahead. Defaults to 1.
    max_bid_price : float
        Maximum allowable bid price. Defaults to 100.
    min_bid_price : float
        Maximum allowable bid price. Defaults to -100.
    max_demand : float
        Maximum demand capacity of the unit. Defaults to 10e3.
    device : str
        Device for computation, such as "cpu" or "cuda". Defaults to "cpu".
    float_type : str
        Data type for floating-point calculations, typically "float32". Defaults to "float32".
    learning_mode : bool
        Indicates whether the agent is in learning mode. Defaults to False.
    algorithm : str
        Name of the RL algorithm in use. Defaults to "matd3".
    actor_architecture_class : type[torch.nn.Module]
        Class of the neural network architecture used for the actor network. Defaults to MLPActor.
    actor : torch.nn.Module
        Actor network for determining actions.
    order_types : list[str]
        Types of market orders supported by the strategy. Defaults to ["SB"].
    action_noise : NormalActionNoise
        Noise model added to actions during learning to encourage exploration. Defaults to None.
    collect_initial_experience_mode : bool
        Whether the agent is collecting initial experience through exploration. Defaults to True.

    Args
    ----
    *args : Variable length argument list.
    **kwargs : Arbitrary keyword arguments.
    """

    def __init__(self, *args, **kwargs):
        # 'foresight' represents the number of time steps into the future that we will consider
        # when constructing the observations. This value is fixed for each strategy, as the
        # neural network architecture is predefined, and the size of the observations must remain consistent.
        # If you wish to modify the foresight length, remember to also update the 'obs_dim' parameter above,
        # as the observation dimension depends on the foresight value.
        self.foresight = kwargs.pop("foresight", 12)  # in hours
        self.nbins = kwargs.pop("nbins", 4)
        self.steps = kwargs.pop("steps", 1)  # would enable 24h bidding
        act_dim = self.nbins * self.steps  # actions for each time step in the foresight
        unique_obs_dim = self.nbins
        obs_dim = kwargs.pop(
            "obs_dim", 3 * self.foresight + unique_obs_dim
        )  # e.g. 36 shared observations + 4 unique_observations

        super().__init__(
            foresight=self.foresight,
            obs_dim=obs_dim,
            act_dim=act_dim,  # actions for each time step in the foresight
            unique_obs_dim=unique_obs_dim,
            *args,
            **kwargs,
        )

        # define allowed order types
        self.order_types = kwargs.get("order_types", ["SB"])
        self.opportunity_cost_scaling = kwargs.get("opportunity_cost_scaling", 0)

    def calculate_bids(
        self,
        units_operator,  # type: UnitsOperator
        market_config: MarketConfig,
        product_tuples: list[Product],
        **kwargs,
    ) -> Orderbook:
        """
        Calculates bids based on the current observations and actions derived from the actor network.

        Args
        ----
            units_operator (UnitsOperator): The operator that bids on the market.
            market_config (MarketConfig): The configuration of the market.
            product_tuples (list[Product]): List of products with start and end times for bidding.
            **kwargs : Additional keyword arguments.

        Returns
        -------
        Orderbook
            Contains bid entries for each product, including start time, end time, price, and volume.

        Notes
        -----
        This method obtains actions as a tensor of bid prices and total flexible quantity to bid.
        Prices per quantile are then translated into unit-specific bids, which are submitted by sorting
        units by their marginal cost, bidding their inflexible generation at 0 â‚¬/MWh and iteratively
        bidding flex capacity for the lowest price quantile until its volume is not fully bid.
        """

        start = product_tuples[0][0]
        end = product_tuples[-1][1]
        market_id = market_config.market_id
        bids = []

        assert market_config.market_products[0].count <= self.steps, (
            f"{market_id} market contains less than {self.steps} products."
        )
        assert len(units_operator.units) >= self.nbins, (
            f"{units_operator.id} operates less than {self.nbins} units."
        )

        ### STEP 1: CREATE OBSERVATION ###

        next_observation = self.create_observation(
            units_operator=units_operator,
            market_id=market_config.market_id,
            start=start,
            end=end,
        )
        scaled_costs = next_observation[-self.nbins :]

        ### STEP 2: RESCALE THE AGENT INPUTS AND OUTPUTS ###

        actions, noise = self.get_actions(next_observation)

        costs = min_max_rescale(
            scaled_costs.cpu().numpy(), self.min_price, self.max_price
        )

        markups = min_max_rescale(
            actions.cpu().numpy(),
            1,  # TODO: this artificially forces the unit to bid above marginal cost
            3,
            lower_bound=-1,
            upper_bound=1,
        )

        ### STEP 3. BID INFLEXIBLE GENERATION OF ONLINE UNITS ###

        # 3a. Map each unit to the corresponding price quantile based on its marginal cost
        for i, product in enumerate(product_tuples):
            prod_start = product[0]
            prod_end = product[1]

            for unit_id, unit in units_operator.units.items():
                min_power, max_power = unit.calculate_min_max_power(start, end)
                inflex_gen, max_mw = min_power[0], max_power[0]
                flex_gen = max_mw - inflex_gen
                marginal_cost = unit.calculate_marginal_cost(start, max_mw)

                j = next(
                    (k for k, c in enumerate(costs) if c >= marginal_cost),
                    self.nbins - 1,
                )

                # 3b. Bid INFLEXIBLE generation of online units for their mc

                if inflex_gen > 0:
                    bids.append(
                        {
                            "start_time": prod_start,
                            "end_time": prod_end,
                            "only_hours": None,
                            "price": marginal_cost,
                            "volume": inflex_gen,
                            "unit_id": unit_id,
                            "bid_id": f"{units_operator.id}_{unit_id}_inflex",
                            "node": units_operator.units[unit_id].node,
                        }
                    )

                # 3c. Bid FLEXIBLE generation of online units for the price of corresponding quantile
                bids.append(
                    {
                        "start_time": prod_start,
                        "end_time": prod_end,
                        "only_hours": None,
                        "price": marginal_cost
                        * markups[self.nbins * i + j],  # price for quantile j at time i
                        "volume": flex_gen,
                        "unit_id": unit_id,
                        "bid_id": f"{units_operator.id}_{unit_id}_flex",
                        "node": units_operator.units[unit_id].node,
                    }
                )

        if self.learning_mode:
            self.learning_role.add_actions_to_cache(
                units_operator.id, start, actions, noise
            )

        return bids

    def get_actions(self, next_observation: th.Tensor) -> tuple[th.Tensor, th.Tensor]:
        """
        Compute actions based on the current observation.

        Args
        ----
        next_observation (torch.Tensor): The current observation, where the last element is assumed to be the marginal cost.

        Returns
        -------
        tuple of torch.Tensor
            A tuple containing: Actions to be taken (with or without noise). The noise component (if any), useful for diagnostics.
            The output action is a list of bid prices for flexible generation.
            Output is scaled to the range [-1, 1].

        Notes
        -----
        During learning, exploratory noise is applied and already part of the curr_action unless in evaluation mode.
        In initial exploration mode, bids price are around the quantiles.
        This assumes the last self.nbins elements of `next_observation`
        have the following structure: [flex_mc_0, flex_mc_1, ..., flex_mc_dim]
        """

        # Get the base action and associated noise from the parent implementation
        curr_action, noise = super().get_actions(next_observation)

        if self.learning_mode and not self.evaluation_mode:
            # Uniformly random actions in [-1.0, 1.0], sorted to ensure increasing prices
            if self.collect_initial_experience_mode:
                freq = 10
                curr_action = (
                    th.randint_like(curr_action, low=-1 * freq, high=1 * freq + 1)
                    / freq
                )

                # res_load = min_max_rescale(next_observation[0],
                #                            self.min_res_load, self.max_res_load)
                # res_load = np.floor(res_load.item() / 500) * 500

                # response_dict = {4000.0: [0.9999999422227193, -1, 1.],
                # 5000.0: [0.00458909405911978, 0.24999995467527292, 1.],
                # 6000.0: [0.003797706313778626, 1.0, 1.0],
                # 2000.0: [-1, -1, -1],
                # 3000.0: [-0.6666667316047459, -1, -1],
                # 5500.0: [0.0008693561622754586, 0.0008917639352676865, 1.0]}

                # curr_action = response_dict.get(res_load, [-1,-1,-1])
                # print(curr_action, res_load)

                # return th.tensor(curr_action), noise

        return curr_action, noise

    def prepare_observations(self, units_operator, market_id):
        total_capacity = self.total_capacity(units_operator)
        self.installed_capacity = total_capacity[market_id]

        gen_obs = 0

        for u_id, unit in units_operator.units.items():
            unit_gen = FastSeries(index=unit.index, value=0)
            price_forecast = unit.forecaster.price[market_id]
            residual_load = unit.forecaster.residual_load[market_id]

            for start in price_forecast.index:
                marginal_cost = unit.calculate_marginal_cost(start, unit.max_power)
                unit_state = price_forecast[start] > marginal_cost
                unit_gen[start] = unit_state * unit.max_power

            gen_obs += unit_gen

        self.min_price = min(price_forecast)
        self.max_price = max(price_forecast)
        self.min_res_load = min(residual_load)
        self.max_res_load = max(residual_load)

        self.scaled_res_load_obs = min_max_scale(
            residual_load, self.min_res_load, self.max_res_load
        )

        self.scaled_prices_obs = min_max_scale(
            price_forecast, self.min_price, self.max_price
        )

        # scale this by residual load or by installed capacity?
        self.scaled_gen_obs = gen_obs / residual_load
        # super().prepare_observations(unit, market_id)

    def create_observation(self, units_operator, market_id, start, end):
        # ensure scaled observations are prepared
        if not hasattr(self, "scaled_res_load_obs") or not hasattr(
            self, "scaled_prices_obs"
        ):
            self.prepare_observations(units_operator, market_id)

        # =============================================================================
        # 1.1 Get the Observations, which are the basis of the action decision
        # =============================================================================

        # --- 1. Forecasted residual load and price (forward-looking) ---
        scaled_res_load_forecast = self.scaled_res_load_obs.window(
            start, self.foresight, direction="forward"
        )
        scaled_price_forecast = self.scaled_prices_obs.window(
            start, self.foresight, direction="forward"
        )

        scaled_gen_forecast = self.scaled_gen_obs.window(
            start, self.foresight, direction="forward"
        )

        # --- 2. Historical actual prices (backward-looking) ---
        # TODO: remove this
        # scaled_price_history = (
        #     unit.outputs["energy_accepted_price"].window(
        #         start, self.foresight, direction="backward"
        #     )
        #     / self.max_bid_price
        # )

        # --- 3. Individual observations ---

        individual_observations = self.get_individual_observations(
            units_operator, start, end
        )

        # concat all observations into one array
        observation = np.concatenate(
            [
                scaled_res_load_forecast,
                scaled_price_forecast,
                scaled_gen_forecast,
                # scaled_price_history,
                individual_observations,
            ]
        )

        # transfer array to GPU for NN processing
        observation = th.as_tensor(
            observation, dtype=self.float_type, device=self.device
        ).flatten()

        if self.learning_mode:
            self.learning_role.add_observation_to_cache(
                units_operator.id, start, observation
            )

        return observation

    def get_individual_observations(
        self,
        units_operator,  # type: UnitsOperator
        start: datetime,
        end: datetime,
    ):
        """
        Retrieves the observations specific to the units_operator. Returns a scaled array
        in range [-1,1] with the structure: [scaled_cost_1, scaled_cost_2, ...],
        where:
            scaled_cost: self.nbins quantiles of flex marginal costs for units
            that are bid in the market.

        Args
        ----
            units_on (dict): The units that the operator bids on the market.
            start (datetime.datetime): Start time for the observation period.
            end (datetime.datetime): End time for the observation period.

        Returns
        -------
        individual_observations (np.array): total flexible capacity,
        weighted quantiles of marginal costs.

        Notes
        -----
            Outputs are in range [-1,1], where
            costs are min-max scaled by [self.min_bid_price, self.max_bid_price].
        """

        # Sort unit tuples by marginal cost
        unit_tuples = {}

        for u_id, unit in units_operator.units.items():
            min_power, max_power = unit.calculate_min_max_power(start, end)
            inflex_gen, max_mw = min_power[0], max_power[0]
            flex_gen = max_mw - inflex_gen
            marginal_cost = unit.calculate_marginal_cost(start, max_mw)
            unit_tuples[u_id] = inflex_gen, flex_gen, marginal_cost

        sorted_tuples = sorted(list(unit_tuples.values()), key=lambda x: x[-1])
        inflex_quant, flex_quant, flex_cost = zip(*sorted_tuples)

        # Average marginal costs for each quantile
        bins = [i / self.nbins for i in range(1, self.nbins + 1)]
        cost_bins = np.quantile(
            flex_cost, q=bins, weights=flex_quant, method="inverted_cdf"
        )
        scaled_costs = min_max_scale(cost_bins, self.min_price, self.max_price)

        return scaled_costs

    def calculate_reward(
        self,
        units_operator,  # type: UnitsOperator
        marketconfig: MarketConfig,
        orderbook: Orderbook,
    ):
        """
        Calculates the reward for the unit based on profits, costs, and opportunity costs from market transactions.

        Args
        ----
            units_operator (UnitsOperator): The operator for which to calculate the reward.
            marketconfig (MarketConfig): The configuration of the market.
            orderbook (Orderbook): Orderbook containing executed bids and details.

        Notes
        -----
        The profit is computed using **flexible** bids only.
        The reward is computed by multiplying the following:
        **Profit**: Income from accepted flexible bids minus marginal and start-up costs.
        **Scaling**: A scaling factor to normalize the reward to the range [-1,1].

        The reward is scaled and stored along with other outputs in the data to support learning.
        """

        market_getter = itemgetter("start_time", "end_time", "only_hours")
        orderbook.sort(key=market_getter)
        # Function is called after the market is cleared, and we get the market feedback,
        # allowing us to calculate profit based on the realized transactions.
        product_type = marketconfig.product_type
        start = orderbook[0]["start_time"]

        # # Depending on how the unit calculates marginal costs, retrieve cost values.

        income = 0.0
        reward = 0.0
        operational_cost = 0.0
        start_cost = 0.0
        opportunity_cost = 0.0

        accepted_volume_total = 0
        offered_volume_total = 0
        reward = 0

        # Iterate over all orders in the orderbook to calculate order-specific profit.

        for product, product_orders in groupby(orderbook, market_getter):
            prod_start, prod_end, only_hours = product
            duration = (prod_end - prod_start) / timedelta(hours=1)

            for order in product_orders:
                unit_id = order["unit_id"]
                unit = units_operator.units[unit_id]
                market_clearing_price = order["accepted_price"]
                accepted_volume = order.get("accepted_volume", 0)
                accepted_volume_total += accepted_volume
                offered_volume_total += order["volume"]

                # Calculate profit as income minus operational cost for this event.
                order_income = market_clearing_price * accepted_volume * duration
                marginal_cost = unit.calculate_marginal_cost(
                    prod_start, unit.outputs[product_type].at[prod_start]
                )
                order_cost = marginal_cost * accepted_volume * duration

                # Consideration of start-up costs if unit was started at this time step.
                op_time = unit.get_operation_time(prod_start)
                unit_sc = unit.get_starting_costs(op_time)

                if (
                    unit.outputs[product_type].at[prod_start] != 0
                    and unit.outputs[product_type].at[prod_start - unit.index.freq] == 0
                ):
                    start_cost += unit_sc

                # Accumulate income and operational cost for all orders.
                income += order_income
                operational_cost += order_cost

                if not accepted_volume and marginal_cost > market_clearing_price:
                    # if order was accepted, but profit could have been positive --> loss from NOT bidding
                    opportunity_cost += (
                        -1
                        * (market_clearing_price - marginal_cost)
                        * order["volume"]
                        * duration
                    )
                    reward = -1

                if order["price"] == market_clearing_price:
                    price_forecast = unit.forecaster.price[marketconfig.market_id][
                        prod_start
                    ]
                    price_diff = (
                        market_clearing_price - price_forecast
                    ) * accepted_volume
                    reward = -1 if price_diff < 0 else 1

        price_forecast = unit.forecaster.price[marketconfig.market_id][prod_start]
        price_diff = (market_clearing_price - price_forecast) * accepted_volume_total

        profit = income - (operational_cost + start_cost)
        # scaling factor to avoid too large rewards
        # scaled_profit = profit / (self.max_bid_price * offered_volume_total * self.steps)
        # opp_cost = opportunity_cost / (self.max_bid_price * offered_volume_total * self.steps)
        # reward = scaled_profit + self.opportunity_cost_scaling * opp_cost

        if self.learning_mode:
            self.learning_role.add_reward_to_cache(
                units_operator.id, start, reward, opportunity_cost, profit
            )

    # def calculate_reward(
    #     self,
    #     units_operator,  # type: UnitsOperator
    #     marketconfig: MarketConfig,
    #     orderbook: Orderbook,
    # ):
    #     """
    #     Calculates the reward for the unit based on profits, costs, and opportunity costs from market transactions.

    #     Args
    #     ----
    #         units_operator (UnitsOperator): The operator for which to calculate the reward.
    #         marketconfig (MarketConfig): The configuration of the market.
    #         orderbook (Orderbook): Orderbook containing executed bids and details.

    #     Notes
    #     -----
    #     The profit is computed using **flexible** bids only.
    #     The reward is computed by multiplying the following:
    #     **Profit**: Income from accepted flexible bids minus marginal and start-up costs.
    #     **Scaling**: A scaling factor to normalize the reward to the range [-1,1].

    #     The reward is scaled and stored along with other outputs in the data to support learning.
    #     """

    #     market_getter = itemgetter("start_time", "end_time", "only_hours")
    #     orderbook.sort(key=market_getter)
    #     # Function is called after the market is cleared, and we get the market feedback,
    #     # allowing us to calculate profit based on the realized transactions.
    #     product_type = marketconfig.product_type
    #     market_id = marketconfig.market_id
    #     duration = (orderbook[0]["start_time"] - orderbook[-1]["end_time"]) / timedelta(hours=1)
    #     # # Depending on how the unit calculates marginal costs, retrieve cost values.
    #     tot_profits = 0
    #     rel_profits = 0

    #     # Iterate over all orders in the orderbook to calculate order-specific profit.
    #     for product, product_orders in groupby(orderbook, market_getter):
    #         start, end, _ = product
    #         profits = 0
    #         competitive_profits = 0

    #         for order in product_orders:
    #             unit_id = order["unit_id"]
    #             unit = units_operator.units[unit_id]

    #             competitive_price = unit.forecaster.price[market_id][start]
    #             clearing_price = order["accepted_price"]
    #             accepted_volume = order.get("accepted_volume", 0)

    #             # Calculate profit as income minus operational cost for this event.
    #             min_power, max_power = unit.calculate_min_max_power(start, end)

    #             marginal_cost = unit.calculate_marginal_cost(
    #                 start, unit.outputs[product_type].at[start])

    #             unit_profit = (clearing_price - marginal_cost) * accepted_volume
    #             unit_comp_profit = (competitive_price - marginal_cost) * max_power[0]
    #             profits+= unit_profit
    #             competitive_profits+= unit_comp_profit

    #         if competitive_profits == 0:
    #             continue

    #         tot_profits+= profits
    #         rel_profits+= profits / competitive_profits
    #         # max_comp_profits+= competitive_profits

    #     # scaling factor to avoid too large rewards
    #     #reward = tot_profits / (self.installed_capacity * self.max_price)

    #     reward = rel_profits / (duration * self.min_price)

    #     if self.learning_mode:
    #         self.learning_role.add_reward_to_cache(
    #             units_operator.id, start, reward, 0, tot_profits
    #         )


# def calculate_mustrun_profit(
#         min_power:float,
#         marginal_cost:float,
#         foresight:int,
#         price_fcst:np.array,
# ) -> float:
#     """
#     Computes expected profits at min_power over a given time foresight,
#     given an array of price forecasts and one marginal cost.

#     Args
#     ----
#     min_power (float): Minimum power output of the unit.
#     marginal_cost (float): Marginal cost of the unit.
#     foresight (int): Number of time steps to consider for profit calculation.
#     price_fcst (np.array): Array of forecasted prices over the foresight period.

#     Returns
#     -------
#     profit (float): Expected profit of running at min capacity and
#     marginal cost over the foresight period.

#     """
#     profit = 0.0
#     for t in range(min(foresight, len(price_fcst))):
#         profit += (price_fcst[t] - marginal_cost) * min_power

#     return profit

# def determine_on_off_units(
#     self,
#     units_operator, # type:UnitsOperator
#     market_id: str,
#     start: datetime,
#     end: datetime
# ) -> tuple[dict, dict]:

#     units_on, units_off = {}, {}

#     for unit_id, unit in units_operator.units.items():
#         if market_id not in unit.forecaster.price:
#             continue

#         price_fcst = unit.forecaster.price[market_id][start:end]
#         # obtain min power and maximum power
#         min_power, max_power = unit.calculate_min_max_power(start,end)
#         inflex_gen, max_mw = min_power[0], max_power[0]
#         flex_gen = max_mw - inflex_gen
#         marginal_cost = unit.calculate_marginal_cost(start, max_mw)

#         op_time = unit.get_operation_time(start)

#         # Previously: unit was OFFLINE
#         if op_time <= 0:
#             mustrun_profit = calculate_mustrun_profit(inflex_gen,
#                                                       marginal_cost,
#                                                       int(unit.min_operating_time),
#                                                       price_fcst)

#             # if the unit is constrained by its min down time --> OFFLINE
#             if op_time > unit.min_down_time:
#                 units_off[unit_id] = inflex_gen, flex_gen, marginal_cost
#             # if expected profits higher than start cost --> ONLINE
#             elif mustrun_profit > unit.hot_start_cost:
#                 units_on[unit_id] = inflex_gen, flex_gen, marginal_cost
#             # else --> stay OFFLINE
#             else:
#                 units_off[unit_id] = inflex_gen, flex_gen, marginal_cost

#         # Previously: unit was ONLINE
#         else:
#             mustrun_profit = calculate_mustrun_profit(inflex_gen,
#                                                       marginal_cost,
#                                                       int(unit.min_down_time),
#                                                       price_fcst)

#             # if the unit is constrained by its min op. time --> ONLINE
#             if op_time < unit.min_operating_time:
#                 units_on[unit_id] = inflex_gen, flex_gen, marginal_cost

#             # if expected profits lower than start cost --> OFFLINE
#             elif mustrun_profit < - unit.hot_start_cost:
#                 units_off[unit_id] = inflex_gen, flex_gen, marginal_cost

#             # else --> stay ONLINE
#             else:
#                 units_on[unit_id] = inflex_gen, flex_gen, marginal_cost

#     return units_on, units_off
